---
title: "WY Lake Sediment Prokaryotic Community Analyses"
author: "Jordan Von Eggers"
date: "2024-01-19"
output: html_document
editor_options: 
  chunk_output_type: console
---

# load packages
```{r}

require(tidyverse)
require(vegan)
require(phyloseq)
require(beepr)
require(parallelDist)
require(colorspace)
require(pivottabler)
require(reshape2)
require(rioja)

# require(iNEXT)
# require(phangorn)
# require(msa)
# require(Biostrings)
# 
# require(cluster)
# 
# require(geosphere)
# require(Hmisc)
# require(patchwork)
# require(Matrix)
# require(metagMisc)
# require(ggplot2)
# library(MetBrewer)
# 
# require(rioja)
# require(mgcv)
# require(parallelDist)
# require(ape)
# require(dplyr)
# library(caret)
# library(picante)
```


# Part III: Data Analysis

## 1. Load data

```{r}
load("WyLakeMicrobes_Phyloseq_16Jan2024.RData")
```


## 1. iCAMP community assembly

### a. make phylogenetic tree

#### i. subset ESVS with 10+ reads


```{r}
ESV<-as.data.frame(otu_table(ps))
ESV<-t(ESV)
ESV<-ESV[order(rownames(ESV)),]

table(colSums(ESV)<10)
# FALSE  TRUE 
# 28488 64357
#[1] "2024-01-16"
mean(colSums(ESV)) #53 reads on average - "2024-01-16"

lessthan10<-which(colSums(ESV)<10)
ESV_10plusreads<-ESV[,-lessthan10]
dim(ESV_10plusreads)
# 478 28488 - 27May2023
table(colSums(ESV_10plusreads)<10)# all FALSE
```

#### ii. subset fasta file with sequences

in local R, subset fasta file by the ESVs with 10+ reads (normalized reads)

```{r}
seqs<-Biostrings::readDNAStringSet("OriginalFiles/zotus_nonchimeric.fa") 
seqs@ranges@NAMES<-stringr::str_split(seqs@ranges@NAMES,pattern = ";", 3, simplify = T)[,1]

seqs_sub<-seqs[colnames(ESV_10plusreads)]
table(seqs_sub@ranges@NAMES %in% colnames(ESV_10plusreads))
table(colnames(ESV_10plusreads)%in%seqs_sub@ranges@NAMES)
rm(list=ls()[! ls() %in% c("ESV_10plusreads", "seqs_sub" )])
#save.image("WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads_16Jan2024.RData")
#writeXStringSet(seqs_sub,filepath = "ESVs_with10ormorereads_forBeartooth_16Jan2024.fasta", format = "fasta")
```

copy the fasta file over to the supercomputer

```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/ESVs_with10ormorereads_forBeartooth_16Jan2024.fasta jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/decontam_dataset/phylogenetic_tree
```

#### iii. make phylogenetic tree

using clustalo to align and then fasttree to make the tree

align_maketree.sh
```{bash}
#!/bin/bash
#SBATCH --job-name phylotree
#SBATCH --mem=120GB
#SBATCH --time=1-00:00:00
#SBATCH --cpus-per-task=6
#SBATCH --account=microbiome
#SBATCH --output=phylotree_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load arcc/1.0 miniconda3/4.12.0
conda activate shotgun_env
cd /project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/decontam_dataset/phylogenetic_tree

clustalo -i ESVs_with10ormorereads_forBeartooth_16Jan2024.fasta -o tempfile_16Jan2024_muscled.fa -v --threads=6

FastTree -nt tempfile_16Jan2024_muscled.fa > ESVs_with10ormorereads_output_16Jan2024_muscled.nwk

```


Copy environment over to supercomputer
```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads_16Jan2024.RData jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/decontam_dataset/iCAMP
```


```{bash}
cp ESVs_with10ormorereads_output_16Jan2024_muscled.nwk ../iCAMP
```


### b. qpen ESVs with 10+ reads

qpen_function.R
```{r}
require(phyloseq)
require(iCAMP)
require(ape)
load("../WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads_16Jan2024.RData")
comm<-ESV_10plusreads
tree<-read.tree("../ESVs_with10ormorereads_output_16Jan2024_muscled.nwk")
table(colnames(ESV_10plusreads)%in%tree[["tip.label"]]) #all TRUE
table(tree[["tip.label"]]%in%colnames(ESV_10plusreads)) #all TRUE


wd0="/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/decontam_dataset/iCAMP/qpen"
nworker=6 # parallel computing thread number
rand.time=1000 # usually use 1000 for real data.
  

  # for a big dataset, pdist.big may be used
  save.wd="/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/decontam_dataset/iCAMP/qpen/pdbig.qpen"
  print(save.wd)
  # please change to the folder you want to save the pd.big output.
  
  pd.big=pdist.big(tree = tree, wd=save.wd, nworker = nworker)
  qp2=qpen(comm=comm, pd=pd.big$pd.file, pd.big.wd=pd.big$pd.wd,
           pd.big.spname=pd.big$tip.label, tree=tree,
           rand.time=rand.time, nworker=nworker)
  setwd(wd0)
save.image("WyLakeMicrobes_env_16Jan2024_qpen_ESVswith10plusreads_results.RData")
```

run_qpen_function.sh
```{bash}
#!/bin/bash
#SBATCH --job-name qpen_10plus
#SBATCH --mem=120GB
#SBATCH --time=6-00:00:00
#SBATCH --cpus-per-task=6
#SBATCH --account=microbiome
#SBATCH --output=qpen_10plus_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load gcc/12.2.0 r/4.2.2
cd /project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/decontam_dataset/iCAMP/qpen

srun Rscript qpen_function.R
echo "srun Rscript qpen_function.R"

echo "finished qpen iCAMP - JVE"
date
```


LEFT OFF HERE 16 Jan 2024
copy back to desktop
```{bash}
rsync jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/iCAMP/qpen/WyLakeMicrobes_env_16Jan2024_qpen_ESVswith10plusreads_results.RData /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes
```


### c. qpen output - ESVs with 10plus reads

#### i) start here
I reran this quickly May 29, 2023 but it all looks the same, could look at again
```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
load("WyLakeMicrobes_env_27May2023_qpen_ESVswith10plusreads_results.RData")

#pull out results from iCAMP
qpn<-qp2$result[,c("sample1","sample2","process")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"process[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)%in%metadata$samp_names) #all true
table(colnames(dfr)%in%metadata$samp_names) # all true

#now add in environmental distances (lake bottom water and lake depth)
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

table(colnames(dfr)==metadata$samp_names) # all true
table(colnames(dfr)==rownames(metadata_sub)) # all true 

daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))
table(colnames(daisy.mat)==colnames(dfr)) # all true
table(rownames(daisy.mat)==rownames(dfr)) # all true

daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
env_dist<-melt(daisy.mat, na.rm=TRUE)

process<-melt(as.matrix(dfr), na.rm=T)

table(process$Var1==env_dist$Var1) # all true
table(process$Var2==env_dist$Var2) # all true 
process$env_dist<-env_dist$value

pairwise<-process #overwrite original file

names(pairwise)[1]<-"s1_samp_names"
pairwise$s1_samp_names<-as.character(pairwise$s1_samp_names)
names(pairwise)[2]<-"s2_samp_names"
pairwise$s2_samp_names<-as.character(pairwise$s2_samp_names)
names(pairwise)[3]<-"process"

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

pairwise<-merge(pairwise, metadata_s1, by="s1_samp_names")
pairwise<-merge(pairwise, metadata_s2, by="s2_samp_names")

#remove metadata notes
pairwise$s1_notes<-NULL
pairwise$s2_notes<-NULL
pairwise$s1_Notes_sed_water_wt<-NULL
pairwise$s2_Notes_sed_water_wt<-NULL
pairwise$s1_Notes_carbon_nitrogen<-NULL
pairwise$s2_Notes_carbon_nitrogen<-NULL
pairwise$s1_Notes._lake_sed_pH<-NULL
pairwise$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
pairwise$abs_cm<-rep(NA, nrow(pairwise))
i=1
for(i in 1:nrow(pairwise)){
  ifelse(pairwise$s1_lake_drive[i]==pairwise$s2_lake_drive[i],pairwise$abs_cm[i]<-abs(pairwise$s2_depth[i]-pairwise$s1_depth[i]),NA)
}

# calculate geographic distance

require(geosphere)
for(i in 1:nrow(pairwise)){
        pairwise$geo_dist[i]<-as.numeric(distm(data.frame(X = pairwise$s1_longitude[i], Y = pairwise$s1_latitude[i]),data.frame(X = pairwise$s2_longitude[i], Y = pairwise$s2_latitude[i])))
}

pairwise$geo_dist_km<-pairwise$geo_dist/1000

write.csv(pairwise, "qpen_10plusESVs_allcomparisons_29May2023.csv")
```

#### ii) environmental distance within each zone

```{r}
comps_backup<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)

comps<-comps_backup

comps$d_val<-comps$env_dist

#make breaks for zone A
comps_tmp<-comps[comps$s1_zone=="A" & comps$s2_zone=="A",]

comps_tmp<-comps_tmp[comps_tmp$d_val!=0,]
comps_tmp$d_val_group_breaks<-cut2(comps_tmp$d_val, g=10)
levels(comps_tmp$d_val_group_breaks)
# [1] "[0.0162,0.117)" "[0.1167,0.163)" "[0.1632,0.210)" "[0.2097,0.240)" "[0.2399,0.276)"
#  [6] "[0.2759,0.323)" "[0.3234,0.384)" "[0.3835,0.454)" "[0.4543,0.540)" "[0.5399,0.722]"
breaks<-c(as.numeric(gsub("\\]","" ,gsub("\\[","",unlist(str_split(as.character(levels(comps_tmp$d_val_group_breaks)), pattern=",")))[c(seq(1, 20, 2),20)])))

#make sure first value is below the minimum env_distance measure that isn't 0
min(comps_backup[comps_backup$env_dist!=0,]$env_dist)
#[1] 0.01621537

# make a bottom break (0.016 - just below the lowest env_dist) that is above zero but below the first break
breaks<-c(0.016,breaks[2:11]) 

full_output<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)

zone<-c("A","B","C")
j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]

sub<-comps_sub[comps_sub$d_val==0,]
sub$d_val_group<-rep(0, nrow(sub))

comps_sub<-comps_sub[comps_sub$d_val!=0,]
comps_sub$d_val_group<-as.numeric(cut(comps_sub$d_val, breaks=breaks))
comps_sub<-rbind(sub, comps_sub)

#breaks_labels<- levels(comps$d_val_group_breaks)
breaks_labels<-c("[0, 0]", "[0.016, 0.12)", "[0.12, 0.16)", "[0.16, 0.21)", "[0.21, 0.24)",
 "[0.24, 0.28)", "[0.28, 0.32)", "[0.32, 0.38)", "[0.38, 0.45)",
"[0.45, 0.54)" ,"[0.54, 0.72]")

tmp<-comps_sub
tally<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)
proc<-unique(comps_backup$process)
groups<-sort(unique(tmp$d_val_group))
i=1
p=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  for(p in 1:length(proc)){
    tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2),d_val_group=groups[i], d_val_inclthisnumandbelow=breaks[i],zone=zone[j], dist="env"))
  }
  }

full_output<-rbind(full_output,tally)
}
#check to make sure they add to one
range(full_output$n)
#[1]  171 2020 #29May2023
mean(full_output$n)
#947.6364 #29May2023


#write.csv(full_output, "qpen_10plusESVs_envdist_29May2023.csv")

```

#### iii) geographic distance

```{r}
comps_backup<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)
comps<-comps_backup


comps[comps$s1_lake_id==comps$s2_lake_id & comps$s1_lake_drive!=comps$s2_lake_drive,]$geo_dist_km<-0.001 #add one meter for cores in the same lake
comps$d_val<-comps$geo_dist_km
breaks<-c(seq(0,15,5), seq(100, 300, 200), seq(400,500,100))  ##nothing from  43.30254  174.6661
breaks<-c(0,0.1, breaks[2:8])
full_output<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)


zone<-c("A","B","C")
j=1
for( j in 1:3) {
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]

sub<-comps_sub[comps_sub$d_val==0,]
sub$d_val_group<-rep(0, nrow(sub))

comps_sub<-comps_sub[comps_sub$d_val!=0,]
comps_sub$d_val_group<-as.numeric(cut(comps_sub$d_val, breaks=breaks))
comps_sub<-rbind(sub, comps_sub)

breaks_labels<- c("[0,0]",levels(cut(comps$d_val, breaks=breaks)))

tmp<-comps_sub
tally<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)
proc<-unique(comps_backup$process)
groups<-sort(unique(tmp$d_val_group))
i=1
p=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  for(p in 1:length(proc)){
    tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2),d_val_group=groups[i], d_val_inclthisnumandbelow=breaks[i],zone=zone[j], dist="geo"))
  }
  }
full_output<-rbind(full_output,tally)
#count the number of comparisons in each zone
}

range(full_output$n)
#[1]  75 2604 # 29May2023
mean(full_output$n)
#1158.222 - 29May2023
print(breaks_labels)

#write.csv(full_output, "qpen_10plusESVs_geodist_29May2023.csv")
```

#### iv) combine the two dataframes

```{r}
geo_dist_tally<-read.csv("qpen_10plusESVs_geodist_29May2023.csv", header=T, row.names=1)
env_dist_tally<-read.csv("qpen_10plusESVs_envdist_29May2023.csv", header=T, row.names=1)
full_output<-rbind(geo_dist_tally,env_dist_tally)

full_output[full_output$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
full_output[full_output$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
full_output[full_output$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
full_output[full_output$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
full_output[full_output$process=="Undominated",]$process<-"C_Drift"


#add in color
full_output$zone_col<-rep('#018571',nrow(full_output))
full_output[full_output$zone=="B",]$zone_col<-"#C4AD79"
full_output[full_output$zone=="C",]$zone_col<-'#a6611a'
        


#add in xlab as dist column
full_output[full_output$dist=="env",]$dist<-'Environmental dissimilarity'
full_output[full_output$dist=="geo",]$dist<-'Distance (km)'

#write.csv(full_output,"qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May023.csv")

#if count needed
count<-unique(full_output[,c("d_val_group","zone","n","dist")])
#write.csv(count, "qpen_10plusESVs_count_summary_29May2023.csv")
```

#### v) plot env and geo dist

```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)
full_output$proportion<-full_output$percent
full_output$percent<-full_output$percent*100

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")
#new_colors<-c("#CCCCCC","#B0E2FF", "#36648B")

break_labels<-list()
break_labels[[1]]<-c( "0",">0 to 0.1" ,  ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0", "0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")

#full_output<-full_output[full_output$process%in%sort(unique(full_output$process))[3:5],]

ggplt<-list()
i=1
j=1
for(j in 1:3){
        sub<-full_output[full_output$zone==sort(unique(full_output$zone))[j],]
for(i in 1:2){
        sub2<-sub[sub$dist==unique(sub$dist)[i],]       
ifelse(j==3, 
       
       
       ggplt[[length(ggplt)+1]] <- ggplot(sub2,            
               aes(x = d_val_group,
                   y = percent,
                   color= process)) +  geom_point(size=3)+ theme_bw()   + xlab(label = sub2$dist[1])+ scale_x_continuous(breaks = sort(unique(sub2$d_val_group)), labels=break_labels[[i]])+ ylab(label = "") + geom_line(linewidth=2) +   labs(color="Assembly process")  + scale_color_manual(values=new_colors)+ theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) +theme(axis.text.x = element_text(angle = 60,hjust=1))+      
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
        axis.text=element_text(size=13), #change font size of axis text
        axis.title=element_text(size=15), #change font size of axis titles
        plot.title=element_text(size=14), #change font size of plot title
        legend.text=element_text(size=14), #change font size of legend text
        legend.title=element_text(size=15)) +
                theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())#change font size of legend title
       
       , 
       
       
              ggplt[[length(ggplt)+1]] <- ggplot(sub2,            
               aes(x = d_val_group,
                   y = percent,
                   color= process)) + geom_point(size=3)+ theme_bw()   + xlab(label = sub2$dist[1])+ scale_x_continuous(breaks = sort(unique(sub2$d_val_group)), labels=break_labels[[i]])+ ylab(label = "") + geom_line(linewidth=2) +   labs(color="Assembly process")   + scale_color_manual(values=new_colors)+ theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) +theme(axis.text.x = element_text(angle = 60,hjust=1))+      
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
        axis.text=element_text(size=13), #change font size of axis text
        axis.title=element_text(size=15), #change font size of axis titles
        plot.title=element_text(size=14), #change font size of plot title
        legend.text=element_text(size=14), #change font size of legend text
        legend.title=element_text(size=15))+ #change font size of legend title
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank()) +
        theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())#change font size of legend title
       )
        }}



pdf("Figures/CommAssemProc_EnvDist_GeoDist_29May2023.pdf",height=7,width=7)
ggplt[[1]]+ggplt[[2]]+ ggplt[[3]]+ggplt[[4]]+ggplt[[5]]+ggplt[[6]]+ 
  plot_layout(ncol = 2)
dev.off()


```

#### vi) plot sediment distance & GAMS

```{r}

qpn<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)

#subset by samples within the same core
downcore<-qpn[is.na(qpn$abs_cm)==F & qpn$abs_cm<27 ,]


downcore$d_val<-abs(downcore$abs_cm)
downcore$d_val_group_breaks<-cut2(downcore$d_val, g=10)
downcore$d_val_group<-as.numeric(cut2(downcore$d_val, g=10))
levels(downcore$d_val_group_breaks)
break_labels<- c("0 to <2.5" ,"2.5 to <5" ,"5 to <7", "7 to <9" ,"9 to <11" ,"11 to <15"
,"15 to <18" ,"18 to <22" ,"22 to <26")
#these are put into 9 groups here instead of the requested 10, must be to make it even.

tmp<-downcore
tally<-data.frame(process=NULL,percent=NULL, d_val_group=NULL,n=NULL)
groups<-sort(unique(downcore$d_val_group))
i=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  processes<-as.data.frame(table(tmp2$process)/nrow(tmp2))
  colnames(processes)[1]<-"process"
  colnames(processes)[2]<-"percent"
  processes$process<-as.character(processes$process)
  processes$d_val_group<-rep(groups[i],nrow(processes))
  processes$n<-rep(nrow(tmp2),nrow(processes))
  tally<-rbind(tally,processes)
}
  


tally$proportion<-tally$percent
tally$percent<-tally$percent*100

tally[tally$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
tally[tally$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
tally[tally$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
tally[tally$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
tally[tally$process=="Undominated",]$process<-"C_Drift"

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

        ggplt <- ggplot(tally,            
                        aes(x = d_val_group,
                            y = percent,
                            color= process)) +  geom_line(linewidth=2) +geom_point(size=3) + theme_bw() + scale_x_continuous(breaks=seq(1,length(groups),1), 
                                                                                                                             labels=break_labels) + xlab(label = "Vertical sediment\ndistance (cm)")+ ylab(label = "Proportion (%)") + geom_line(linewidth=2) +   labs(color="Assembly process")    + scale_color_manual(values=new_colors, labels=c("Variable selection",  "Homogeneous selection",    "Drift",  "Homogenizing dispersal" , "Dispersal limitation" )) + theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) + theme(axis.text.x = element_text(angle = 45,hjust=1))+ guides(color = guide_legend(override.aes = list(linewidth = 6))) + theme(legend.position="none")+
                theme(axis.text=element_text(color="black"))+
                theme(axis.text.x = element_text(angle = 60,hjust=1))+
                theme(text=element_text(size=14), #change font size of all text
                      axis.text=element_text(size=14), #change font size of axis text
                      axis.title=element_text(size=15), #change font size of axis titles
                      plot.title=element_text(size=14), #change font size of plot title
                      legend.text=element_text(size=14), #change font size of legend text
                      legend.title=element_text(size=15),
                      panel.grid.minor = element_blank(), 
                      panel.grid.major.x = element_blank()) #change font size of legend title 

pdf("Figures/CommAssemProc_SedDist_29May2023.pdf", height=3.05, width=3.3)
ggplt
dev.off()

unique(tally$n)
#[1] 372 352 302 283 239 403 163 236 190

#write.csv(tally,"qpen_10plusESVs_seddist_29June2023.csv")

```

sediment distance GAM

sediment distance (with zero)
need to run most of section before (don't need to replot)
```{r}
model_results<-data.frame(process=NULL, devex=NULL, p=NULL)

tally$percent<-tally$percent/100
#Plot the sediment depth GAM for each process
pdf("Figures/SupplementaryFigures/seddepth_GAM_6Sept2023.pdf", height=3.5, width=12)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="black", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels)),1), las=2, labels = break_labels)
title(xlab=c("","","Sediment distance (cm)","","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)

Data<-data.frame(x=sub$d_val_group, y=sub$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=new_colors[i], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(new_colors[i], alpha.f = 0.40), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(process=sort(unique(tally$process))[i], devex=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
}
dev.off()

round(mean(model_results$devex),digits=3)
#[1] 0.914 # 29Jan2023
```


plot legend
```{r}
require(cowplot)
library(ggplot2) 
library(grid)
library(gridExtra) 
# Using the cowplot package
legend <- cowplot::get_legend(ggplt)

grid.newpage()
grid.draw(legend)
```


#### vii) GAMS

doesn't include comparisons within the same lake 8Feb2023 
the labeling for geographic distance is off (double check if going to put in supplementary figures)
29June2023 - can't remember logic for why I removed 0 from the GAMs..
without same lakes
```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

break_labels<-list()
break_labels[[1]]<-c( ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")

full_output<-full_output[full_output$d_val_group!=0,] #GAMs without 0 (without comparisons from the same lake)
tmp1<-full_output[full_output$dist=="Environmental dissimilarity",]
tmp2<-full_output[full_output$dist=="Distance (km)",]
tmp2<-tmp2[tmp2$d_val_group!=1,]
full_output<-rbind(tmp2,tmp1)


model_results<-data.frame(dist=NULL, process=NULL, zone=NULL, rsq=NULL, p=NULL)

d=1
for (d in 1:2){
pdf(paste("Figures/Fig7_qpen_",unique(full_output$dist)[d],"_GAM_18Aug2023.pdf",sep=""), height=3.5, width=12)
par(mfrow=c(1,5),mar=c(8,4,2,1))
tally<-full_output[full_output$dist==unique(full_output$dist)[d],]
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="white", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels[[d]])),1), las=2, labels = break_labels[[d]])
title(xlab=c("","",unique(full_output$dist)[d],"","")[i], cex.lab=2, line=6)
title(ylab=c("Proportion","","","","")[i], cex.lab=2, line =2)
x=1
for(x in 1:3){
sub2<-sub[sub$zone==unique(sub$zone)[x],]
points(sub2$d_val_group,sub2$percent, pch=16, col=sub2$zone_col[x])

#GAM
Data<-data.frame(x=sub2$d_val_group, y=sub2$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=sub2$zone_col[x], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(sub2$zone_col[x], alpha.f = 0.20), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(dist=unique(full_output$dist)[d], process=sort(unique(tally$process))[i], zone=unique(sub$zone)[x], rsq=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
        
}}
dev.off()
}
write.csv(model_results, "qPEN_CommunityAssembly_GAMS_without0_29June2023.csv")

```

with same lakes
```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

break_labels<-list()
break_labels[[1]]<-c( "0",">0 to 0.1" ,  ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0", "0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")


model_results<-data.frame(dist=NULL, process=NULL, zone=NULL, dev.exp=NULL, p=NULL)

d=1
for (d in 1:2){
pdf(paste("Figures/SupplementaryFigures/Fig7_qpen_",unique(full_output$dist)[d],"_GAM_18Aug2023.pdf",sep=""), height=3.5, width=12)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
tally<-full_output[full_output$dist==unique(full_output$dist)[d],]
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="white", xaxt="n")
axis(side=1,cex=0.8, at=seq(0,(length(break_labels[[d]])-1),1), las=2, labels = break_labels[[d]])
title(xlab=c("","",unique(full_output$dist)[d],"","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)
x=1
for(x in 1:3){
sub2<-sub[sub$zone==unique(sub$zone)[x],]
points(sub2$d_val_group,sub2$percent, pch=16, col=sub2$zone_col[x])

#GAM
Data<-data.frame(x=sub2$d_val_group, y=sub2$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=sub2$zone_col[x], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(sub2$zone_col[x], alpha.f = 0.20), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(dist=unique(full_output$dist)[d], process=sort(unique(tally$process))[i], zone=unique(sub$zone)[x], dev.exp=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
        
}}
dev.off()
}
write.csv(model_results, "qPEN_CommunityAssembly_GAMS_with0_18Aug2023.csv")

mean(model_results[model_results$dist=="Environmental dissimilarity",]$dev.exp)
#0.5559333 - aug 18, 2023
mean(model_results[model_results$dist=="Distance (km)",]$dev.exp)
# 0.5546-  aug 18, 2023


```


#### viii) stats for manuscript
```{r}
qpn<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)
(table(qpn$process))/nrow(qpn)

 #   Dispersal.Limitation Heterogeneous.Selection   Homogeneous.Selection 
 #             0.34732419              0.22467830              0.39389314 
 # Homogenizing.Dispersal             Undominated 
 #             0.01335930              0.02074507 

#selection
0.22467830 + 0.39389314


#stochastic
0.01335930 + 0.34732419 + 0.02074507

```

fig 6 A (sed distance)

```{r}
full_output<-read.csv("qpen_10plusESVs_seddist_29June2023.csv", header=T,row.names=1)
i=1
for( i in 1:5){
sub<-full_output[full_output$d_val_group==1 & full_output$process==sort(unique(full_output$process))[i],]
print(sub$process[1])
print(signif(sub$proportion, digits=3)*100)
}

i=1
for( i in 1:5){
sub<-full_output[full_output$d_val_group%in%c(8,9) & full_output$process==sort(unique(full_output$process))[i],]
print(sub$process[1])
print(signif(sub$proportion, digits=3)*100)
}

```

Within an individual sediment core, samples â‰¤ 2.5 cm apart were either homogenized (homogenous selection, 71.5%) or differentiated by selection (variable selection, 5.1%), regardless of horizon. As the distance between samples increased, homogeneous selection declined and variable selection increased (Fig. 6, A). At sediment distances > 18 cm (18-22 and 22-26 cm), where all pairs of samples were compared across horizons, variable selection predominated (29.7-39.5%). Homogenizing dispersal (mass effects) was highest between comparisons 0-7 cm apart (15.3-21.5%), and declined to 5.3% with increasing sediment distance. Dispersal limitation increased with sediment distance, reaching 26.8% at 22-26 cm. Drift played a minor role (< 9%) across all sediment distances.

figure 6 B and C

```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

#1) same lake (environment)

#Homogenous selection
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="B_Homogeneous selection", ]$percent), digits=3)*100


#variable selection
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="A_Variable selection", ]$percent), digits=3)*100


#disp lim
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="E_Dispersal limitation", ]$percent), digits=3)*100


#homog disp
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="D_Homogenizing dispersal", ]$percent), digits=3)*100


#or signif
# 61.5
# 7.19
# 8.49
# 19.7


```

Manuscript text:

Homogeneous selection dominated comparisons within the same horizon within any given lake (mean across horizons, 61.5%), followed by homogenizing dispersal (19.7%), variable selection (7.19%), and dispersal limitation (8.49%) (Fig. 6, B and C).

inter-lake comparisons (averaged across environmental distance and geographic distance)

```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))

for( i in 1:5){

sub<-rbind(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%!in%c(0) & full_output$process==sort(unique(full_output$process))[i],]
      , 
      full_output[full_output$dist=="Distance (km)" & full_output$d_val_group%!in%c(0,1) & full_output$process==sort(unique(full_output$process))[i],])

print(sub$process[1])
print(signif(mean(sub$percent),digits=3)*100)
print(signif(range(sub$percent),digits=3)*100)
}


```

[1] "A_Variable selection" [1] 14.2 [1]  3.17 28.20
[1] "B_Homogeneous selection"[1] 47.7 [1] 26.8 72.0
[1] "C_Drift" [1] 2.77 [1]  0.0 10.9
[1] "D_Homogenizing dispersal" [1] 1.32 [1] 0.00 6.67
[1] "E_Dispersal limitation" [1] 34 [1] 17.5 47.2



As environmental dissimilarity and geographic distance increased with inter-lake comparisons, homogenizing dispersal declined while variable selection and dispersal limitation increased. Regardless, homogeneous selection often remained the most dominant community assembly process in all horizons. Homogeneous selection ranged from 26.8-72.0% (avg. 47.7%), variable selection 3.17-28.20% (avg. 14.2%), and dispersal limitation 17.5-47.2% (avg. 34.0%). Homogenizing dispersal and drift acting alone had negligible effects (avg. 1.32 and 2.77%, respectively) across comparisons of abiotic lake environments and geographic distances.


```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
z=1
for(z in 1:3){
    sub<-full_output[full_output$zone==c("A","B","C")[z],]  

sub2<-rbind(sub[sub$dist=="Environmental dissimilarity" & sub$d_val_group%!in%c(0) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],]
      , 
      sub[sub$dist=="Distance (km)" & sub$d_val_group%!in%c(0,1) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],])

 
print(sub2$zone[1])
print(signif(range(sub2$percent),digits=3)*100)
}
```
In the redox horizon, the contributions of homogenous selection, variable selection, and dispersal limitation explained a comparable proportion of comparisons (11.8-47.0%).


```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
z=1
i=1
for( i in 1:5){
sub<-rbind(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%!in%c(0) & full_output$process==sort(unique(full_output$process))[i],]
      , 
      full_output[full_output$dist=="Distance (km)" & full_output$d_val_group%!in%c(0,1) & full_output$process==sort(unique(full_output$process))[i],])

for(z in 1:3){
    sub2<-sub[sub$zone==c("A","B","C")[z],]    


print(sub2$process[1])
print(sub2$zone[1])
print(signif(mean(sub2$percent),digits=3)*100)
print(signif(range(sub2$percent),digits=3)*100)
}}
```

[1] "B_Homogeneous selection"
[1] "A"
[1] 38.5

[1] "B_Homogeneous selection"
[1] "B"
[1] 45.8

[1] "B_Homogeneous selection"
[1] "C"
[1] 58.9



As environmental dissimilarity and geographic distance increased between lakes, homogenous selection increased across horizons from, on average, 38.5% in the redox horizon to 58.9% in the depauperate horizon (Fig. 6, B, C).



```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
i=1
    sub<-full_output[full_output$zone=="C",]
sub2<-rbind(sub[sub$dist=="Environmental dissimilarity" & sub$d_val_group%!in%c(0) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],]
      , 
      sub[sub$dist=="Distance (km)" & sub$d_val_group%!in%c(0,1) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],])

hs_de<-NULL
hs_vs<-NULL
for (i in 1:length(unique(sub2$d_val_group))){
 sub3<-sub2[sub2$d_val_group==sort(unique(sub2$d_val_group))[i],]

hs_de<-c(hs_de,sub3[sub3$process=="B_Homogeneous selection",]$percent/ sub3[sub3$process=="E_Dispersal limitation",]$percent)
hs_vs<-c(hs_vs,sub3[sub3$process=="B_Homogeneous selection",]$percent/ sub3[sub3$process=="A_Variable selection",]$percent)
    
}
        print(sub3$zone[1])
          print("hs_de")
print(signif(mean(hs_de),digits=3))   
print(signif(range(hs_de),digits=3)) 
          print("hs_vs")
print(signif(mean(hs_vs),digits=3))  
print(signif(range(hs_vs),digits=3)) 

```

[1] "C"

[1] "hs_de"
 
[1] 1.99

[1] 1.28 4.11

[1] "hs_vs"

[1] 8.17

[1]  3.97 17.80

 In the depauperate horizon, homogeneous selection explained the differences between assemblages twice as often as dispersal limitation, on average, and eight times as often as variable selection.






#### ix) mantel tests of RCBray values

These all need to be dist objects

```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
load("WyLakeMicrobes_env_27May2023_qpen_ESVswith10plusreads_results.RData")
require(cluster)
require(stringr)
require(reshape2)
require(geosphere)
require(Hmisc)
require(patchwork)
require(Matrix)
require(vegan)


#can reaload data from here, or just use the qp2 object
qpn<-qp2$result[,c("sample1","sample2","RC")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"RC[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)%in%metadata$samp_names) #all true
table(colnames(dfr)%in%metadata$samp_names) # all true

RCbray<-as.dist(dfr)

#now add in environmental distances (lake bottom water and lake depth)
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
metadata_sub<-metadata[,names(metadata)%in%variables]


table(colnames(dfr)==metadata$samp_names) # all true
table(colnames(dfr)==rownames(metadata_sub)) # all true 

env_dist <- as.dist(as.matrix(daisy(scale(metadata_sub), metric="gower")))
table(labels(RCbray)==labels(env_dist))


# geographic distance

#Lat&lon to distance in meters
xy <- data.frame(X = metadata$longitude, Y = metadata$latitude)
rownames(xy)<-metadata$samp_names
dist_m_output<-distm(xy)
rownames(dist_m_output)<-rownames(xy)
names(dist_m_output)<-rownames(xy)
geo_dist<-as.dist(dist_m_output)

#check to make sure all labels match!
table(labels(RCbray)==labels(env_dist)) #all true
table(labels(RCbray)==labels(geo_dist)) #all true

mantel(RCbray, env_dist)
mantel(RCbray, geo_dist)

#add partial mantel test, spatially structured environmental variables
mantel.partial(RCbray, env_dist, geo_dist, method = "pearson", permutations = 999)
mantel.partial(RCbray, geo_dist, env_dist, method = "pearson", permutations = 999)
```

Call:
mantel(xdis = RCbray, ydis = env_dist) 

Mantel statistic r: 0.2452 
      Significance: 0.001 

Upper quantiles of permutations (null model):
    90%     95%   97.5%     99% 
0.00974 0.01260 0.01558 0.01895 
Permutation: free
Number of permutations: 999



Call:
mantel(xdis = RCbray, ydis = geo_dist) 

Mantel statistic r: 0.2039 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0116 0.0155 0.0191 0.0237 
Permutation: free
Number of permutations: 999




Call:
mantel.partial(xdis = RCbray, ydis = env_dist, zdis = geo_dist,      method = "pearson", permutations = 999) 

Mantel statistic r: 0.2425 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0101 0.0131 0.0150 0.0171 
Permutation: free
Number of permutations: 999




Call:
mantel.partial(xdis = RCbray, ydis = geo_dist, zdis = env_dist,      method = "pearson", permutations = 999) 

Mantel statistic r: 0.2005 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0113 0.0148 0.0187 0.0228 
Permutation: free
Number of permutations: 999



#### x) deeper comparisons

```{r}
require(ggplot2)

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")
comps_backup<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)
comps<-comps_backup
comps$d_val<-comps$abs_cm
comps<-comps[is.na(comps$d_val)==F,]
comps<-comps[comps$d_val>26,] # 119 comparisons, so no many compared to the other ones

tmp2<-comps
tally<-data.frame(n=NULL,process=NULL,percent=NULL)
proc<-unique(comps_backup$process)
for(p in 1:5){
        tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2)))
}
tally$group<-rep("Deep comparisons", nrow(tally))

EAP_plot<-ggplot(tally, aes(x = group, y = percent , fill = process)) +
        geom_bar(stat="identity") + scale_fill_manual(values=new_colors,labels= c("Variable selection", "Homogeneous selection", "Drift", "Homogenizing dispersal", "Dispersal limitation" )) + guides(fill=guide_legend(title="Assembly process")) +  xlab(" ") +
  ylab("Proportion (%)") +
pdf("Figures/SupplementaryFigures/SFig2_deep_community_assembly_6July2023.pdf", height=4, width=4)
EAP_plot
dev.off()

```



#### xi) CAP sediment characteristics

```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
load("WyLakeMicrobes_env_27May2023_qpen_ESVswith10plusreads_results.RData")


#can reaload data from here, or just use the qp2 object
qpn<-qp2$result[,c("sample1","sample2","process")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"process[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
table(colnames(dfr)==metadata$samp_names) # all true


#now select the sediment characteristics to examine
#using objects from above
variables<-c("pH"
, "d_13_c"  
, "cn"
, "sulfur_perc"     
, "water_perc"     
, "protein_per") 

#pull out metadata

metadata_sub<-metadata[,names(metadata)%in%variables]

table(colnames(dfr)==rownames(metadata_sub)) # all true 


daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))
table(colnames(daisy.mat)==colnames(dfr)) # all true
table(rownames(daisy.mat)==rownames(dfr)) # all true


daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
#there are a number of samples that don't have the data specified in the variables, therefore they are listed as NA and removed here.
env_dist<-melt(daisy.mat, na.rm=TRUE)

env_dist_reexpand <- reshape(env_dist, direction="wide", idvar="Var1", timevar="Var2")
rownames(env_dist_reexpand)<-env_dist_reexpand$Var1
env_dist_reexpand$Var1<-NULL
colnames(env_dist_reexpand)<-str_split_fixed(colnames(env_dist_reexpand),"value[.]",n=2)[,2]

#figure out which ones were different
setdiff(rownames(env_dist_reexpand),colnames(env_dist_reexpand))
setdiff(colnames(env_dist_reexpand),rownames(env_dist_reexpand))
env_dist_reexpand$SV0226L<-rep(NA,nrow(env_dist_reexpand))
env_dist_reexpand[nrow(env_dist_reexpand)+1,] <- NA
rownames(env_dist_reexpand)[nrow(env_dist_reexpand)]<-"33_1_10_DNA"

env_dist_reexpand<-env_dist_reexpand[order(row.names(env_dist_reexpand)), ]
table(rownames(env_dist_reexpand)==colnames(env_dist_reexpand)) #all true

#how many NAs in each and overlap for metadata
#metadata_sub[,metadatacolnames(env_dist_reexpand)]
met<-metadata_sub[rownames(metadata_sub)%in% colnames(env_dist_reexpand),]
#pH, cn and percent water are present in most samples, but then half have d13c and half the sulfur and protein percent

#subset the process/dfr data frame by the comparisons in metadata
dfr<-dfr[colnames(env_dist_reexpand),colnames(env_dist_reexpand)]

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)==rownames(env_dist_reexpand)) #all true
table(colnames(dfr)==colnames(env_dist_reexpand)) #all true

#melt back to pairwise comparisons
env_dist<-melt(as.matrix(env_dist_reexpand))
process<-melt(as.matrix(dfr))


table(process$Var1==env_dist$Var1) # all true
table(process$Var2==env_dist$Var2) # all true 
process$env_dist<-env_dist$value
process<-process[complete.cases(process),]


pairwise<-process

names(pairwise)[1]<-"s1_samp_names"
pairwise$s1_samp_names<-as.character(pairwise$s1_samp_names)
names(pairwise)[2]<-"s2_samp_names"
pairwise$s2_samp_names<-as.character(pairwise$s2_samp_names)
names(pairwise)[3]<-"process"

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

pairwise<-merge(pairwise, metadata_s1, by="s1_samp_names")
pairwise<-merge(pairwise, metadata_s2, by="s2_samp_names")

#remove metadata notes
pairwise$s1_notes<-NULL
pairwise$s2_notes<-NULL
pairwise$s1_Notes_sed_water_wt<-NULL
pairwise$s2_Notes_sed_water_wt<-NULL
pairwise$s1_Notes_carbon_nitrogen<-NULL
pairwise$s2_Notes_carbon_nitrogen<-NULL
pairwise$s1_Notes._lake_sed_pH<-NULL
pairwise$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
pairwise$abs_cm<-rep(NA, nrow(pairwise))
i=1
for(i in 1:nrow(pairwise)){
  ifelse(pairwise$s1_lake_drive[i]==pairwise$s2_lake_drive[i],pairwise$abs_cm[i]<-abs(pairwise$s2_depth[i]-pairwise$s1_depth[i]),NA)
}

# calculate geographic distance

require(geosphere)
for(i in 1:nrow(pairwise)){
        pairwise$geo_dist[i]<-as.numeric(distm(data.frame(X = pairwise$s1_longitude[i], Y = pairwise$s1_latitude[i]),data.frame(X = pairwise$s2_longitude[i], Y = pairwise$s2_latitude[i])))
}

pairwise$geo_dist_km<-pairwise$geo_dist/1000

write.csv(pairwise, "qpen_10plusESVs_sediment_characteristics_10July2023.csv")

```

plot all zones together

```{r}

#qpn<-read.csv("qpen_10plusESVs_sediment_characteristics_10July2023.csv", header=T, row.names=1)
#subset by samples within the same core
downcore<-qpn[is.na(qpn$abs_cm)==F & qpn$abs_cm<27 ,]
# we don't want to subset only samples within the same core, but really just want samples that are comparable ANYWHERE
downcore<-qpn

downcore$d_val<-downcore$env_dist
downcore$d_val_group_breaks<-cut2(downcore$d_val, g=10)
downcore$d_val_group<-as.numeric(cut2(downcore$d_val, g=10))
levels(downcore$d_val_group_breaks)
break_labels<- c("0 to <0.03" ,"0.03 to <0.05" ,"0.05 to <0.06", "0.06 to <0.08" ,"0.08 to <0.10" ,"0.10 to <0.13"
,"0.13 to <0.15" ,"0.15 to <0.20" ,"0.20 to <0.28", "0.28 to 1")
# [ includes ( up to 

tmp<-downcore
tally<-data.frame(process=NULL,percent=NULL, d_val_group=NULL,n=NULL)
groups<-sort(unique(downcore$d_val_group))
i=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  processes<-as.data.frame(table(tmp2$process)/nrow(tmp2))
  colnames(processes)[1]<-"process"
  colnames(processes)[2]<-"percent"
  processes$process<-as.character(processes$process)
  processes$d_val_group<-rep(groups[i],nrow(processes))
  processes$n<-rep(nrow(tmp2),nrow(processes))
  tally<-rbind(tally,processes)
}
  

tally[tally$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
tally[tally$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
tally[tally$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
tally[tally$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
tally[tally$process=="Undominated",]$process<-"C_Drift"

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

        ggplt <- ggplot(tally,            
                        aes(x = d_val_group,
                            y = percent,
                            color= process)) +  geom_line(linewidth=2) +geom_point(size=3) + theme_bw() + scale_x_continuous(breaks=seq(1,length(groups),1), 
                                                                                                                             labels=break_labels) + xlab(label = "Sediment characteristic\ndissimilarity")+ ylab(label = "Proportion") + geom_line(linewidth=2) +   labs(color="Assembly process")    +theme(axis.ticks.x = element_blank()) + scale_color_manual(values=new_colors, labels=c("Variable selection",  "Homogeneous selection",    "Drift",  "Homogenizing dispersal" , "Dispersal limitation" )) + theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,.75) + theme(axis.text.x = element_text(angle = 45,hjust=1))+ guides(color = guide_legend(override.aes = list(linewidth = 6))) +
                theme(axis.text=element_text(color="black"))+
                theme(axis.text.x = element_text(angle = 60,hjust=1))+
                theme(text=element_text(size=14), #change font size of all text
                      axis.text=element_text(size=14), #change font size of axis text
                      axis.title=element_text(size=15), #change font size of axis titles
                      plot.title=element_text(size=14), #change font size of plot title
                      legend.text=element_text(size=14), #change font size of legend text
                      legend.title=element_text(size=15),
                      panel.grid.minor = element_blank(), 
                      panel.grid.major.x = element_blank()) #change font size of legend title 

#pdf("Figures/SupplementaryFigures/CAP_sediment_characteristics_intracore_10July2023.pdf", height=3.5, width=6)
pdf("Figures/SupplementaryFigures/CAP_sediment_characteristics_intercore_10July2023.pdf", height=3.5, width=6)
ggplt
dev.off()

unique(tally$n)
# 4277 4276


```




## 2. Alpha diversity

### a. using estimate_richness in phyloseq instead
```{r}
ps_26<-subset_samples(ps,bin_depth<=26)
rich<-estimate_richness(ps_26)

rownames(rich)<-gsub("X","",as.character(rownames(rich)))
rich<-merge(rich,metadata,by="row.names")

jpeg(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SupplementaryFigure6_Richness.jpg"), height=3, width=8, units = "in",res = 600)
par(mfrow=c(1,3))
plot(rich$bin_depth,rich$Observed, pch=16, col="#00000060", xlab="Depth (cm)", ylab="Observed richness")
abline(lm(rich$Observed~rich$bin_depth), lwd=2)
text(y=max(rich$Observed)*0.97, x=20, paste0("p-val: ", signif(summary(lm(rich$Observed~rich$bin_depth))$coefficients[2,4], digits=3)), cex=1)
text(y=max(rich$Observed)*0.91, x=20, paste0("r-sq: ", round(summary(lm(rich$Observed~rich$bin_depth))$r.sq, digits=2)), cex=1)
mtext("A",side=3,line=0.5 ,at=1, cex=2)

plot(rich$bin_depth,rich$Shannon, pch=16, col="#00000060", xlab="Depth (cm)", ylab="Shannon" )
abline(lm(rich$Shannon~rich$bin_depth), lwd=2)
text(y=max(rich$Shannon)*0.45, x=20, paste0("p-val: ", signif(summary(lm(rich$Shannon~rich$bin_depth))$coefficients[2,4], digits=3)), cex=1)
text(y=max(rich$Shannon)*0.4, x=20, paste0("r-sq: ", round(summary(lm(rich$Shannon~rich$bin_depth))$r.sq, digits=2)), cex=1)
mtext("B",side=3,line=0.5 ,at=1, cex=2)


plot(rich$bin_depth,rich$InvSimpson, pch=16, col="#00000060", xlab="Depth (cm)", ylab="Inverse Simpson")
abline(lm(rich$InvSimpson~rich$bin_depth), lwd=2)
text(y=max(rich$InvSimpson)*0.96, x=20, paste0("p-val: ", signif(summary(lm(rich$InvSimpson~rich$bin_depth))$coefficients[2,4], digits=3)), cex=1)
text(y=max(rich$InvSimpson)*0.88, x=20, paste0("r-sq: ", round(summary(lm(rich$InvSimpson~rich$bin_depth))$r.sq, digits=2)), cex=1)
mtext("C",side=3,line=0.5,at=1, cex=2)

dev.off()
```




## 4. NMDS

### a. run NMDS
```{r}
ps_table <- data.frame(otu_table(ps_tr))
ps_table <-t(ps_table)
sd_sed <- data.frame(sample_data(ps_tr))

ord_baseR<-metaMDS(ps_table, distance = "bray")
# Run 0 stress 0.1709794 
# Run 1 stress 0.2061269 
# Run 2 stress 0.2025503 
# Run 3 stress 0.1930247 
# Run 4 stress 0.1982512 
# Run 5 stress 0.1924732 
# Run 6 stress 0.1926573 
# Run 7 stress 0.1937572 
# Run 8 stress 0.1929558 
# Run 9 stress 0.2011198 
# Run 10 stress 0.19689 
# Run 11 stress 0.1915363 
# Run 12 stress 0.2017257 
# Run 13 stress 0.1792799 
# Run 14 stress 0.1926363 
# Run 15 stress 0.1960716 
# Run 16 stress 0.199951 
# Run 17 stress 0.1981593 
# Run 18 stress 0.1917151 
# Run 19 stress 0.178133 
# Run 20 stress 0.1948058 
# *** Best solution was not repeated -- monoMDS stopping criteria:
#      1: no. of iterations >= maxit
#     13: stress ratio > sratmax
#      6: scale factor of the gradient < sfgrmin
# ran 2024-01-17

fig<-ordiplot(ord_baseR, type="points")

NMDS1<-fig$sites[,1]
NMDS2<-fig$sites[,2]

fig_sites<-as.data.frame(fig[["sites"]])
table(fig_sites$NMDS2==NMDS2) #same for both NMDS1 and NMDS2


fig_sites$samp_names<-rownames(fig_sites)
fig_sites$samp_names<-gsub("X","",as.character(fig_sites$samp_names))
table(names(as.data.frame(ps_tr@otu_table))==fig_sites$samp_names) # all true 

#add in metadata to the dataframe with the NMDS
ord_df<-merge(fig_sites,sd_sed, by="samp_names")

#8c510a darker brown
#a6611a # dark brown
#dfc27d
#80cdc1
#018571 # dark teal

darkertan<-darken("#dfc27d", 0.1)
#C4AD79

ord_df$zone_col<-rep('#01857180',nrow(ord_df))
ord_df[ord_df$bin_depth%in%c(6,8,10,12),]$zone_col<-"#C4AD7980"
ord_df[ord_df$bin_depth%in%c(14,16,18,20,22,24,26),]$zone_col<-'#a6611a80'
ord_df[ord_df$depth>26,]$zone_col<-'#00000080' #black

zone_colors<- c('#018571','#dfc27d','#a6611a','#000000')

sd_sed$bottom_water_temp<-sd_sed$water_sample_t_bot
sd_sed$lake_depth<-sd_sed$max_lake_depth
sd_sed$sediment_depth<-sd_sed$depth

#if you want first axis reversed!
ord_df$NMDS1<-(ord_df$NMDS1*(-1))

ord.fit <- envfit(ord_baseR ~  sediment_depth + lake_depth + bottom_water_temp,  data = sd_sed,  perm = 1000, na.rm = TRUE)
ord.fit[["vectors"]][["arrows"]][1,1]<-(ord.fit[["vectors"]][["arrows"]][1,1]*(-1))

#save.image(paste0(Sys.Date(),"_NMDS.Rdata"))
beep()
```


### b. Add variables in with vectors
```{r}
load("2024-01-17_NMDS.Rdata")

ord.fit <- envfit(ord_baseR ~ depth + max_lake_depth + water_sample_t_bot +   water_sample_ph_bot + water_sample_do_bot + water_sample_t_surf + water_sample_ph_surf + water_sample_do_surf + c_perc  + n_perc  + d_13_c,  data = sd_sed,  perm = 1000, na.rm = TRUE)
ord.fit[["vectors"]][["arrows"]][1,1]<-(ord.fit[["vectors"]][["arrows"]][1,1]*(-1))

ord_df$shape<-rep(16,nrow(ord_df))
ord_df[ord_df$depth>26,]$shape<-8
ord_df[ord_df$depth>26,]$zone_col<-'#a6611a' 

ord_df$size<-rep(1.5,nrow(ord_df))
ord_df[ord_df$depth>26,]$size<-1
```

### c. plot NMDS
```{r}
pdf(paste0("Figures/",Sys.Date(),"_NMDS.pdf"), width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,pch=ord_df$shape,cex=ord_df$size, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col=ord_df$zone_col,xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
plot(ord.fit, labels=c("sediment \n depth","lake depth","bottom water temperature\n","bottom water pH", "bottom water DO\n\n\n\n" ,"surface water temperature" ,"surface water pH" ,"surface water DO", "% carbon", "% nitrogen", "d13C"),p.max=0.05, col="black",lwd=6, cex=1.2)
dev.off()
```

### d. plot graphical summary
```{r}
ord_df$shape<-rep(16,nrow(ord_df))
ord_df[ord_df$depth>26,]$zone_col<-'#a6611a80'


pdf(paste0("Figures/",Sys.Date(),"_NMDS_graphicalsummary.pdf"), width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,pch=ord_df$shape,cex=1.2, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col=ord_df$zone_col,xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
dev.off()
```

### e. points by mountain range

```{r}
ord_df$mtn_pch<-rep(NA,nrow(ord_df))
ord_df[ord_df$mountain_range=="Snowy",]$mtn_pch<-21 #circle
ord_df[ord_df$mountain_range=="Beartooth",]$mtn_pch<-22 #square
ord_df[ord_df$mountain_range=="Wind River",]$mtn_pch<-23 #diamond
ord_df[ord_df$mountain_range=="Bighorn",]$mtn_pch<-24 #triangle
ord_df$mtn_pch<-as.numeric(ord_df$mtn_pch)
ord_df[ord_df$depth>26,]$zone_col<-'#00000099' 


pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_NMDS_mtnshapes.pdf"), width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,cex=1.5, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col="black",bg=ord_df$zone_col, pch=ord_df$mtn_pch, xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
dev.off()

```



### f. PERMANOVA

```{r}
ps_table <- data.frame(otu_table(ps_tr)) 
names(ps_table)<-colnames(ps_tr@otu_table)
ps_table<-as.data.frame(t(ps_table))

sd <- as.matrix(sample_data(ps_tr))
sd<-as.data.frame(sd)
sd[sd$lake_id=="40",]$water_sample_t_bot<-20.1#JVE - first adding surface water temperature for round lake bottom water temperature since the lake it 1.5 m deep
sd<-sd %>% filter(lake_id != "45")

vars<-c("water_sample_t_bot",
"max_lake_depth",
"depth",
"water_sample_ph_bot",
"water_sample_do_bot",
"water_sample_t_surf",
"water_sample_ph_surf",
"water_sample_do_surf")
sd <- sd[names(sd)%in%vars]
table(is.na(sd)) #make sure there are no NAs

ps_table <- ps_table %>%
  filter(row.names(.) %in% row.names(sd))
table(rownames(ps_table)%in%rownames(sd))


adonis_table<-data.matrix(ps_table) 
adonis_dist<-parallelDist::parDist(adonis_table, method = "bray") 
adonis2(adonis_dist ~water_sample_t_bot +
max_lake_depth + 
depth+ 
water_sample_ph_bot+
water_sample_do_bot+
water_sample_t_surf+
water_sample_ph_surf+
water_sample_do_surf, data = sd) 

beep()
```

Permutation test for adonis under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 999

adonis2(formula = adonis_dist ~ water_sample_t_bot + max_lake_depth + depth + water_sample_ph_bot + water_sample_do_bot + water_sample_t_surf + water_sample_ph_surf + water_sample_do_surf, data = sd)
                    Df SumOfSqs      R2      F Pr(>F)    
water_sample_t_bot  33   64.788 0.36332 8.1977  0.001 ***
max_lake_depth       1    1.060 0.00595 4.4269  0.001 ***
depth               40   20.268 0.11366 2.1158  0.001 ***
Residual           385   92.204 0.51707                  
Total              459  178.320 1.00000                  

Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1










## 5. Rel abund of dominant taxa

### a. Caluclate top phyla

#### ii. Subset phyloseq by 26 cm and then glom by Phylum
```{r}
#subset samples less than or equal to 26
ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
ps_tr_26_phy<-tax_glom(ps_tr_26, taxrank = "Phylum",NArm = FALSE)
ps_melt<-psmelt(ps_tr_26_phy)
write.csv(ps_melt, paste0(Sys.Date(),"_RelativeAbundance_AllPhyla.csv"))
beep()
```

#### iii. calculate top phyla
```{r}
ps_melt<-read.csv("2024-01-17_RelativeAbundance_AllPhyla.csv", header=T, row.names=1)

#which phyla go over a threshold on AVERAGE for each bin depth
    pt <- PivotTable$new()
    pt$addData(ps_melt)
    pt$addRowDataGroups("bin_depth") 
    pt$addColumnDataGroups("Phylum") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    
    
    phy_avg_abund <- pt$asDataFrame()
    phy_avg_abund$bin_depth<-rownames(phy_avg_abund)
    phy_avg_abund<-phy_avg_abund[-which(phy_avg_abund$bin_depth=="Total"),]
    phy_avg_abund$Total<-NULL
    phy_avg_abund$bin_depth <- as.numeric(phy_avg_abund$bin_depth)
    phy_avg_abund <- melt(phy_avg_abund, id.vars = "bin_depth")
    
    rm(pt)
    
length(unique(as.character(phy_avg_abund[which(phy_avg_abund$value>0.04),]$variable)))
#10 - 2024-01-17

subphy<-unique(as.character(phy_avg_abund[which(phy_avg_abund$value>0.04),]$variable))
subphy
 # [1] "Acidobacteriota"   "Bacteroidota"      "Chloroflexi"       "Crenarchaeota"    
 # [5] "Cyanobacteria"     "Desulfobacterota"  "Halobacterota"     "Planctomycetota"  
 # [9] "Proteobacteria"    "Verrucomicrobiota"

# number of samples included
length(unique(ps_melt$samp_names))
#429 samples - 2024-01-17

# what percent are these 10 phyla in the entire dataset?
sum(ps_melt[ps_melt$Phylum%in%subphy,]$Abundance)/length(unique(ps_melt$samp_names))
#[1] 0.7065141 - 2024-01-17 total reads

```

proportion of reads of these dominant phyla in each zone
```{r}
#proportion of the dominant phyla in the redox zone
zone<-subset_samples(ps_tr, bin_depth%in%c(0,2,4))
round(sum(colSums(otu_table(subset_taxa(zone, Phylum%in%c("Bacteroidota" ,"Cyanobacteria"  ,  "Proteobacteria","Verrucomicrobiota")))))/sum(colSums(otu_table(zone)))*100, digits=1)
#[1] 33.5 - 2024-01-17

#transition zone
zone<-subset_samples(ps_tr, bin_depth%in%c(6,8,10,12))
round(sum(colSums(otu_table(subset_taxa(zone, Phylum%in%c("Acidobacteriota" ,"Chloroflexi",  "Desulfobacterota" ,"Halobacterota")))))/sum(colSums(otu_table(zone)))*100, digits=1)
#[1] 38.8 -  2024-01-17

#depauperate zone 
zone<-subset_samples(ps_tr, bin_depth%in%c(14,16,18,20,22,24,26))
round(sum(colSums(otu_table(subset_taxa(zone, Phylum%in%c("Crenarchaeota"   ,"Planctomycetota")))))/sum(colSums(otu_table(zone)))*100, digits=1)
#[1] 20.1 - 2024-01-17
```


```{r}
topphy<-read.csv("2024-01-17_RelativeAbundance_AllPhyla.csv", header=T, row.names=1)
topphy<-topphy[topphy$Phylum%in%c("Acidobacteriota" ,  "Bacteroidota" ,    
"Chloroflexi"    ,   "Crenarchaeota"    ,"Halobacterota",
"Cyanobacteria"  ,   "Desulfobacterota" ,
"Planctomycetota" , "Proteobacteria"   ,
"Verrucomicrobiota"),]

ordphy<-c(  "Bacteroidota" ,    
"Cyanobacteria"  ,  "Proteobacteria"   ,
"Verrucomicrobiota",
"Acidobacteriota" ,"Chloroflexi",  "Desulfobacterota" ,"Halobacterota"
 ,"Crenarchaeota"   ,"Planctomycetota")

lake_drives<-unique(topphy$lake_drive)
zone_colors<- c(rep('#018571',4), rep('#C4AD79', 4), rep('#a6611a',3))

vals<-list()
labs<-list()

pdf(paste0("Figures/", Sys.Date(),"_RelAbun_TopPhyla.pdf"), width=13, height=4)
par(mfrow=c(1,13), mar=c(6,6,1,0))
plot(0:26,0:26, bty="n", frame.plot = FALSE, xaxt="n", yaxt="n",ylab = "Depth (cm)", xlab="",ylim=c(26,0), las=1, cex.lab=1.6, pch=19, col="white")
axis(side=2, at= seq(0, 26, by=2), cex.axis=1.6,labels= seq(0, 26, by=2), las=1)
par(mar=c(6,0.5,1,1), xpd=TRUE)
for(i in 1:length(unique(topphy$Phylum))){
  temp<-topphy[topphy$Phylum==ordphy[i],]
  temp<-temp[order(temp$bin_depth,decreasing=T),]
  pt <- PivotTable$new()
    pt$addData(temp)
    pt$addRowDataGroups("bin_depth") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    meanabund <- pt$asDataFrame()
    meanabund$bin_depth<-rownames(meanabund)
    meanabund<-meanabund[-which(meanabund$bin_depth=="Total"),]
    meanabund$bin_depth<-as.numeric(meanabund$bin_depth)
    meanabund<-meanabund[order(meanabund$bin_depth,decreasing = T),]
    plot(temp$Abundance,temp$bin_depth,col="white",ylim=c(26,0),bty="n",xlim=c(0,max(meanabund$Abundance)*1.8),ylab="",xlab="",yaxt="n",xaxt="n",cex.axis=1.6)
    vals[[i]]<-seq(0,(max(meanabund$Abundance)*1.8), length.out=5)
    labs[[i]]<- c("0", as.character(round(vals[[i]][2:5], digits=2)))
    axis(side = 1, at = vals[[i]], labels =labs[[i]], cex.axis=1.6)

    for(l in 1:length(lake_drives)){
  temp2<-temp[temp$lake_drive==lake_drives[l],]  
  temp2<-temp2[order(temp2$bin_depth,decreasing = F),]
  lines(temp2$Abundance,temp2$bin_depth, col="gray")}
    lines(meanabund$Abundance,meanabund$bin_depth, col=zone_colors[i],lwd=4)
}
dev.off()


```



### b. Top families

```{r}
load("WyLakeMicrobes_Phyloseq_16Jan2024.RData")
#subset samples less than or equal to 26
ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
ps_tr_26_fam<-tax_glom(ps_tr_26, taxrank = "Family",NArm = FALSE)
ps_melt<-psmelt(ps_tr_26_fam)
write.csv(ps_melt, paste0(Sys.Date(),"_RelativeAbundance_AllFamilies.csv"))
```

```{r}
ps_melt<-read.csv("2024-01-17_RelativeAbundance_AllFamilies.csv", header=T, row.names=1)
ps_melt$taxtofam<-paste(ps_melt$Phylum, ps_melt$Class, ps_melt$Order, ps_melt$Family, sep = "@")

#which phyla go over a threshold on AVERAGE for each bin depth
    pt <- PivotTable$new()
    pt$addData(ps_melt)
    pt$addRowDataGroups("bin_depth") 
    pt$addColumnDataGroups("taxtofam") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    
    
    fam_avg_abund <- pt$asDataFrame()
    fam_avg_abund$bin_depth<-rownames(fam_avg_abund)
    fam_avg_abund<-fam_avg_abund[-which(fam_avg_abund$bin_depth=="Total"),]
    fam_avg_abund$Total<-NULL
    fam_avg_abund$bin_depth <- as.numeric(fam_avg_abund$bin_depth)
    fam_avg_abund <- melt(fam_avg_abund, id.vars = "bin_depth")
    
    rm(pt)
    

#remove NA@NA
fam_avg_abund<-fam_avg_abund[fam_avg_abund$variable!="NA@NA@NA@NA",]
    

#but only include those that are actually assigned to a family, otherwise you are looking really at unassigned families in specific orders or classes

subfam<-unique(as.character(fam_avg_abund[which(fam_avg_abund$value>0.0138),]$variable))
table((str_split(subfam,pattern = "@", 4, simplify = T)[,4])!="NA")
subfam
#  [1] "Acidobacteriota@Aminicenantia@Aminicenantales@NA"                     
#  [2] "Acidobacteriota@Vicinamibacteria@Vicinamibacterales@NA"               
#  [3] "Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"       
#  [4] "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"              
#  [5] "Chloroflexi@Anaerolineae@RBG-13-54-9@NA"                              
#  [6] "Chloroflexi@Dehalococcoidia@MSBL5@NA"                                 
#  [7] "Chloroflexi@KD4-96@NA@NA"                                             
#  [8] "Crenarchaeota@Bathyarchaeia@NA@NA"                                    
#  [9] "Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
# [10] "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae"            
# [11] "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
# [12] "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae"    
# [13] "Latescibacterota@NA@NA@NA"                                            
# [14] "Nanoarchaeota@Nanoarchaeia@Woesearchaeales@NA"                        
# [15] "Planctomycetota@Phycisphaerae@DG-20@NA"                               
# [16] "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
# [17] "Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group"
# [18] "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
# [19] "Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae"    
# [20] "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
# [21] "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"           
# [22] "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
# [23] "Sva0485@NA@NA@NA"                                                     
# [24] "Thermoplasmatota@Thermoplasmata@Marine Benthic Group D and DHVEG-1@NA"
# [25] "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"           
# [26] "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae"



subfam<-c("Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"    
, "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"              
, "Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
, "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae"            
, "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
, "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae"    
, "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
,"Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group"
, "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"           
, "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
, "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"           
, "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae"  )

sum(ps_melt[ps_melt$taxtofam%in%subfam,]$Abundance)/length(unique(ps_melt$samp_names))
#[1] 0.2705308 - 2024-01-17
```

### i. Plot
```{r}
topfam<-read.csv("2024-01-17_RelativeAbundance_AllFamilies.csv", header=T, row.names=1)
topfam$taxtofam<-paste(topfam$Phylum, topfam$Class,topfam$Order, topfam$Family, sep = "@")
topfam<-topfam[topfam$taxtofam%in%c("Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"   
, "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"              
, "Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
, "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae"            
, "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
, "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae"    
, "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
,"Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group"
, "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"           
, "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
, "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"           
, "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae"  ),]

#Look at which ones are archaea
topfam %>% select(Kingdom, taxtofam) %>% unique()

#alphabetically ordered by family name
ordered<-c("Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae" 
, "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae" 
, "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
, "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae" 
,"Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
, "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"      

, "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"
,"Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"   
, "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
, "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae" 
, "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"      

, "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
,"Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group")

lake_drives<-unique(topfam$lake_drive)

zone_colors<- c(rep('#018571',8), rep('#C4AD79', 5), rep('#a6611a',2))

vals<-list()
labs<-list()

pdf(paste0("Figures/", Sys.Date(),"_RelAbun_TopFam.pdf"), width=14, height=4)
par(mfrow=c(1,16), mar=c(6,6,1,0))
plot(0:26,0:26, bty="n", frame.plot = FALSE, xaxt="n", yaxt="n",ylab = "Depth (cm)", xlab="",ylim=c(26,0), las=1, cex.lab=1.6, pch=19, col="white")
axis(side=2, at= seq(0, 26, by=2), cex.axis=1.6,labels= seq(0, 26, by=2), las=1)
par(mar=c(6,0.5,1,1), xpd=TRUE)
for(i in 1:length(unique(topfam$taxtofam))){
  temp<-topfam[topfam$taxtofam==ordered[i],]
  temp<-temp[order(temp$bin_depth,decreasing=T),]
  pt <- PivotTable$new()
    pt$addData(temp)
    pt$addRowDataGroups("bin_depth") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    meanabund <- pt$asDataFrame()
    meanabund$bin_depth<-rownames(meanabund)
    meanabund<-meanabund[-which(meanabund$bin_depth=="Total"),]
    meanabund$bin_depth<-as.numeric(meanabund$bin_depth)
    meanabund<-meanabund[order(meanabund$bin_depth,decreasing = T),]
    plot(temp$Abundance,temp$bin_depth,col="white",ylim=c(26,0),bty="n",xlim=c(0,max(meanabund$Abundance)*1.8),ylab="",xlab="",yaxt="n",xaxt="n", cex.axis=1.6)
        vals[[i]]<-seq(0,(max(meanabund$Abundance)*1.8), length.out=5)
    labs[[i]]<- c("0", as.character(round(vals[[i]][2:5], digits=2)))
    axis(side = 1, at = vals[[i]], labels =labs[[i]], cex.axis=1.6)

    for(l in 1:length(lake_drives)){
  temp2<-temp[temp$lake_drive==lake_drives[l],]  
  temp2<-temp2[order(temp2$bin_depth,decreasing = F),]
  lines(temp2$Abundance,temp2$bin_depth, col="gray")}
    lines(meanabund$Abundance,meanabund$bin_depth, col=zone_colors[i],lwd=4)
}
dev.off()


```




### c. Elemental analyses
```{r}
load("WyLakeMicrobes_Phyloseq_16Jan2024.RData")

ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
ESV<-as.data.frame(ps_tr_26@otu_table@.Data)
meta_sed_26<-metadata[metadata$samp_names%in%names(ESV),]

depthbins<-sort(unique(meta_sed_26$bin_depth),decreasing=F)

summary<-data.frame(bin_depth=NULL,
                    c13_mean=NULL,c13_sd=NULL,
                    c_perc_mean=NULL,c_perc_sd=NULL,
                    cn_mean=NULL,cn_sd=NULL)
i=1
for(i in 1:length(depthbins)){
  tmp<-meta_sed_26[meta_sed_26$bin_depth==depthbins[i],]
  tmp2<-data.frame(bin_depth=depthbins[i],
                    c13_mean=mean(tmp$d_13_c,na.rm=T),c13_sd=sd(tmp$d_13_c,na.rm=T),
                    c_perc_mean=mean(tmp$c_perc,na.rm=T),c_perc_sd=sd(tmp$c_perc,na.rm=T),
                   cn_mean=mean(tmp$cn,na.rm=T),cn_sd=sd(tmp$cn,na.rm=T))
  summary<-rbind(summary,tmp2)
}


# average CONISS across all samples
ESV<-as.data.frame(ps_tr@otu_table@.Data)
ESV<-t(ESV)

ESV_meta<-as.matrix(ps_tr@sam_data)
ESV_meta<-as.data.frame(ESV_meta)
ESV_meta$bin_depth<-as.numeric(ESV_meta$bin_depth)

#create a mean relative abundance of each ESV for each depth
mean_abundances<-data.frame()
i=1
centimeters<-c(0,2,4,6,8,10,12,14,16,18,20,22,24,26)
  sub<-ESV[rownames(ESV)%in%(ESV_meta[ESV_meta$bin_depth==centimeters[1] & is.na(ESV_meta$bin_depth)==FALSE,]$samp_names),]
  mean_abundances<-as.data.frame(colMeans(sub))
  colnames( mean_abundances)[1]<-centimeters[i]
for(i in 2:length(centimeters)){
  sub<-ESV[rownames(ESV)%in%(ESV_meta[ESV_meta$bin_depth==centimeters[i] & is.na(ESV_meta$bin_depth)==FALSE,]$samp_names),]
  means<-as.data.frame(colMeans(sub))
  colnames(means)[1]<-centimeters[i]
  mean_abundances<-cbind(mean_abundances,means)
}

tma<-as.matrix(t(mean_abundances))
dist<-vegdist(tma)
clust<-chclust(dist)
```

#CODE BELOW NOT UPDATED

Elemental measurements
```{r}
pdf(paste0("Figures/", Sys.Date(),"_RelAbun_Elemental.pdf"), width=13, height=4)  
seq<-seq(2,6,2)
lab<-c("d13C", "%C","C:N")
lines<-3.5
sed_col<-"#616161"
i=1


par(mfrow=c(1,13), mar=c(6,6,1,0))
plot(0:26,0:26, bty="n", frame.plot = FALSE, xaxt="n", yaxt="n",ylab = "Depth (cm)", xlab="",ylim=c(26,0), las=1, cex.lab=1.6, pch=19, col="white")
axis(side=2, at= seq(0, 26, by=2), cex.axis=1.6,labels= seq(0, 26, by=2), las=1)
par(mar=c(6,0.5,1,1), xpd=TRUE)

for(i in 1:length(labs)){
  sum_temp<-summary[,c(1,seq[i],seq[i]+1)]
  sum_temp$sdp<-sum_temp[,2]+sum_temp[,3]
  sum_temp$sdm<-sum_temp[,2]-sum_temp[,3]
  plot(sum_temp[,2],sum_temp$bin_depth,ylim=c(26,0),xlim=c(min(sum_temp$sdm),max(sum_temp$sdp)),type="l",bty="n", yaxt="n", ylab="",col="white",lwd=2, xlab="", cex.axis=1.6)
    mtext(lab[i],side=1,line=3.5, cex=1.1)
polygon(x = c(sum_temp$sdp,rev(sum_temp$sdm)),  # X-Coordinates of polygon 
        y = c(sum_temp$bin_depth, rev(sum_temp$bin_depth)),    # Y-Coordinates of polygon
        col = paste("#616161","50",sep=""), 
        border=paste("#616161","50",sep="")) 
lines(sum_temp[,2],sum_temp$bin_depth, col="#616161",lwd=3)
}
 dev.off()
   
```

CONISS
```{r}

pdf("Figures/RelAbun_CONISS_26June2023.pdf", width=13, height=4)
par(mfrow=c(1,13), mar=c(5.5,6,1.5,0))

par(mar=c(5.5,2,1.5,1))
 plot(clust, xvar=as.numeric(clust[["labels"]]),ylim=c(0,3.2), xaxt="n",hang=-1, cex=1.6, cex.lab=1.6, cex.main=1.8, horiz=TRUE, x.rev=TRUE) 
  mtext("Distance",side=1,line=3, cex=1.1)
  mtext("CONISS", side=3, line=0, cex=1.1)
  axis(side=1,at=c(0,1,2,3),labels=c(0,1,2,3), cex.axis=1.6)
dev.off()

```





## 6. Island Biogeography for poster

Merge in the lake area measurements from Google Earth Pro polygons, plot whether lake depth increases with lake area. Generally true, but some exceptions of large shallow lakes. 
```{r}
lkarea<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/metadata_lakearea_27May2023.csv",header=T)

meta_merged<-merge(metadata,lkarea,by="lake_name")

#plot lake area by lake depth

uniq_lake<- meta_merged %>% select(lake_name,lakearea_squaremeters,max_lake_depth)
uniq_lake<-unique(uniq_lake)
plot(uniq_lake$lakearea_squaremeters,uniq_lake$max_lake_depth, pch=16, xlab="Lake area (sq m)",ylab="Max. lake depth")

```


```{r}
ESV<-as.data.frame(otu_table(ps))
ESV<-t(ESV)

#calculate the number of ESVs for each sediment core
LkDr_ESVs<-data.frame(lake_drive=NULL, num_samples=NULL,num_ESVs=NULL)
i=1
for(i in 1:length(unique(metadata$lake_drive))){
        #for each lake_drive, grab all the sample names in metadata
        samples<-metadata[metadata$lake_drive==unique(metadata$lake_drive)[i],]$samp_names
        #pull out number of ESVs from the table 
        sub_ESV<-as.data.frame(ESV[rownames(ESV)%in%samples,])  
        colsumsESV<-as.data.frame(colSums(sub_ESV))
       LkDr_ESVs<-rbind(LkDr_ESVs,data.frame(lake_drive=unique(metadata$lake_drive)[i], num_samples=length(samples),num_ESVs=colSums(colsumsESV != 0)))
}

#this didn't work if just one sample so updated the last two manually

LkDr_ESVs[47,3]<-2003
LkDr_ESVs[48,3]<-3570

```

Something to think about is that some lakes have MORE sediment samples, can plot this
```{r}
plot(LkDr_ESVs$num_samples, LkDr_ESVs$num_ESVs, pch=16, ylab="Total ESVs per core", xlab="Sediment samples")
#cores must have at least 5 samples

#remove lake_drives with less than 5 samples
LkDr_ESVs<-LkDr_ESVs[LkDr_ESVs$num_samples>4,]

#merge with lake metadata
uniq_lake<- meta_merged %>% select(lake_name,lakearea_squaremeters,max_lake_depth, lake_drive, mountain_range)
uniq_lake<-unique(uniq_lake)

#merge with lake metadata
isl_bio<-merge(LkDr_ESVs,uniq_lake, by="lake_drive")

isl_bio$col<-as.factor(isl_bio$mountain_range)
isl_bio$col<-as.numeric(isl_bio$col)
isl_bio$lakearea_squarekm<-isl_bio$lakearea_squaremeters/1000000
```

plot number of taxa with lake depth, lake size, and lake depth x size
```{r}
cols<-met.brewer(name="Egypt", n=4, type="discrete")
cols<-c("#000000",cols[1],cols[4],cols[2],cols[3])
full_cols<-cols
#cols<-paste(cols,"99", sep="")
point_types<-c(16,17,18,19,20)



pdf("Figures/ESVs_lakearea_29May2023.pdf", height=4,width=5)
par(mar=c(4,6,2,2))
expression<-expression(Lake ~ area ~ (km^2))
plot(isl_bio$lakearea_squarekm,isl_bio$num_ESVs, pch=16, cex=2, ylab="Exact sequence variants \n(ESVs) per core" ,col=cols[isl_bio$col], xlab=expression)
legend("topright",title="Mountain range", c("Beartooth" , "Bighorn"  ,  "Snowy" ,     "Wind River"), bty="n",pt.cex=2, col=full_cols, pch=16)
dev.off()

pdf("Figures/ESVs_lakevolume_29May2023.pdf", height=4,width=5)
par(mar=c(4,6,2,2))
expression<-expression(Lake ~ volume ~ (m^3))
plot((isl_bio$lakearea_squaremeters * isl_bio$max_lake_depth),isl_bio$num_ESVs, cex=2,pch=16, ylab="Exact sequence variants \n(ESVs) per core",col=cols[isl_bio$col], xlab=expression)
legend("topright",title="Mountain range", c("Beartooth" , "Bighorn"  ,  "Snowy" ,     "Wind River"), bty="n",pt.cex=2, col=full_cols, pch=16)
dev.off()
```




```{r}
plot(isl_bio$max_lake_depth,isl_bio$num_ESVs,  ylab="ESVs per core", xlab="Lake depth (m)", col=cols[isl_bio$col],pch=point_types[isl_bio$col])
```



## 7. Stats for manuscript
```{r}
# what is the total number of cores and lakes?
length(unique(metadata$lake_id)) # 36 lakes
length(unique(metadata$lake_drive)) # 48 cores 

#average and range of sediment depth for cores? 
lake_drives<-unique(metadata$lake_drive)
maxd<-NULL
for(i in 1:length(lake_drives)){
        tmp<-metadata[metadata$lake_drive==lake_drives[i],]
       maxd <-c(maxd,max(tmp$depth))
}
mean(maxd)
#21.83333
max(maxd)
#88
min(maxd)   
#2

min(metadata$max_lake_depth)
max(metadata$max_lake_depth)
#0.5-19m

#how many lakes greater than or equal to 26 cm deep? 
table(maxd>=26)
22/(26+22)
#0.4583333 of the lakes were at or greater than 26 cm 

# how many samples are less than or equal to 26 cm
nrow(metadata[metadata$depth<=26,])
# 429 samples

# how many samples greater than 26 cm
478-429
#49 - 28June2023

meta_sed_26<-metadata[metadata$depth<=26,]

# JVE notes - I need to say how many samples are measured in ALL samples, not just 26 cm 

# #how many samples <=26 have elemental measurements?
# sub<-meta_sed_26[is.na(meta_sed_26$d_13_c)==FALSE,]
# nrow(sub)
# #121 samples
# 
# #how many cores and samples have C:N data
# length(unique(ps@sam_data[is.na(ps@sam_data$cn)==FALSE,]$lake_id))
# # 28
# #samples less than 26 cm that have CN data
# nrow(meta_sed_26[is.na(meta_sed_26$cn)==FALSE,])
# # 262 samples have C:N, C%, N%
# 
# #how many cores have d13C data
# length(unique(ps@sam_data[is.na(ps@sam_data$d_13_c)==FALSE,]$lake_id))
# # 13
# #how many samples <=26 have elemental measurements?
# nrow(meta_sed_26[is.na(meta_sed_26$d_13_c)==FALSE,])
# #121 samples

# so INSTEAD - did this:
# all the true
table(is.na(metadata$pH)==F)
#278

table(is.na(metadata$cn)==F)
#282

table(is.na(metadata$d_13_c)==F)
#130



#where are those from?
unique(ps@sam_data[is.na(ps@sam_data$d_13_c)==FALSE,]$mountain_range)
#just the Snowies

#Values for elemental measurements for results section



print("surface")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(0,2,4),]$c_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(0,2,4),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(0,2,4),]$cn, na.rm=T),digits=1)


print("replacement")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12),]$c_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12),]$cn, na.rm=T),digits=2)

print("depauperate")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(14,16,18,20,22,24,26),]$c_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(14,16,18,20,22,24,26),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(14,16,18,20,22,24,26),]$cn, na.rm=T),digits=1)

print("replacement and depauperate")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22,24,26),]$c_perc, na.rm=T),digits=1)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22,24,26),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22,24,26),]$cn, na.rm=T),digits=2)

# 28June2023
# [1] "surface"
# [1] 13.09
# [1] 1.34
# [1] "replacement"
# [1] 11.46
# [1] 1.02
# [1] "depauperate"
# [1] 11.34
# [1] 0.95
# [1] "replacement and depauperate"
# [1] 11.40
# [1] 0.98


# a positive shift in carbon isotopic composition (Î´13C) of occurred from depths 0-4 cm
sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(0),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
#[1] -30.0454 - 28June2023
sd(sub$d_13_c)
#[1] 2.124595 - 28June2023


sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(4),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
sd(sub$d_13_c)
#[1] 4.420052 - 28June2023
(-30.0454) - (-25.2764)
#-4.769 (round to 4.77%) - 28June2023

sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
#[1] -24.65961 - 28June2023
sd(sub$d_13_c)
#[1] 4.301652  - 28June2023

sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(24,26),]
nrow(sub)
#10 samples at depths 24 and 26 with isotopic data
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
#[1] -26.081  - 28June2023
sd(sub$d_13_c)
#[1] 2.139629  - 28June2023


# range of elevations
range(metadata$elevation_meters,na.rm=T) #NAs are the blanks that don't have elevations
#2032 3350
#subset for 26 cm cutoff elevation
range(meta_sed_26$elevation_meters,na.rm=T) 
#2032 3350 (same)

#range of temperatures

#these are the same for the 26 cm and less samples and the entire dataset
range(metadata$water_sample_t_bot, na.rm=T)
#3.8 20.1
#these are the same for the 26 cm and less samples and the entire dataset
range(metadata$water_sample_t_surf, na.rm=T)
#11.3 20.7
range(metadata$water_sample_ph_bot, na.rm=T)
#5.39 9.68
range(metadata$water_sample_ph_surf, na.rm=T)
#6.83 9.63
range(metadata$water_sample_do_bot, na.rm=T)
#-0.06 12.14
range(metadata$water_sample_do_surf, na.rm=T)
#3.14 8.23

# Started with 555 samples
# ended with 478 samples

# How many lakes cored in 2018 and 2017
sub2017<-metadata[metadata$year_sample=="2017",]
length(unique(sub2017$lake_name))
sub2018<-metadata[metadata$year_sample=="2018",]
length(unique(sub2018$lake_name))

#how many cores from the Snowies
sub<-metadata[metadata$mountain_range=="Snowy",]
length(unique(sub$lake_name))

#looking for how many lakes were cored more than once (eight)
sort(unique(sub$lake_drive))

#bighorn
sub<-metadata[metadata$mountain_range=="Bighorn",]
length(unique(sub$lake_name))
sub<-metadata[metadata$mountain_range=="Beartooth",]
length(unique(sub$lake_name))
sub<-metadata[metadata$mountain_range=="Wind River",]
length(unique(sub$lake_name))


#create supplementary table 1

ST1<-metadata[,names(metadata)%in%c("lake_id"                
, "drive"                  
,"lake_name"              
,"lake_number"            
, "year_sample"            
, "mountain_range"         
, "latitude"               
, "longitude"              
, "elevation_meters"       
, "max_lake_depth"
,"water_sample_depth_surf"
, "water_sample_ph_surf"   
,"water_sample_do_surf"   
, "water_sample_t_surf"    
, "water_sample_depth_bot" 
,"water_sample_ph_bot"    
, "water_sample_do_bot"    
,"water_sample_t_bot")]

ST1<-unique(ST1)

write.csv(ST1,"SupplementaryTable1_28June2023.csv")


#what percent of reads are archaea?
arch<-subset_taxa(ps, Kingdom=="Archaea")
sum(rowSums(arch@otu_table))/sum(rowSums(ps@otu_table))
#[1] 0.177471 - 28June2023 this is the only new number after rerunning in June

# additional generalizations between shallow, warm and cool, deep lakes

#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata

require(GGally)

metadata<-metadata[order(match(rownames(metadata),colnames(ps_tr@otu_table@.Data))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

cor(metadata_sub)

which(is.na(metadata_sub[3]==T))
metadata_sub[which(is.na(metadata_sub[3]==T)),]

ggpairs(metadata_sub)


#alphaproteobacteria (nitrogen reducers) decline with depth
sub<-subset_taxa(ps_tr, Class=="Alphaproteobacteria")
sub %>% group_by (bin_depth) %>% summarize_at(vars(Abundance), list(abundance = mean)) %>% plot()
```

## 8. Distance decay
```{r}
#load data
#used transformed data
OTU<-t(as.data.frame(ps_tr@otu_table@.Data))
#calculate Bray-Curtis similarity between all samples
comm.dist <- 1 - vegdist(OTU)

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),rownames(OTU))),]
table(rownames(OTU)==rownames(metadata)) #all true

#Lat&lon to distance in meters
xy <- data.frame(X = metadata$longitude, Y = metadata$latitude)
rownames(xy)<-metadata$samp_names
dist_m_output<-distm(xy)
rownames(dist_m_output)<-rownames(xy)
names(dist_m_output)<-rownames(xy)
dist_m_output<-as.dist(dist_m_output)


#transform all distance matrices into dataframes with pairwise comparisons
coord.dist.ls<-as.matrix(dist_m_output)
coord.dist.ls[upper.tri(coord.dist.ls, diag = T)] <- NA
coord.dist.ls<-reshape2::melt(coord.dist.ls, na.rm=T)
names(coord.dist.ls)<-c("s1_samp_names","s2_samp_names","geo_dist")


comm.dist.ls<-as.matrix(comm.dist)
comm.dist.ls[upper.tri(comm.dist.ls, diag = T)] <- NA
comm.dist.ls<-reshape2::melt(comm.dist.ls, na.rm=T)
names(comm.dist.ls)<-c("s1_samp_names","s2_samp_names","comm")


#check the names of these match
table(coord.dist.ls[,1]==comm.dist.ls[,1]) #all true
table(coord.dist.ls[,2]==comm.dist.ls[,2]) #all true

#create df with similarity of community and distance
comps<-data.frame(comm.dist.ls)
comps$geo_dist<-coord.dist.ls$geo_dist
comps$s1_samp_names<-as.character(comps$s1_samp_names)
comps$s2_samp_names<-as.character(comps$s2_samp_names)

#add zone into metadata
metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

#merge in metadata to table
metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

comps<-merge(comps, metadata_s1, by="s1_samp_names")
comps<-merge(comps, metadata_s2, by="s2_samp_names")

#remove metadata notes
comps$s1_notes<-NULL
comps$s2_notes<-NULL
comps$s1_Notes_sed_water_wt<-NULL
comps$s2_Notes_sed_water_wt<-NULL
comps$s1_Notes_carbon_nitrogen<-NULL
comps$s2_Notes_carbon_nitrogen<-NULL
comps$s1_Notes._lake_sed_pH<-NULL
comps$s2_Notes._lake_sed_pH<-NULL

# add in centimeters into the distance
comps$abs_cm<-rep(NA, nrow(comps))
comps$s1_depth<-as.numeric(comps$s1_depth)
comps$s2_depth<-as.numeric(comps$s2_depth)
i=1
for(i in 1:nrow(comps)){
  ifelse(comps$s1_lake_drive[i]==comps$s2_lake_drive[i],comps$abs_cm[i]<-abs(comps$s2_depth[i]-comps$s1_depth[i]),NA)
}

#this one takes forever and adds 1 meter to cores within the same lake
comps$dist_1m_forsamelake<-rep(NA,nrow(comps))
i=1
for(i in 1:nrow(comps)){
 if(comps$s1_lake_name[i]==comps$s2_lake_name[i] & comps$s1_lake_drive[i] != comps$s2_lake_drive[i]){comps$dist_1m_forsamelake[i]<-comps$geo_dist[i]+1}else{comps$dist_1m_forsamelake[i]<-comps$geo_dist[i]}
}


#one sample with 2 replicates, so put in 0.001 for the dist_cm_core column
comps<-comps[order(comps$abs_cm,decreasing=F),]
which(names(comps)=="abs_cm")
comps[1,which(names(comps)=="abs_cm")]<-0.001
#check
comps[1,]

rm(comm.dist.ls)
rm(coord.dist.ls)
rm(metadata_s1)
rm(metadata_s2)
rm(OTU)
rm(xy)
rm(comm.dist)
rm(dist_m_output)
rm(i)

#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(ps_tr@otu_table@.Data))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

daisy.mat <- as.dist(as.matrix(daisy(scale(metadata_sub), metric="gower")))

env_distance<-as.matrix(daisy.mat)
env_distance[upper.tri(env_distance, diag = T)] <- NA
env_distance<-reshape2::melt(env_distance, na.rm=T)
names(env_distance)<-c("s1_samp_names","s2_samp_names","env_dist")

env_distance$s1_samp_names<-as.character(env_distance$s1_samp_names)
env_distance$s2_samp_names<-as.character(env_distance$s2_samp_names)

comps<-comps[order(comps$s1_samp_names,comps$s2_samp_names),]
env_distance<-env_distance[order(env_distance$s1_samp_names,env_distance$s2_samp_names),]

table(comps$s1_samp_names==env_distance$s1_samp_names) #all TRUE
table(comps$s2_samp_names==env_distance$s2_samp_names) #all TRUE

comps$env_dist<-env_distance$env_dist
rm(env_distance)

comps$geo_dist_km<-comps$geo_dist/1000

#overwrite file
#write.csv(comps, "pairwise_comparisons_29June2029.csv")

```

### iii. community similarity decay

summary figure (horizons not broken out)
```{r}
comps<-read.csv("pairwise_comparisons_29June2029.csv", header=T, row.names=1)

model_result<-list()
theme_comm<-theme_classic()+
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
              axis.text=element_text(size=13), #change font size of axis text
              axis.title=element_text(size=15), #change font size of axis titles  
              axis.title.x = element_text(vjust=-0.3),
              axis.title.y = element_text(margin = margin(r = 10)))
ggplt<-list()
#sediment distance from an individual core
sub<-comps[is.na(comps$abs_cm)==FALSE,]
sub<-sub[sub$s1_zone%in%c("A","B","C") & sub$s2_zone%in%c("A","B","C"),]
table(sub$s1_lake_drive==sub$s2_lake_drive)
#2081 comparisons (29June2023)


Data<-data.frame(x=sub$abs_cm,y=sub$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data) 
#dat_gam=gam(y~s(x), data=Data)
model_result[[1]]<-summary(dat_gam)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit

gam.check(dat_gam)

## plot
ggplt[[1]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
                geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                           col="black", alpha = 0.7) +
        geom_line(linewidth=1.5) + labs(x = "Sediment distance (cm)", y = "Community similarity (1-Bray)")+
        scale_x_continuous(breaks=seq(0,26,4))+
        ylim(0,0.8)+
        annotate("text", x=(26*0.99), y=0.8, label= "A", size=7)+
        annotate("text", x=(26*0.75), y=0.7,  label="Dev exp = 32.1%", size=5) +
        theme_comm



sub_bind<-NULL
#Geographic distance#
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        sub_bind<-rbind(sub_bind,sub)
}
        Data<-data.frame(x=sub_bind$geo_dist_km,y=sub_bind$comm)
        Data<-Data[order(Data$x),]
        dat_gam=gam(y~s(x, k=4), data=Data)
      # dat_gam=gam(y~s(x), data=Data)
        model_result[[2]]<-summary(dat_gam)
        pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
        Data$fit<-pred$fit
        Data$se<-pred$se.fit
         model_result[[2]]
        

ggplt[[2]]<-ggplot(data =Data , aes(x = x, y = fit)) +
        geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
        geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                    col="black", alpha = 0.7) +
        geom_line(linewidth=1.5) + labs(x = "Distance (km)", y = "")+
        scale_x_continuous(breaks=seq(0,500,100))+
        annotate("text", x=(500*0.99), y=0.8, label= "B", size=7)+
        annotate("text", x=(500*0.75), y=0.7, label="Dev exp = 8.8%",  size=5) +
        ylim(0,0.8)+
        theme_comm  


sub_bind<-NULL
#environmental distance distance#
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        sub_bind<-rbind(sub_bind,sub)
}
Data<-data.frame(x=sub_bind$env_dist,y=sub_bind$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data)
#dat_gam=gam(y~s(x), data=Data)
model_result[[3]]<-summary(dat_gam)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit
model_result[[3]]

   ggplt[[3]]<-ggplot(data =Data , aes(x = x, y = fit)) +
           geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
           geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                       col="black", alpha = 0.7) +
   geom_line(linewidth=1.5) + labs(x = "Environmental dissimilarity", y = "")+
   scale_x_continuous(breaks=seq(0,0.73,0.1))+
           annotate("text", x=(0.73*0.99), y=0.8, label= "C", size=7)+
        annotate("text", x=(0.73*0.75), y=0.7, label="Dev exp = 17.6%", size=5) +
           ylim(0,0.8)+
           theme_comm


pdf("Figures/CommSimmDecay_14Aug2023.pdf", height = 3.5, width= 11)
ggplt[[1]]+ ggplt[[2]] + ggplt[[3]] + plot_layout(ncol = 3)
dev.off()



model_result[[1]]
model_result[[2]]
model_result[[3]]

```

without labels (A B C and dev explained)

```{r}
comps<-read.csv("pairwise_comparisons_29June2029.csv", header=T, row.names=1)

model_result<-list()
theme_comm<-theme_classic()+
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
              axis.text=element_text(size=13), #change font size of axis text
              axis.title=element_text(size=15), #change font size of axis titles  
              axis.title.x = element_text(vjust=-0.3),
              axis.title.y = element_text(margin = margin(r = 10)))
ggplt<-list()
#sediment distance from an individual core
sub<-comps[is.na(comps$abs_cm)==FALSE,]
sub<-sub[sub$s1_zone%in%c("A","B","C") & sub$s2_zone%in%c("A","B","C"),]
table(sub$s1_lake_drive==sub$s2_lake_drive)
#2081 comparisons (29June2023)


Data<-data.frame(x=sub$abs_cm,y=sub$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data) 
model_result[[1]]<-summary(dat_gam)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit

gam.check(dat_gam)

## plot
ggplt[[1]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
                geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                           col="black", alpha = 0.7) +
        geom_line(linewidth=1.5) + labs(x = "Sediment distance (cm)", y = "Community similarity (1-Bray)")+
        scale_x_continuous(breaks=seq(0,26,4))+
        ylim(0,0.8)+
        theme_comm



sub_bind<-NULL
#Geographic distance#
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        sub_bind<-rbind(sub_bind,sub)
}
        Data<-data.frame(x=sub_bind$geo_dist_km,y=sub_bind$comm)
        Data<-Data[order(Data$x),]
        dat_gam=gam(y~s(x, k=4), data=Data)
        model_result[[2]]<-summary(dat_gam)
        pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
        Data$fit<-pred$fit
        Data$se<-pred$se.fit
         model_result[[2]]
        

ggplt[[2]]<-ggplot(data =Data , aes(x = x, y = fit)) +
        geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
        geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                    col="black", alpha = 0.7) +
        geom_line(linewidth=1.5) + labs(x = "Distance (km)", y = "")+
        scale_x_continuous(breaks=seq(0,500,100)) +
        ylim(0,0.8)+
        theme_comm  


sub_bind<-NULL
#environmental distance distance#
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        sub_bind<-rbind(sub_bind,sub)
}
Data<-data.frame(x=sub_bind$env_dist,y=sub_bind$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data)
model_result[[3]]<-summary(dat_gam)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit
model_result[[3]]

   ggplt[[3]]<-ggplot(data =Data , aes(x = x, y = fit)) +
           geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
           geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                       col="black", alpha = 0.7) +
   geom_line(linewidth=1.5) + labs(x = "Environmental dissimilarity", y = "")+
   scale_x_continuous(breaks=seq(0,0.73,0.1)) +
           ylim(0,0.8)+
           theme_comm


pdf("Figures/CommSimmDecay_nolabs_5Jan2024.pdf", height = 3.5, width= 11)
ggplt[[1]]+ ggplt[[2]] + ggplt[[3]] + plot_layout(ncol = 3)
dev.off()

model_result[[1]]
model_result[[2]]
model_result[[3]]
```


supplementary figure - GAMS with different horizons
```{r}
theme_comm<-theme_classic()+
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
              axis.text=element_text(size=13), #change font size of axis text
              axis.title=element_text(size=15), #change font size of axis titles  
              axis.title.x = element_text(vjust=-0.3),
              axis.title.y = element_text(margin = margin(r = 10)))
ggplt<-list()
#sediment distance from an individual core
sub<-comps[is.na(comps$abs_cm)==FALSE,]
sub<-sub[sub$s1_zone%in%c("A","B","C") & sub$s2_zone%in%c("A","B","C"),]
table(sub$s1_lake_drive==sub$s2_lake_drive)
#2081 comparisons (16 Feb 2023)


Data<-data.frame(x=sub$abs_cm,y=sub$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit

## plot
ggplt[[1]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                geom_point(data =  Data, aes(x = x, y = y), size=1.5, alpha=0.3) +
                geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                            alpha = 0.3) +
        geom_line(linewidth=1.5) + labs(x = "Sediment distance (cm)", y = "Community similarity (1-Bray)")+
        scale_x_continuous(breaks=seq(0,26,4))+
        ylim(0,0.8)+
        theme_comm





#geographic distance
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        Data<-data.frame(x=sub$geo_dist_km,y=sub$comm)
        Data<-Data[order(Data$x),]
        dat_gam=gam(y~s(x, k=4), data=Data)
        pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
        Data$fit<-pred$fit
        Data$se<-pred$se.fit
        
        if(i==1){     
                ggplt[[2]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                        geom_point(data =  Data, aes(x = x, y = y), size=1.5, col=adjustcolor(c('#018571','#C4AD79','#a6611a')[i], alpha.f = 0.30)) +
                        geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                                    alpha = 0.3) +
                        geom_line(linewidth=1.5) + labs(x = "", y = "")+
                        scale_x_continuous(breaks=seq(0,500,100))+
                        ylim(0,0.8)+
                        theme_comm
        }
        if(i==2){
                ggplt[[3]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                        geom_point(data =  Data, aes(x = x, y = y), size=1.5, col=adjustcolor(c('#018571','#C4AD79','#a6611a')[i], alpha.f = 0.30)) +
                        geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                                    alpha = 0.3) +
                        geom_line(linewidth=1.5) + labs(x = "", y = "Community similarity (1-Bray)")+
                        scale_x_continuous(breaks=seq(0,500,100))+
                        ylim(0,0.8)+
                        theme_comm
        }
        if(i==3){
                ggplt[[4]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                        geom_point(data =  Data, aes(x = x, y = y), size=1.5, col=adjustcolor(c('#018571','#C4AD79','#a6611a')[i], alpha.f = 0.30)) +
                        geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                                    alpha = 0.3) +
                        geom_line(linewidth=1.5) + labs(x = "Distance (km)", y = "")+
                        scale_x_continuous(breaks=seq(0,500,100))+
                        ylim(0,0.8)+
                        theme_comm  
        }}

#environmental dissimilarity
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        Data<-data.frame(x=sub$env_dist,y=sub$comm)
        Data<-Data[order(Data$x),]
        dat_gam=gam(y~s(x, k=4), data=Data)
        pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
        Data$fit<-pred$fit
        Data$se<-pred$se.fit
        
if(i==1){     
        ggplt[[5]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                geom_point(data =  Data, aes(x = x, y = y), size=1.5, col=adjustcolor(c('#018571','#C4AD79','#a6611a')[i], alpha.f = 0.30)) +
                geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                            alpha = 0.3) +
                geom_line(linewidth=1.5) + labs(x = "", y = "")+
               scale_x_continuous(breaks=seq(0,0.73,0.1))+
                ylim(0,0.8)+
                theme_comm
}
if(i==2){
   ggplt[[6]]<-ggplot(data =Data , aes(x = x, y = fit)) +
           geom_point(data =  Data, aes(x = x, y = y), size=1.5, col=adjustcolor(c('#018571','#C4AD79','#a6611a')[i], alpha.f = 0.30)) +
           geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                       alpha = 0.3) +
   geom_line(linewidth=1.5) + labs(x = "", y = "")+
   scale_x_continuous(breaks=seq(0,0.73,0.1))+
           ylim(0,0.8)+
           theme_comm
}
if(i==3){
   ggplt[[7]]<-ggplot(data =Data , aes(x = x, y = fit)) +
           geom_point(data =  Data, aes(x = x, y = y), size=1.5, col=adjustcolor(c('#018571','#C4AD79','#a6611a')[i], alpha.f = 0.30)) +
           geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                       alpha = 0.3) +
   geom_line(linewidth=1.5) + labs(x = "Environmental dissimilarity", y = "")+
   scale_x_continuous(breaks=seq(0,0.73,0.1))+
           ylim(0,0.8)+
           theme_comm
}}

pdf("Figures/Fig5_CommunityAssembly_BC_16Feb2023.pdf",height=7,width=7)
ggplt[[2]]+ ggplt[[3]]+ggplt[[4]]+ggplt[[5]]+ggplt[[6]]+ ggplt[[7]]+ 
        plot_layout(ncol = 2, byrow = F)
dev.off()

pdf("Figures/Fig5_CommunityAssembly_A_16Feb2023.pdf",height=2.4,width=3.3)
ggplt[[1]]
dev.off()


```




## 9. Test for phylogenetic signal (Pearman code)

Subset ESV table for ESVs with 10+ reads for computational tractability

```{bash}
rsync jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylogenetic_tree/ESVs_with10ormorereads_output_27May2023_muscled.nwk /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes

```


I can't to this with 28,480 ESVs (ESVs with 10+ reads, so will use the most abundant ESVs instead)

```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
all_depths<-NULL
i=1
cm<-unique(ps_tr@sam_data$bin_depth)
for(i in 1:length(cm)){
  ps_tmp <- subset_samples(ps_tr, bin_depth==cm[i]) 
  ps_tmp <- filter_taxa(ps_tmp, function(x) sum(x) > 0, TRUE)
  means <- as.data.frame(rowMeans(ps_tmp@otu_table))
  names(means)<-"val"
  means$otu<-rownames(means)
  avgabundtax<-means[order(means$val,decreasing=T),]$otu[1:3500]
  all_depths<-c(all_depths,avgabundtax)
}

unique_alldepths<-unique(all_depths)
length(unique_alldepths)

my_subset <- subset(otu_table(ps), rownames(otu_table(ps)) %in% unique_alldepths)
table(sort(rownames(otu_table(my_subset)))==sort(unique_alldepths)) #make sure this is all TRUE
```

all taxa but three match, so going ahead with using this
OTU_log.p <- match.phylo.comm(tree, OTU_log)$comm
[1] "Dropping taxa from the community because they are not present in the phylogeny:"
[1] "centroid=otu32478" "centroid=otu44283"
[3] "centroid=otu47385"
tree_log.p <- match.phylo.comm(tree, OTU_log)$phy
[1] "Dropping taxa from the community because they are not present in the phylogeny:"
[1] "centroid=otu32478" "centroid=otu44283"
[3] "centroid=otu47385"

```{r}
#Load phylogenetic tree
phylo <- read.tree("ESVs_with10ormorereads_output_27May2023_muscled.nwk")
#subset by the abundant 10875 ESVs
physeq <- merge_phyloseq(my_subset, tax_table(ps), sample_data(ps), phylo)
tree <- physeq@phy_tree
# make sure only the 10875 ESVs are in the tree
table(tree$tip.label%in%unique_alldepths) #all TRUE
table(unique_alldepths%in%tree$tip.label) #all TRUE
rm(physeq)

#using just the 10875 most abundant ESVs
#match up with metadata
OTU<-as.data.frame(otu_table(my_subset))
OTU<-t(OTU)
OTU<-OTU[order(rownames(OTU)),] #site by species

#order metadata
metadata<-metadata[order(rownames(metadata)),] 
#subset metadata
metadata.a <- metadata %>% select(depth, elevation_meters,max_lake_depth, water_sample_ph_bot, water_sample_do_bot, water_sample_t_bot,pH,n_perc, c_perc)

#make OTU and metadata match
table(rownames(OTU)==rownames(metadata)) #all true


#Predict the missing metadata (JVE: not very familiar with this part of John Pearman's code to predict missing metadata..)
set.seed(496)

metadata.1 <-
  preProcess(metadata.a,
             method = c("bagImpute"))

metadata.2  <- 
  predict(metadata.1 , metadata.a)


OTU_log <- log(OTU + 1) #JVE: unsure why log + 1

OTU_log.p <- match.phylo.comm(tree, OTU_log)$comm
tree_log.p <- match.phylo.comm(tree, OTU_log)$phy

phydist <- cophenetic(tree_log.p)

#phylogenetic distance
phydist_hel <- decostand(phydist, method="hellinger")

#from site x species to species x site
table <- t(OTU_log)

env.var.names<-colnames(metadata.2)

#loop through each environmental variable and create a list of each "final table"
all_env.vars_tab<-list()
q=1
for(q in 1:length(env.var.names)){

table_env<-rbind(metadata.2[,q],table)
rownames(table_env)[1]<-"env.var"

table_w <- t(table_env) #first column environmental variable 

headTable <- colnames(table_w) 
x <- headTable[1] # The first column is a constant env.var and is being compared to OTU


# Create the final_table empty

m <- matrix(0, nrow = 0, ncol = 3) 
final_table <- data.frame(m)
colnames(final_table)  <- c('ymax','d50', 'xmax') 

# the for loop, to get all otus 1 by 1 compared to env.var

for(i in seq(2,length(headTable),1)) #start at 2 because the 1 is the Eh_mv
{
  y <- headTable[i] # get otu name
  tablei <-  table_w[,c(x,y)] # extract 2 columns to create a new table
  
  head  <- colnames(tablei)
  
  ymax = which.max(tablei[,2]) # get the max relative abundance of the OTU
  
  MaxRow <- tablei[ymax,] # create a table with the line of the max OTU value
 
  tableiInf <- subset(tablei,tablei[,1]<= MaxRow[1]) #create two tables greater and lower than the x coord
  tableiSup <- subset(tablei,tablei[,1]>= MaxRow[1]) #of the max
  
  tableiInfno0 <- subset(tableiInf,tableiInf[,2]>(MaxRow[2]/20)) #remove the observations where the relative OTU abundance is 0
  tableiSupno0 <- subset(tableiSup,tableiSup[,2]>(MaxRow[2]/20)) #remove the observations where the relative OTU abundance is 0
  
  
  #Determine the lowest and highest Eh value where you find the OTU
  
  xInf <- min(tableiInfno0[,1])
  xSup <- max(tableiSupno0[,1])
  
  # calculate the d50
  
  d50  <- 0.68*abs(xSup-xInf)/2
  #JVE - why is this 0.68?
  
  # create the final table for the otu in the loop
  
  tablei_fin  <- matrix(c(MaxRow[2],d50,MaxRow[1]),ncol=3)
  rownames(tablei_fin)  <- c(head[2])
  colnames(tablei_fin)  <- c('ymax','d50', 'xmax')
  
  # add to the final_table the values for each otu 
  final_table <- rbind(final_table,tablei_fin)
  
  
}
#write the table and put into a list
write.table(final_table, paste("niche_", env.var.names[q], "_9Jan2023.txt", sep=""), sep="\t")
all_env.vars_tab[[q]]<-final_table
}

#remove all but the two objects needed for the mantel correlogs
rm(list=ls()[! ls() %in% c("all_env.vars_tab","phydist_hel")])
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")

```


```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylo_signal

PrayingMantus@0613@
```

#### i) run on Beartooth

phylogenetic_signal_1.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[1]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_1<-mantel.correlog(env_dist,phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_1.RData")

```

phylogenetic_signal_2.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[2]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_2<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_2.RData")

```

phylogenetic_signal_3.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[3]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_3<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_3.RData")

```

phylogenetic_signal_4.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[4]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_4<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_4.RData")

```

phylogenetic_signal_5.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[5]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_5<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_5.RData")

```

phylogenetic_signal_6.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[6]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_6<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_6.RData")

```

phylogenetic_signal_7.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[7]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_7<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_7.RData")

```

phylogenetic_signal_8.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[8]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_8<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_8.RData")

```

phylogenetic_signal_9.R

```{r}
require(vegan)
load("WyLakeMicrobes_10July2023_phylogeneticsignal_forBeartooth.RData")
sub1<-all_env.vars_tab[[9]]
sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]
env_dist<-vegdist(sub2$xmax, method="euclidean")
mc_result_9<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)
save.image("WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_9.RData")

```

run_phylogenetic_signal.sh

```{bash}
#!/bin/bash
#SBATCH --job-name phylo_signal
#SBATCH --mem=20GB
#SBATCH --time=6-00:00:00
#SBATCH --cpus-per-task=1
#SBATCH --account=microbiome
#SBATCH --output=phylo_signal_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load gcc/12.2.0 r/4.2.2
cd /project/seddna/jvonegge/WY_lake_microbes/16S/phylo_signal
date

srun Rscript phylogenetic_signal_1.R
echo "srun Rscript phylogenetic_signal_1.R"

srun Rscript phylogenetic_signal_2.R
echo "srun Rscript phylogenetic_signal_2.R"

srun Rscript phylogenetic_signal_3.R
echo "srun Rscript phylogenetic_signal_3.R"

srun Rscript phylogenetic_signal_4.R
echo "srun Rscript phylogenetic_signal_4.R"

srun Rscript phylogenetic_signal_5.R
echo "srun Rscript phylogenetic_signal_5.R"

srun Rscript phylogenetic_signal_6.R
echo "srun Rscript phylogenetic_signal_6.R"

srun Rscript phylogenetic_signal_7.R
echo "srun Rscript phylogenetic_signal_7.R"

srun Rscript phylogenetic_signal_8.R
echo "srun Rscript phylogenetic_signal_8.R"

srun Rscript phylogenetic_signal_9.R
echo "srun Rscript phylogenetic_signal_9.R"


echo "finished correlogs"
date

```

copy folder back to computer

```{bash}
rsync -r jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylo_signal /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes
```

#### ii) Plot mantel correlograms

```{r}
env.var.names<-c("Sediment depth (cm)",               "Elevation (m)"   , "Max lake depth (m)" ,    
"Bottom water pH", "Bottom water dissolved oxygen", "Bottom water temperature" ,
"Sediment pH"                ,  "Sediment percent nitrogen"            ,  "Sediment percent carbon"    )  
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_1.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_2.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_3.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_4.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_5.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_6.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_7.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_8.RData")
load("phylo_signal/WyLakeMicrobes_10July2023_phylogeneticsignal_mantelcorrresult_9.RData")

figs<-list()
figs[[1]]<-mc_result_1
figs[[2]]<-mc_result_2
figs[[3]]<-mc_result_3
figs[[4]]<-mc_result_4
figs[[5]]<-mc_result_5
figs[[6]]<-mc_result_6
figs[[7]]<-mc_result_7
figs[[8]]<-mc_result_8
figs[[9]]<-mc_result_9

i=1
pdf("Figures/SupplementaryFigures/Phylogenetic_signal_mantel_corr_July2023.pdf", height = 8, width=10)
par(mfrow=c(3,3), mar=c(4,4,4,2))
for(i in 1:9){
plot(figs[[i]])
title(main=env.var.names[i])
}
dev.off()


```







## 10. Upload sequences to NCBI

```{r}
require(stringr)
require(reshape)
require(dplyr)
files<-read.delim("list_of_files.txt",header=F)
names(files)[1]<-"filename"
files$samp<-str_split(files$filename,pattern = ".16S.", 2, simplify = T)[,1]
files$samp<-str_split(files$samp,pattern = "Calder.", 2, simplify = T)[,2]
files$number<-rep(seq(1:4),653)

files<-reshape(files, idvar = "samp", timevar = "number", direction = "wide")
files<-as.data.frame(files)
names(files)<-c("sample_name", "filename", "filename2", "filename3", "filename4")


files$samp1<-str_split(files$filename,pattern = ".16S.", 2, simplify = T)[,1]
files$samp1<-str_split(files$samp1,pattern = "Calder.", 2, simplify = T)[,2]

files$samp2<-str_split(files$filename2,pattern = ".16S.", 2, simplify = T)[,1]
files$samp2<-str_split(files$samp2,pattern = "Calder.", 2, simplify = T)[,2]

files$samp3<-str_split(files$filename3,pattern = ".16S.", 2, simplify = T)[,1]
files$samp3<-str_split(files$samp3,pattern = "Calder.", 2, simplify = T)[,2]

files$samp4<-str_split(files$filename4,pattern = ".16S.", 2, simplify = T)[,1]
files$samp4<-str_split(files$samp4,pattern = "Calder.", 2, simplify = T)[,2]

files$TF<-rep(NA,nrow(files))
for( i in 1:nrow(files)){
        files$TF[i]<-ifelse(files$sample_name[i]==files$samp1[i] & files$sample_name[i]==files$samp2[i] & files$sample_name[i]==files$samp3[i] & files$sample_name[i]==files$samp4[i], files$TF[i]<-TRUE,files$TF[i]<-FALSE )
}

table(files$TF)

order<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/additional_files/SRA_metadata_sampleorder.csv",header=F)

metadata<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/metadata_29Aug2022.csv", header=T, row.names=1)
table(order$V1==metadata$cleanedID)

#rename East Glacier mislabeled sample
files[which(files$sample_name=="EG0308L2"),]$sample_name<-"EG0318L"

subfiles<-filter(files, sample_name %in% metadata$samp_names)  

subfiles<-subfiles[order(match(subfiles$sample_name,metadata$samp_names)),]

table(subfiles$sample_name==metadata$samp_names)
subfiles<-subfiles[,1:5]
write.csv(subfiles, "/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/additional_files/Filenames_for_NCBI_SRA_upload.csv")

fastq_keep_list<-c(subfiles$filename, subfiles$filename2, subfiles$filename3, subfiles$filename4)
write.table(fastq_keep_list,"Metadata/additional_files/subset_list_of_files_forBeartooth.txt", sep=",",col.names = FALSE, row.names=FALSE, quote = FALSE)
```

```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/additional_files/subset_list_of_files_forBeartooth.txt jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload

#subset bash files on linux
cp /project/microbiome/data/seq/psomagen_17sep20_novaseq2/rawdata/sample_fastq/16S/Calder/* /project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/fastq_files

rsync -a /project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/fastq_files --files-from=/project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/subset_list_of_files_forBeartooth.txt /project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/subset_fastq_files



sftp subftp@ftp-private.ncbi.nlm.nih.gov
```


additional code - not sure if actually used it.
```{r}
require(stringr)
require(reshape)
require(dplyr)
files<-read.delim("list_of_files.txt",header=F)
names(files)[1]<-"filename"
files$samp<-str_split(files$filename,pattern = ".16S.", 2, simplify = T)[,1]
files$samp<-str_split(files$samp,pattern = "Calder.", 2, simplify = T)[,2]
files$number<-rep(seq(1:4),653)

files<-reshape(files, idvar = "samp", timevar = "number", direction = "wide")
files<-as.data.frame(files)
names(files)<-c("sample_name", "filename", "filename2", "filename3", "filename4")


files$samp1<-str_split(files$filename,pattern = ".16S.", 2, simplify = T)[,1]
files$samp1<-str_split(files$samp1,pattern = "Calder.", 2, simplify = T)[,2]

files$samp2<-str_split(files$filename2,pattern = ".16S.", 2, simplify = T)[,1]
files$samp2<-str_split(files$samp2,pattern = "Calder.", 2, simplify = T)[,2]

files$samp3<-str_split(files$filename3,pattern = ".16S.", 2, simplify = T)[,1]
files$samp3<-str_split(files$samp3,pattern = "Calder.", 2, simplify = T)[,2]

files$samp4<-str_split(files$filename4,pattern = ".16S.", 2, simplify = T)[,1]
files$samp4<-str_split(files$samp4,pattern = "Calder.", 2, simplify = T)[,2]

files$TF<-rep(NA,nrow(files))
for( i in 1:nrow(files)){
        files$TF[i]<-ifelse(files$sample_name[i]==files$samp1[i] & files$sample_name[i]==files$samp2[i] & files$sample_name[i]==files$samp3[i] & files$sample_name[i]==files$samp4[i], files$TF[i]<-TRUE,files$TF[i]<-FALSE )
}

table(files$TF)

order<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/additional_files/SRA_metadata_sampleorder.csv",header=F)

metadata<-read.csv("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/metadata_29Aug2022.csv", header=T, row.names=1)
table(order$V1==metadata$cleanedID)

#rename East Glacier mislabeled sample
files[which(files$sample_name=="EG0308L2"),]$sample_name<-"EG0318L"

subfiles<-filter(files, sample_name %in% metadata$samp_names)  

subfiles<-subfiles[order(match(subfiles$sample_name,metadata$samp_names)),]

table(subfiles$sample_name==metadata$samp_names)
subfiles<-subfiles[,1:5]
write.csv(subfiles, "/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/additional_files/Filenames_for_NCBI_SRA_upload.csv")

fastq_keep_list<-c(subfiles$filename, subfiles$filename2, subfiles$filename3, subfiles$filename4)
write.table(fastq_keep_list,"Metadata/additional_files/subset_list_of_files_forBeartooth.txt", sep=",",col.names = FALSE, row.names=FALSE, quote = FALSE)

rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/Metadata/additional_files/subset_list_of_files_forBeartooth.txt jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload

#subset bash files on linux
cp /project/microbiome/data/seq/psomagen_17sep20_novaseq2/rawdata/sample_fastq/16S/Calder/* /project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/fastq_files

rsync -a /project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/fastq_files --files-from=/project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/subset_list_of_files_forBeartooth.txt /project/seddna/jvonegge/WY_lake_microbes/16S/NCBI_upload/subset_fastq_files



```



## 11. shared ESVs and shared families

will all reads

```{r}
require(Matrix)
require(metagMisc)
require(phyloseq)
require(reshape2)
require(cluster)
require(stringr)
require(geosphere)

load("WyLakeMicrobes_phyloseq_env_29Aug2022.RData")

#calculate
shared_esvs <- phyloseq_num_shared_otus(ps)


#shared ESVs
shared<-as.matrix(shared_esvs[["shared"]])
shared[upper.tri(shared, diag = T)] <- NA
shared<-melt(shared,na.rm=TRUE)

colnames(shared)[3]<-"shared"

#nonshared ESVs
nonshared<-as.matrix(shared_esvs[["nonshared_total"]])
nonshared[upper.tri(nonshared, diag = T)] <- NA
nonshared<-melt(nonshared,na.rm=TRUE)
colnames(nonshared)[3]<-"nonshared"

table(nonshared$Var1==shared$Var1) #all T
table(nonshared$Var2==shared$Var2) #all T

shared$nonshared<-nonshared$nonshared
rm(nonshared)
shared$percent<-shared$shared/(shared$shared+shared$nonshared)


#now add in environmental distances
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(as.matrix(shared_esvs[["shared"]])))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))

daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
env_dist<-melt(daisy.mat, na.rm=TRUE)

table(shared$Var1==env_dist$Var1) # all true
table(shared$Var2==env_dist$Var2) # all true 
shared$env_dist<-env_dist$value
 #overwrite original file

names(shared)[1]<-"s1_samp_names"
shared$s1_samp_names<-as.character(shared$s1_samp_names)
names(shared)[2]<-"s2_samp_names"
shared$s2_samp_names<-as.character(shared$s2_samp_names)

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

shared<-merge(shared, metadata_s1, by="s1_samp_names")
shared<-merge(shared, metadata_s2, by="s2_samp_names")

#remove metadata notes
shared$s1_notes<-NULL
shared$s2_notes<-NULL
shared$s1_Notes_sed_water_wt<-NULL
shared$s2_Notes_sed_water_wt<-NULL
shared$s1_Notes_carbon_nitrogen<-NULL
shared$s2_Notes_carbon_nitrogen<-NULL
shared$s1_Notes._lake_sed_pH<-NULL
shared$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
shared$abs_cm<-rep(NA, nrow(shared))
i=1
for(i in 1:nrow(shared)){
  ifelse(shared$s1_lake_drive[i]==shared$s2_lake_drive[i],shared$abs_cm[i]<-abs(shared$s2_depth[i]-shared$s1_depth[i]),NA)
}


# calculate geographic distance


for(i in 1:nrow(shared)){
        shared$geo_dist[i]<-as.numeric(distm(data.frame(X = shared$s1_longitude[i], Y = shared$s1_latitude[i]),data.frame(X = shared$s2_longitude[i], Y = shared$s2_latitude[i])))
}

shared$geo_dist_km<-shared$geo_dist/1000


#write.csv(shared,"sharedESVs_14Aug2023.csv")
```

```{r}
# comps_backup<-read.csv("sharedESVs_14Aug2023.csv",header=T,row.names=1)
# comps_backup$percent<-comps_backup$percent*100

zone<-c("A","B","C")
comps<-comps_backup
pdf("Figures/SupplementaryFigures/PercentSharedESVS_14Aug2023.pdf", width=7, height=7)
par(mfrow=c(3,3), mar=c(4,4,3,2))

j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]
plot(comps_sub$env_dist, comps_sub$percent, ylab="Shared ESVs (%)", pch=16, col="#00000050",xlab="Environmental dissimilarity", ylim=c(0,40),main=c("Redox", "Transition", "Depauperate")[j])
abline(lm(comps_sub$percent~comps_sub$env_dist), col="lightgreen", lwd=2)
if(summary(lm(comps_sub$percent~comps_sub$env_dist))$coefficients[2,4]<0.05){
        text(x=(max(comps_sub$env_dist)*.95), 40*0.95,"*" ,cex=3)
}}



j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]
plot(comps_sub$geo_dist_km, comps_sub$percent, ylab="Shared ESVs (%)", pch=16, col="#00000050",xlab="Distance (km)",ylim=c(0,40))
abline(lm(comps_sub$percent~comps_sub$geo_dist_km), col="lightgreen", lwd=2)
if(summary(lm(comps_sub$percent~comps_sub$geo_dist_km))$coefficients[2,4]<0.05){
        text(x=(max(comps_sub$geo_dist_km)*.95), 40*0.95,"*" ,cex=3)
}}



#sediment
comps<-comps_backup[is.na(comps_backup$abs_cm)==F & comps_backup$abs_cm<27 ,]
plot(comps$abs_cm, comps$percent, ylab="Shared ESVs (%)", xlab="Sediment distance (cm)", pch=16, col="#00000050",main="All horizons, individual cores")
abline(lm(comps$percent~comps$abs_cm), col="lightgreen", lwd=2)
if(summary(lm(comps$percent~comps$abs_cm))$coefficients[2,4]<0.05){
        text(x=(max(comps$abs_cm)*.95), max(comps$percent)*0.95,"*" ,cex=3)
}

dev.off()
```






###Alpha diversity is really different with this new dataset
Going to use procrust to try to look at the differences between samples
```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
ps_table <- data.frame(otu_table(ps_tr))
ps_table <-t(ps_table)
new.dist<-metaMDS(ps_table, distance = "bray")

load("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/Calder_vsearch/16S/WYLakeSedMicrobes_old/WyLakeMicrobes_phyloseq_env_29Aug2022.RData")
ps_table <- data.frame(otu_table(ps_tr))
ps_table <-t(ps_table)
old.dist<-metaMDS(ps_table, distance = "bray") 

#calculate vegdist
load("/Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/Calder_vsearch/16S/WYLakeSedMicrobes_old/WyLakeMicrobes_phyloseq_env_29Aug2022.RData")
old.dist <- vegdist(wisconsin(t(data.frame(otu_table(ps_tr)))))

load("WyLakeMicrobes_Phyloseq_11May2023.RData")
new.dist <- vegdist(wisconsin(t(data.frame(otu_table(ps_tr)))))

mds.old <- monoMDS(old.dist)
mds.new <- monoMDS(new.dist)

procrust <- procrustes(mds.old, mds.new)
procrust


summary(procrust)

pdf("Figures/Procrustes_diff_28June2023.pdf",height=10, width=20)
plot(procrust)
dev.off()


plot(procrust, kind=2)
residuals(procrust)
summary(procrust)
eigenvals(procrust)
plot(procrust, kind=2)
residuals(procrust)


rm(notnorm.dist)
rm(norm.dist)
rm(mds.notnorm)
rm(mds.norm)
rm(procrust)
rm(otu_to_normalize_10k)
rm(otu_table)

```


# Part IV: Manuscript Revision data analysis

Comment: Firstly, taxa such as cyanobacteria, are as the authors note more representative of the water column and are unlikely to be actively growing in the sediment (bar right at the surface). How do the authors think this is going to impact the conclusions from the assembly process results? While I think the analysis can still be undertaken I do think the conclusions that are derived from the analysis could be different.
Draft response: We appreciate the acknowledgement of how living cyanobacteria may influence interpretation of community assembly processes and agree that there may be minor changes in analysis outcomes. However, cyanobacteria represent a small fraction of the total reads used in estimating community assembly processes, and when we reran the analysis without taxa assigned to cyanobacteria, we saw little to no change in the overall proportion of community assembly processes across all pairwise comparisons in our dataset.

## I. proportion of cyanobacteria in dataset
also proportion of cyanobacteria in phylogenetic tree
```{r}
#proportion of cyanobacteria in entire dataset
round(sum(colSums(otu_table(subset_taxa(ps_tr, Phylum=="Cyanobacteria"))))/sum(colSums(otu_table(ps_tr)))*100, digits=2)
#1.80

#proportion of cyanobacteria in phylogenetic tree
# which ESVs are cyanobacteria?
sub<-subset_taxa(ps, Phylum=="Cyanobacteria")
cyano_ESV<-rownames(tax_table(subset_taxa(ps, Phylum=="Cyanobacteria")))

#run next chunk
```


## 3. iCAMP community assembly

### a. make phylogenetic tree

#### i. subset ESVS with 10+ reads


```{r}
ESV<-as.data.frame(otu_table(ps))
ESV<-t(ESV)
ESV<-ESV[order(rownames(ESV)),]

table(colSums(ESV)<10)
# FALSE  TRUE  - 27May2023
# 28480 64893
mean(colSums(ESV)) #53 reads on average - 27May2023

lessthan10<-which(colSums(ESV)<10)
ESV_10plusreads<-ESV[,-lessthan10]
dim(ESV_10plusreads)
# 478 28480 - 27May2023
table(colSums(ESV_10plusreads)<10)# all FALSE
ESV_10plusreads<-ESV_10plusreads[,-which(colnames(ESV_10plusreads)%in%cyano_ESV)]
dim(ESV_10plusreads)
# [1]   478 28259
# [1] "2024-01-02"

```

What proportion of reads is cyanobacteria in the phylogenetic tree with ESVs with 10+ reads
```{r}
ESV_10plusreads_cyano<-ESV_10plusreads[,which(colnames(ESV_10plusreads)%in%cyano_ESV)]
round(sum(colSums(ESV_10plusreads_cyano))/sum(colSums(ESV_10plusreads))*100, digits=2)
#1.85
rm(ESV_10plusreads_cyano)
rm(cyano_ESV)
```

#### ii. subset fasta file with sequences

in local R, subset fasta file by the ESVs with 10+ reads (normalized reads)

```{r}
seqs<-Biostrings::readDNAStringSet("OriginalFiles/zotus_nonchimeric.fa") 
seqs@ranges@NAMES<-stringr::str_split(seqs@ranges@NAMES,pattern = ";", 3, simplify = T)[,1]

seqs_sub<-seqs[colnames(ESV_10plusreads)]
table(seqs_sub@ranges@NAMES %in% colnames(ESV_10plusreads))
table(colnames(ESV_10plusreads)%in%seqs_sub@ranges@NAMES)
rm(list=ls()[! ls() %in% c("ESV_10plusreads", "seqs_sub" )])
save.image("WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads_NoCyanos_2Jan2024.RData")
writeXStringSet(seqs_sub,filepath = "ESVs_with10ormorereads_forBeartooth_NoCyanos_2Jan2024.fasta", format = "fasta")
```

copy the fasta file over to the supercomputer

```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/ESVs_with10ormorereads_forBeartooth_NoCyanos_2Jan2024.fasta jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/phylogenetic_tree
```

#### iii. make phylogenetic tree

using clustalo to align and then fasttree to make the tree

align_maketree.sh
```{bash}
#!/bin/bash
#SBATCH --job-name phylotree
#SBATCH --mem=120GB
#SBATCH --time=6-00:00:00
#SBATCH --cpus-per-task=6
#SBATCH --account=microbiome
#SBATCH --output=phylotree_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load arcc/1.0 miniconda3/4.12.0
conda activate shotgun_env
cd /project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/phylogenetic_tree

clustalo -i ESVs_with10ormorereads_forBeartooth_NoCyanos_2Jan2024.fasta -o tempfile_2Jan2024_muscled.fa -v --threads=6

FastTree -nt tempfile_2Jan2024_muscled.fa > ESVs_with10ormorereads_NoCyanos_output_2Jan2024_muscled.nwk

```



Copy environment over to supercomputer
```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads_NoCyanos_2Jan2024.RData jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/iCAMP

cp ESVs_with10ormorereads_NoCyanos_output_2Jan2024_muscled.nwk ../iCAMP

```



### b. qpen ESVs with 10+ reads

qpen_function.R
```{r}
require(phyloseq)
require(iCAMP)
require(ape)
load("../WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads_NoCyanos_2Jan2024.RData")
comm<-ESV_10plusreads
tree<-read.tree("../ESVs_with10ormorereads_NoCyanos_output_2Jan2024_muscled.nwk")
table(colnames(ESV_10plusreads)%in%tree[["tip.label"]]) #all TRUE
table(tree[["tip.label"]]%in%colnames(ESV_10plusreads)) #all TRUE


wd0="/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/iCAMP/qpen"
nworker=6 # parallel computing thread number
rand.time=1000 # usually use 1000 for real data.
  

  # for a big dataset, pdist.big may be used
  save.wd="/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/iCAMP/qpen/pdbig.qpen"
  print(save.wd)
  # please change to the folder you want to save the pd.big output.
  
  pd.big=pdist.big(tree = tree, wd=save.wd, nworker = nworker)
  qp2=qpen(comm=comm, pd=pd.big$pd.file, pd.big.wd=pd.big$pd.wd,
           pd.big.spname=pd.big$tip.label, tree=tree,
           rand.time=rand.time, nworker=nworker)
  setwd(wd0)
save.image("WyLakeMicrobes_env_2Jan2024_qpen_ESVswith10plusreads_NoCyanos_results.RData")
```

run_qpen_function.sh
```{bash}
#!/bin/bash
#SBATCH --job-name qpen_10plus
#SBATCH --mem=120GB
#SBATCH --time=6-00:00:00
#SBATCH --cpus-per-task=6
#SBATCH --account=microbiome
#SBATCH --output=qpen_10plus_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load gcc/12.2.0 r/4.2.2
cd /project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/iCAMP/qpen

srun Rscript qpen_function.R
echo "srun Rscript qpen_function.R"

echo "finished qpen iCAMP - JVE"
date
```

copy back to desktop
```{bash}
rsync jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/revision_analyses/iCAMP/qpen/WyLakeMicrobes_env_2Jan2024_qpen_ESVswith10plusreads_NoCyanos_results.RData /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes
```


### c. qpen output - ESVs with 10plus reads

#### i) start here
```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
load("WyLakeMicrobes_env_2Jan2024_qpen_ESVswith10plusreads_NoCyanos_results.RData")

#pull out results from iCAMP
qpn<-qp2$result[,c("sample1","sample2","process")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"process[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)%in%metadata$samp_names) #all true
table(colnames(dfr)%in%metadata$samp_names) # all true

#now add in environmental distances (lake bottom water and lake depth)
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

table(colnames(dfr)==metadata$samp_names) # all true
table(colnames(dfr)==rownames(metadata_sub)) # all true 

daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))
table(colnames(daisy.mat)==colnames(dfr)) # all true
table(rownames(daisy.mat)==rownames(dfr)) # all true

daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
env_dist<-melt(daisy.mat, na.rm=TRUE)

process<-melt(as.matrix(dfr), na.rm=T)

table(process$Var1==env_dist$Var1) # all true
table(process$Var2==env_dist$Var2) # all true 
process$env_dist<-env_dist$value

pairwise<-process #overwrite original file

names(pairwise)[1]<-"s1_samp_names"
pairwise$s1_samp_names<-as.character(pairwise$s1_samp_names)
names(pairwise)[2]<-"s2_samp_names"
pairwise$s2_samp_names<-as.character(pairwise$s2_samp_names)
names(pairwise)[3]<-"process"

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

pairwise<-merge(pairwise, metadata_s1, by="s1_samp_names")
pairwise<-merge(pairwise, metadata_s2, by="s2_samp_names")

#remove metadata notes
pairwise$s1_notes<-NULL
pairwise$s2_notes<-NULL
pairwise$s1_Notes_sed_water_wt<-NULL
pairwise$s2_Notes_sed_water_wt<-NULL
pairwise$s1_Notes_carbon_nitrogen<-NULL
pairwise$s2_Notes_carbon_nitrogen<-NULL
pairwise$s1_Notes._lake_sed_pH<-NULL
pairwise$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
pairwise$abs_cm<-rep(NA, nrow(pairwise))
i=1
for(i in 1:nrow(pairwise)){
  ifelse(pairwise$s1_lake_drive[i]==pairwise$s2_lake_drive[i],pairwise$abs_cm[i]<-abs(pairwise$s2_depth[i]-pairwise$s1_depth[i]),NA)
}

# calculate geographic distance

require(geosphere)
for(i in 1:nrow(pairwise)){
        pairwise$geo_dist[i]<-as.numeric(distm(data.frame(X = pairwise$s1_longitude[i], Y = pairwise$s1_latitude[i]),data.frame(X = pairwise$s2_longitude[i], Y = pairwise$s2_latitude[i])))
}

pairwise$geo_dist_km<-pairwise$geo_dist/1000

write.csv(pairwise, "qpen_10plusESVs_allcomparisons_NoCyanos_4Jan2024.csv")
```

#### ii) environmental distance within each zone

```{r}
comps_backup<-read.csv("qpen_10plusESVs_allcomparisons_NoCyanos_4Jan2024.csv", header=T, row.names=1)

comps<-comps_backup

comps$d_val<-comps$env_dist

#make breaks for zone A
comps_tmp<-comps[comps$s1_zone=="A" & comps$s2_zone=="A",]

comps_tmp<-comps_tmp[comps_tmp$d_val!=0,]
comps_tmp$d_val_group_breaks<-cut2(comps_tmp$d_val, g=10)
levels(comps_tmp$d_val_group_breaks)
# [1] "[0.0162,0.117)" "[0.1167,0.163)" "[0.1632,0.210)" "[0.2097,0.240)" "[0.2399,0.276)"
#  [6] "[0.2759,0.323)" "[0.3234,0.384)" "[0.3835,0.454)" "[0.4543,0.540)" "[0.5399,0.722]"
breaks<-c(as.numeric(gsub("\\]","" ,gsub("\\[","",unlist(str_split(as.character(levels(comps_tmp$d_val_group_breaks)), pattern=",")))[c(seq(1, 20, 2),20)])))

#make sure first value is below the minimum env_distance measure that isn't 0
min(comps_backup[comps_backup$env_dist!=0,]$env_dist)
#[1] 0.01621537

# make a bottom break (0.016 - just below the lowest env_dist) that is above zero but below the first break
breaks<-c(0.016,breaks[2:11]) 

full_output<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)

zone<-c("A","B","C")
j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]

sub<-comps_sub[comps_sub$d_val==0,]
sub$d_val_group<-rep(0, nrow(sub))

comps_sub<-comps_sub[comps_sub$d_val!=0,]
comps_sub$d_val_group<-as.numeric(cut(comps_sub$d_val, breaks=breaks))
comps_sub<-rbind(sub, comps_sub)

#breaks_labels<- levels(comps$d_val_group_breaks)
breaks_labels<-c("[0, 0]", "[0.016, 0.12)", "[0.12, 0.16)", "[0.16, 0.21)", "[0.21, 0.24)",
 "[0.24, 0.28)", "[0.28, 0.32)", "[0.32, 0.38)", "[0.38, 0.45)",
"[0.45, 0.54)" ,"[0.54, 0.72]")

tmp<-comps_sub
tally<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)
proc<-unique(comps_backup$process)
groups<-sort(unique(tmp$d_val_group))
i=1
p=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  for(p in 1:length(proc)){
    tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2),d_val_group=groups[i], d_val_inclthisnumandbelow=breaks[i],zone=zone[j], dist="env"))
  }
  }

full_output<-rbind(full_output,tally)
}
#check to make sure they add to one
range(full_output$n)
#[1]  171 2020 #29May2023
mean(full_output$n)
#947.6364 #29May2023


write.csv(full_output, "qpen_10plusESVs_envdist_NoCyanos_4Jan2024.csv")

```

#### iii) geographic distance

```{r}
comps_backup<-read.csv("qpen_10plusESVs_allcomparisons_NoCyanos_4Jan2024.csv", header=T, row.names=1)
comps<-comps_backup


comps[comps$s1_lake_id==comps$s2_lake_id & comps$s1_lake_drive!=comps$s2_lake_drive,]$geo_dist_km<-0.001 #add one meter for cores in the same lake
comps$d_val<-comps$geo_dist_km
breaks<-c(seq(0,15,5), seq(100, 300, 200), seq(400,500,100))  ##nothing from  43.30254  174.6661
breaks<-c(0,0.1, breaks[2:8])
full_output<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)


zone<-c("A","B","C")
j=1
for( j in 1:3) {
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]

sub<-comps_sub[comps_sub$d_val==0,]
sub$d_val_group<-rep(0, nrow(sub))

comps_sub<-comps_sub[comps_sub$d_val!=0,]
comps_sub$d_val_group<-as.numeric(cut(comps_sub$d_val, breaks=breaks))
comps_sub<-rbind(sub, comps_sub)

breaks_labels<- c("[0,0]",levels(cut(comps$d_val, breaks=breaks)))

tmp<-comps_sub
tally<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)
proc<-unique(comps_backup$process)
groups<-sort(unique(tmp$d_val_group))
i=1
p=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  for(p in 1:length(proc)){
    tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2),d_val_group=groups[i], d_val_inclthisnumandbelow=breaks[i],zone=zone[j], dist="geo"))
  }
  }
full_output<-rbind(full_output,tally)
#count the number of comparisons in each zone
}

range(full_output$n)
#[1]  75 2604 # 29May2023
mean(full_output$n)
#1158.222 - 29May2023
print(breaks_labels)

write.csv(full_output, "qpen_10plusESVs_geodist_NoCyanos_4Jan2024.csv")
```

#### iv) combine the two dataframes

```{r}
geo_dist_tally<-read.csv("qpen_10plusESVs_geodist_NoCyanos_4Jan2024.csv", header=T, row.names=1)
env_dist_tally<-read.csv("qpen_10plusESVs_envdist_NoCyanos_4Jan2024.csv", header=T, row.names=1)
full_output<-rbind(geo_dist_tally,env_dist_tally)

full_output[full_output$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
full_output[full_output$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
full_output[full_output$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
full_output[full_output$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
full_output[full_output$process=="Undominated",]$process<-"C_Drift"


#add in color
full_output$zone_col<-rep('#018571',nrow(full_output))
full_output[full_output$zone=="B",]$zone_col<-"#C4AD79"
full_output[full_output$zone=="C",]$zone_col<-'#a6611a'
        


#add in xlab as dist column
full_output[full_output$dist=="env",]$dist<-'Environmental dissimilarity'
full_output[full_output$dist=="geo",]$dist<-'Distance (km)'

#write.csv(full_output,"qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May023.csv")

#if count needed
count<-unique(full_output[,c("d_val_group","zone","n","dist")])
#write.csv(count, "qpen_10plusESVs_count_summary_29May2023.csv")
```

#### v) plot env and geo dist

```{r}
#full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)
full_output$proportion<-full_output$percent
full_output$percent<-full_output$percent*100

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")
#new_colors<-c("#CCCCCC","#B0E2FF", "#36648B")

break_labels<-list()
break_labels[[1]]<-c( "0",">0 to 0.1" ,  ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0", "0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")

#full_output<-full_output[full_output$process%in%sort(unique(full_output$process))[3:5],]

ggplt<-list()
i=1
j=1
for(j in 1:3){
        sub<-full_output[full_output$zone==sort(unique(full_output$zone))[j],]
for(i in 1:2){
        sub2<-sub[sub$dist==unique(sub$dist)[i],]       
ifelse(j==3, 
       
       
       ggplt[[length(ggplt)+1]] <- ggplot(sub2,            
               aes(x = d_val_group,
                   y = percent,
                   color= process)) +  geom_point(size=3)+ theme_bw()   + xlab(label = sub2$dist[1])+ scale_x_continuous(breaks = sort(unique(sub2$d_val_group)), labels=break_labels[[i]])+ ylab(label = "") + geom_line(linewidth=2) +   labs(color="Assembly process")  + scale_color_manual(values=new_colors)+ theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) +theme(axis.text.x = element_text(angle = 60,hjust=1))+      
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
        axis.text=element_text(size=13), #change font size of axis text
        axis.title=element_text(size=15), #change font size of axis titles
        plot.title=element_text(size=14), #change font size of plot title
        legend.text=element_text(size=14), #change font size of legend text
        legend.title=element_text(size=15)) +
                theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())#change font size of legend title
       
       , 
       
       
              ggplt[[length(ggplt)+1]] <- ggplot(sub2,            
               aes(x = d_val_group,
                   y = percent,
                   color= process)) + geom_point(size=3)+ theme_bw()   + xlab(label = sub2$dist[1])+ scale_x_continuous(breaks = sort(unique(sub2$d_val_group)), labels=break_labels[[i]])+ ylab(label = "") + geom_line(linewidth=2) +   labs(color="Assembly process")   + scale_color_manual(values=new_colors)+ theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) +theme(axis.text.x = element_text(angle = 60,hjust=1))+      
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
        axis.text=element_text(size=13), #change font size of axis text
        axis.title=element_text(size=15), #change font size of axis titles
        plot.title=element_text(size=14), #change font size of plot title
        legend.text=element_text(size=14), #change font size of legend text
        legend.title=element_text(size=15))+ #change font size of legend title
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank()) +
        theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())#change font size of legend title
       )
        }}



pdf("Figures/CommAssemProc_EnvDist_GeoDist_NoCyanos_4Jan2024.pdf",height=7,width=7)
ggplt[[1]]+ggplt[[2]]+ ggplt[[3]]+ggplt[[4]]+ggplt[[5]]+ggplt[[6]]+ 
  plot_layout(ncol = 2)
dev.off()


```

#### vi) plot sediment distance & GAMS

```{r}

qpn<-read.csv("qpen_10plusESVs_allcomparisons_NoCyanos_4Jan2024.csv", header=T, row.names=1)

#subset by samples within the same core
downcore<-qpn[is.na(qpn$abs_cm)==F & qpn$abs_cm<27 ,]


downcore$d_val<-abs(downcore$abs_cm)
downcore$d_val_group_breaks<-cut2(downcore$d_val, g=10)
downcore$d_val_group<-as.numeric(cut2(downcore$d_val, g=10))
levels(downcore$d_val_group_breaks)
break_labels<- c("0 to <2.5" ,"2.5 to <5" ,"5 to <7", "7 to <9" ,"9 to <11" ,"11 to <15"
,"15 to <18" ,"18 to <22" ,"22 to <26")
#these are put into 9 groups here instead of the requested 10, must be to make it even.

tmp<-downcore
tally<-data.frame(process=NULL,percent=NULL, d_val_group=NULL,n=NULL)
groups<-sort(unique(downcore$d_val_group))
i=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  processes<-as.data.frame(table(tmp2$process)/nrow(tmp2))
  colnames(processes)[1]<-"process"
  colnames(processes)[2]<-"percent"
  processes$process<-as.character(processes$process)
  processes$d_val_group<-rep(groups[i],nrow(processes))
  processes$n<-rep(nrow(tmp2),nrow(processes))
  tally<-rbind(tally,processes)
}
  


tally$proportion<-tally$percent
tally$percent<-tally$percent*100

tally[tally$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
tally[tally$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
tally[tally$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
tally[tally$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
tally[tally$process=="Undominated",]$process<-"C_Drift"

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

        ggplt <- ggplot(tally,            
                        aes(x = d_val_group,
                            y = percent,
                            color= process)) +  geom_line(linewidth=2) +geom_point(size=3) + theme_bw() + scale_x_continuous(breaks=seq(1,length(groups),1), 
                                                                                                                             labels=break_labels) + xlab(label = "Vertical sediment\ndistance (cm)")+ ylab(label = "Proportion (%)") + geom_line(linewidth=2) +   labs(color="Assembly process")    + scale_color_manual(values=new_colors, labels=c("Variable selection",  "Homogeneous selection",    "Drift",  "Homogenizing dispersal" , "Dispersal limitation" )) + theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) + theme(axis.text.x = element_text(angle = 45,hjust=1))+ guides(color = guide_legend(override.aes = list(linewidth = 6))) + theme(legend.position="none")+
                theme(axis.text=element_text(color="black"))+
                theme(axis.text.x = element_text(angle = 60,hjust=1))+
                theme(text=element_text(size=14), #change font size of all text
                      axis.text=element_text(size=14), #change font size of axis text
                      axis.title=element_text(size=15), #change font size of axis titles
                      plot.title=element_text(size=14), #change font size of plot title
                      legend.text=element_text(size=14), #change font size of legend text
                      legend.title=element_text(size=15),
                      panel.grid.minor = element_blank(), 
                      panel.grid.major.x = element_blank()) #change font size of legend title 

pdf("Figures/CommAssemProc_SedDist_NoCyanos_4Jan2024.pdf", height=3.05, width=3.3)
ggplt
dev.off()

unique(tally$n)
#[1] 372 352 302 283 239 403 163 236 190

#write.csv(tally,"qpen_10plusESVs_seddist_29June2023.csv")

```

sediment distance GAM

sediment distance (with zero)
need to run most of section before (don't need to replot)
```{r}
model_results<-data.frame(process=NULL, devex=NULL, p=NULL)

tally$percent<-tally$percent/100
#Plot the sediment depth GAM for each process
pdf("Figures/SupplementaryFigures/seddepth_GAM_6Sept2023.pdf", height=3.5, width=12)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="black", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels)),1), las=2, labels = break_labels)
title(xlab=c("","","Sediment distance (cm)","","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)

Data<-data.frame(x=sub$d_val_group, y=sub$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=new_colors[i], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(new_colors[i], alpha.f = 0.40), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(process=sort(unique(tally$process))[i], devex=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
}
dev.off()

round(mean(model_results$devex),digits=3)
#[1] 0.914 # 29Jan2023
```


plot legend
```{r}
require(cowplot)
library(ggplot2) 
library(grid)
library(gridExtra) 
# Using the cowplot package
legend <- cowplot::get_legend(ggplt)

grid.newpage()
grid.draw(legend)
```


#### vii) GAMS

doesn't include comparisons within the same lake 8Feb2023 
the labeling for geographic distance is off (double check if going to put in supplementary figures)
29June2023 - can't remember logic for why I removed 0 from the GAMs..
without same lakes
```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

break_labels<-list()
break_labels[[1]]<-c( ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")

full_output<-full_output[full_output$d_val_group!=0,] #GAMs without 0 (without comparisons from the same lake)
tmp1<-full_output[full_output$dist=="Environmental dissimilarity",]
tmp2<-full_output[full_output$dist=="Distance (km)",]
tmp2<-tmp2[tmp2$d_val_group!=1,]
full_output<-rbind(tmp2,tmp1)


model_results<-data.frame(dist=NULL, process=NULL, zone=NULL, rsq=NULL, p=NULL)

d=1
for (d in 1:2){
pdf(paste("Figures/Fig7_qpen_",unique(full_output$dist)[d],"_GAM_18Aug2023.pdf",sep=""), height=3.5, width=12)
par(mfrow=c(1,5),mar=c(8,4,2,1))
tally<-full_output[full_output$dist==unique(full_output$dist)[d],]
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="white", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels[[d]])),1), las=2, labels = break_labels[[d]])
title(xlab=c("","",unique(full_output$dist)[d],"","")[i], cex.lab=2, line=6)
title(ylab=c("Proportion","","","","")[i], cex.lab=2, line =2)
x=1
for(x in 1:3){
sub2<-sub[sub$zone==unique(sub$zone)[x],]
points(sub2$d_val_group,sub2$percent, pch=16, col=sub2$zone_col[x])

#GAM
Data<-data.frame(x=sub2$d_val_group, y=sub2$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=sub2$zone_col[x], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(sub2$zone_col[x], alpha.f = 0.20), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(dist=unique(full_output$dist)[d], process=sort(unique(tally$process))[i], zone=unique(sub$zone)[x], rsq=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
        
}}
dev.off()
}
write.csv(model_results, "qPEN_CommunityAssembly_GAMS_without0_29June2023.csv")

```

with same lakes
```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

break_labels<-list()
break_labels[[1]]<-c( "0",">0 to 0.1" ,  ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0", "0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")


model_results<-data.frame(dist=NULL, process=NULL, zone=NULL, dev.exp=NULL, p=NULL)

d=1
for (d in 1:2){
pdf(paste("Figures/SupplementaryFigures/Fig7_qpen_",unique(full_output$dist)[d],"_GAM_18Aug2023.pdf",sep=""), height=3.5, width=12)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
tally<-full_output[full_output$dist==unique(full_output$dist)[d],]
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="white", xaxt="n")
axis(side=1,cex=0.8, at=seq(0,(length(break_labels[[d]])-1),1), las=2, labels = break_labels[[d]])
title(xlab=c("","",unique(full_output$dist)[d],"","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)
x=1
for(x in 1:3){
sub2<-sub[sub$zone==unique(sub$zone)[x],]
points(sub2$d_val_group,sub2$percent, pch=16, col=sub2$zone_col[x])

#GAM
Data<-data.frame(x=sub2$d_val_group, y=sub2$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=sub2$zone_col[x], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(sub2$zone_col[x], alpha.f = 0.20), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(dist=unique(full_output$dist)[d], process=sort(unique(tally$process))[i], zone=unique(sub$zone)[x], dev.exp=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
        
}}
dev.off()
}
write.csv(model_results, "qPEN_CommunityAssembly_GAMS_with0_18Aug2023.csv")

mean(model_results[model_results$dist=="Environmental dissimilarity",]$dev.exp)
#0.5559333 - aug 18, 2023
mean(model_results[model_results$dist=="Distance (km)",]$dev.exp)
# 0.5546-  aug 18, 2023


```


#### viii) stats for manuscript
```{r}
qpn<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)
(table(qpn$process))/nrow(qpn)

 #   Dispersal.Limitation Heterogeneous.Selection   Homogeneous.Selection 
 #             0.34732419              0.22467830              0.39389314 
 # Homogenizing.Dispersal             Undominated 
 #             0.01335930              0.02074507 

#selection
0.22467830 + 0.39389314


#stochastic
0.01335930 + 0.34732419 + 0.02074507

```

fig 6 A (sed distance)

```{r}
full_output<-read.csv("qpen_10plusESVs_seddist_29June2023.csv", header=T,row.names=1)
i=1
for( i in 1:5){
sub<-full_output[full_output$d_val_group==1 & full_output$process==sort(unique(full_output$process))[i],]
print(sub$process[1])
print(signif(sub$proportion, digits=3)*100)
}

i=1
for( i in 1:5){
sub<-full_output[full_output$d_val_group%in%c(8,9) & full_output$process==sort(unique(full_output$process))[i],]
print(sub$process[1])
print(signif(sub$proportion, digits=3)*100)
}

```

Within an individual sediment core, samples â‰¤ 2.5 cm apart were either homogenized (homogenous selection, 71.5%) or differentiated by selection (variable selection, 5.1%), regardless of horizon. As the distance between samples increased, homogeneous selection declined and variable selection increased (Fig. 6, A). At sediment distances > 18 cm (18-22 and 22-26 cm), where all pairs of samples were compared across horizons, variable selection predominated (29.7-39.5%). Homogenizing dispersal (mass effects) was highest between comparisons 0-7 cm apart (15.3-21.5%), and declined to 5.3% with increasing sediment distance. Dispersal limitation increased with sediment distance, reaching 26.8% at 22-26 cm. Drift played a minor role (< 9%) across all sediment distances.

figure 6 B and C

```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

#1) same lake (environment)

#Homogenous selection
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="B_Homogeneous selection", ]$percent), digits=3)*100


#variable selection
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="A_Variable selection", ]$percent), digits=3)*100


#disp lim
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="E_Dispersal limitation", ]$percent), digits=3)*100


#homog disp
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="D_Homogenizing dispersal", ]$percent), digits=3)*100


#or signif
# 61.5
# 7.19
# 8.49
# 19.7


```

Manuscript text:

Homogeneous selection dominated comparisons within the same horizon within any given lake (mean across horizons, 61.5%), followed by homogenizing dispersal (19.7%), variable selection (7.19%), and dispersal limitation (8.49%) (Fig. 6, B and C).

inter-lake comparisons (averaged across environmental distance and geographic distance)

```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))

for( i in 1:5){

sub<-rbind(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%!in%c(0) & full_output$process==sort(unique(full_output$process))[i],]
      , 
      full_output[full_output$dist=="Distance (km)" & full_output$d_val_group%!in%c(0,1) & full_output$process==sort(unique(full_output$process))[i],])

print(sub$process[1])
print(signif(mean(sub$percent),digits=3)*100)
print(signif(range(sub$percent),digits=3)*100)
}


```

[1] "A_Variable selection" [1] 14.2 [1]  3.17 28.20
[1] "B_Homogeneous selection"[1] 47.7 [1] 26.8 72.0
[1] "C_Drift" [1] 2.77 [1]  0.0 10.9
[1] "D_Homogenizing dispersal" [1] 1.32 [1] 0.00 6.67
[1] "E_Dispersal limitation" [1] 34 [1] 17.5 47.2



As environmental dissimilarity and geographic distance increased with inter-lake comparisons, homogenizing dispersal declined while variable selection and dispersal limitation increased. Regardless, homogeneous selection often remained the most dominant community assembly process in all horizons. Homogeneous selection ranged from 26.8-72.0% (avg. 47.7%), variable selection 3.17-28.20% (avg. 14.2%), and dispersal limitation 17.5-47.2% (avg. 34.0%). Homogenizing dispersal and drift acting alone had negligible effects (avg. 1.32 and 2.77%, respectively) across comparisons of abiotic lake environments and geographic distances.


```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
z=1
for(z in 1:3){
    sub<-full_output[full_output$zone==c("A","B","C")[z],]  

sub2<-rbind(sub[sub$dist=="Environmental dissimilarity" & sub$d_val_group%!in%c(0) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],]
      , 
      sub[sub$dist=="Distance (km)" & sub$d_val_group%!in%c(0,1) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],])

 
print(sub2$zone[1])
print(signif(range(sub2$percent),digits=3)*100)
}
```
In the redox horizon, the contributions of homogenous selection, variable selection, and dispersal limitation explained a comparable proportion of comparisons (11.8-47.0%).


```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
z=1
i=1
for( i in 1:5){
sub<-rbind(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%!in%c(0) & full_output$process==sort(unique(full_output$process))[i],]
      , 
      full_output[full_output$dist=="Distance (km)" & full_output$d_val_group%!in%c(0,1) & full_output$process==sort(unique(full_output$process))[i],])

for(z in 1:3){
    sub2<-sub[sub$zone==c("A","B","C")[z],]    


print(sub2$process[1])
print(sub2$zone[1])
print(signif(mean(sub2$percent),digits=3)*100)
print(signif(range(sub2$percent),digits=3)*100)
}}
```

[1] "B_Homogeneous selection"
[1] "A"
[1] 38.5

[1] "B_Homogeneous selection"
[1] "B"
[1] 45.8

[1] "B_Homogeneous selection"
[1] "C"
[1] 58.9



As environmental dissimilarity and geographic distance increased between lakes, homogenous selection increased across horizons from, on average, 38.5% in the redox horizon to 58.9% in the depauperate horizon (Fig. 6, B, C).



```{r}
full_output<-read.csv("qpen_10plusESVs_community_assembly_env_geo_dist_summary_29May2023.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
i=1
    sub<-full_output[full_output$zone=="C",]
sub2<-rbind(sub[sub$dist=="Environmental dissimilarity" & sub$d_val_group%!in%c(0) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],]
      , 
      sub[sub$dist=="Distance (km)" & sub$d_val_group%!in%c(0,1) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],])

hs_de<-NULL
hs_vs<-NULL
for (i in 1:length(unique(sub2$d_val_group))){
 sub3<-sub2[sub2$d_val_group==sort(unique(sub2$d_val_group))[i],]

hs_de<-c(hs_de,sub3[sub3$process=="B_Homogeneous selection",]$percent/ sub3[sub3$process=="E_Dispersal limitation",]$percent)
hs_vs<-c(hs_vs,sub3[sub3$process=="B_Homogeneous selection",]$percent/ sub3[sub3$process=="A_Variable selection",]$percent)
    
}
        print(sub3$zone[1])
          print("hs_de")
print(signif(mean(hs_de),digits=3))   
print(signif(range(hs_de),digits=3)) 
          print("hs_vs")
print(signif(mean(hs_vs),digits=3))  
print(signif(range(hs_vs),digits=3)) 

```

[1] "C"

[1] "hs_de"
 
[1] 1.99

[1] 1.28 4.11

[1] "hs_vs"

[1] 8.17

[1]  3.97 17.80

 In the depauperate horizon, homogeneous selection explained the differences between assemblages twice as often as dispersal limitation, on average, and eight times as often as variable selection.






#### ix) mantel tests of RCBray values

These all need to be dist objects

```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
load("WyLakeMicrobes_env_27May2023_qpen_ESVswith10plusreads_results.RData")
require(cluster)
require(stringr)
require(reshape2)
require(geosphere)
require(Hmisc)
require(patchwork)
require(Matrix)
require(vegan)


#can reaload data from here, or just use the qp2 object
qpn<-qp2$result[,c("sample1","sample2","RC")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"RC[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)%in%metadata$samp_names) #all true
table(colnames(dfr)%in%metadata$samp_names) # all true

RCbray<-as.dist(dfr)

#now add in environmental distances (lake bottom water and lake depth)
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
metadata_sub<-metadata[,names(metadata)%in%variables]


table(colnames(dfr)==metadata$samp_names) # all true
table(colnames(dfr)==rownames(metadata_sub)) # all true 

env_dist <- as.dist(as.matrix(daisy(scale(metadata_sub), metric="gower")))
table(labels(RCbray)==labels(env_dist))


# geographic distance

#Lat&lon to distance in meters
xy <- data.frame(X = metadata$longitude, Y = metadata$latitude)
rownames(xy)<-metadata$samp_names
dist_m_output<-distm(xy)
rownames(dist_m_output)<-rownames(xy)
names(dist_m_output)<-rownames(xy)
geo_dist<-as.dist(dist_m_output)

#check to make sure all labels match!
table(labels(RCbray)==labels(env_dist)) #all true
table(labels(RCbray)==labels(geo_dist)) #all true

mantel(RCbray, env_dist)
mantel(RCbray, geo_dist)

#add partial mantel test, spatially structured environmental variables
mantel.partial(RCbray, env_dist, geo_dist, method = "pearson", permutations = 999)
mantel.partial(RCbray, geo_dist, env_dist, method = "pearson", permutations = 999)
```

Call:
mantel(xdis = RCbray, ydis = env_dist) 

Mantel statistic r: 0.2452 
      Significance: 0.001 

Upper quantiles of permutations (null model):
    90%     95%   97.5%     99% 
0.00974 0.01260 0.01558 0.01895 
Permutation: free
Number of permutations: 999



Call:
mantel(xdis = RCbray, ydis = geo_dist) 

Mantel statistic r: 0.2039 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0116 0.0155 0.0191 0.0237 
Permutation: free
Number of permutations: 999




Call:
mantel.partial(xdis = RCbray, ydis = env_dist, zdis = geo_dist,      method = "pearson", permutations = 999) 

Mantel statistic r: 0.2425 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0101 0.0131 0.0150 0.0171 
Permutation: free
Number of permutations: 999




Call:
mantel.partial(xdis = RCbray, ydis = geo_dist, zdis = env_dist,      method = "pearson", permutations = 999) 

Mantel statistic r: 0.2005 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0113 0.0148 0.0187 0.0228 
Permutation: free
Number of permutations: 999



#### x) deeper comparisons

```{r}
require(ggplot2)

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")
comps_backup<-read.csv("qpen_10plusESVs_allcomparisons_29May2023.csv", header=T, row.names=1)
comps<-comps_backup
comps$d_val<-comps$abs_cm
comps<-comps[is.na(comps$d_val)==F,]
comps<-comps[comps$d_val>26,] # 119 comparisons, so no many compared to the other ones

tmp2<-comps
tally<-data.frame(n=NULL,process=NULL,percent=NULL)
proc<-unique(comps_backup$process)
for(p in 1:5){
        tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2)))
}
tally$group<-rep("Deep comparisons", nrow(tally))

EAP_plot<-ggplot(tally, aes(x = group, y = percent , fill = process)) +
        geom_bar(stat="identity") + scale_fill_manual(values=new_colors,labels= c("Variable selection", "Homogeneous selection", "Drift", "Homogenizing dispersal", "Dispersal limitation" )) + guides(fill=guide_legend(title="Assembly process")) +  xlab(" ") +
  ylab("Proportion (%)") +
pdf("Figures/SupplementaryFigures/SFig2_deep_community_assembly_6July2023.pdf", height=4, width=4)
EAP_plot
dev.off()

```



#### xi) CAP sediment characteristics

```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")
load("WyLakeMicrobes_env_27May2023_qpen_ESVswith10plusreads_results.RData")


#can reaload data from here, or just use the qp2 object
qpn<-qp2$result[,c("sample1","sample2","process")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"process[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
table(colnames(dfr)==metadata$samp_names) # all true


#now select the sediment characteristics to examine
#using objects from above
variables<-c("pH"
, "d_13_c"  
, "cn"
, "sulfur_perc"     
, "water_perc"     
, "protein_per") 

#pull out metadata

metadata_sub<-metadata[,names(metadata)%in%variables]

table(colnames(dfr)==rownames(metadata_sub)) # all true 


daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))
table(colnames(daisy.mat)==colnames(dfr)) # all true
table(rownames(daisy.mat)==rownames(dfr)) # all true


daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
#there are a number of samples that don't have the data specified in the variables, therefore they are listed as NA and removed here.
env_dist<-melt(daisy.mat, na.rm=TRUE)

env_dist_reexpand <- reshape(env_dist, direction="wide", idvar="Var1", timevar="Var2")
rownames(env_dist_reexpand)<-env_dist_reexpand$Var1
env_dist_reexpand$Var1<-NULL
colnames(env_dist_reexpand)<-str_split_fixed(colnames(env_dist_reexpand),"value[.]",n=2)[,2]

#figure out which ones were different
setdiff(rownames(env_dist_reexpand),colnames(env_dist_reexpand))
setdiff(colnames(env_dist_reexpand),rownames(env_dist_reexpand))
env_dist_reexpand$SV0226L<-rep(NA,nrow(env_dist_reexpand))
env_dist_reexpand[nrow(env_dist_reexpand)+1,] <- NA
rownames(env_dist_reexpand)[nrow(env_dist_reexpand)]<-"33_1_10_DNA"

env_dist_reexpand<-env_dist_reexpand[order(row.names(env_dist_reexpand)), ]
table(rownames(env_dist_reexpand)==colnames(env_dist_reexpand)) #all true

#how many NAs in each and overlap for metadata
#metadata_sub[,metadatacolnames(env_dist_reexpand)]
met<-metadata_sub[rownames(metadata_sub)%in% colnames(env_dist_reexpand),]
#pH, cn and percent water are present in most samples, but then half have d13c and half the sulfur and protein percent

#subset the process/dfr data frame by the comparisons in metadata
dfr<-dfr[colnames(env_dist_reexpand),colnames(env_dist_reexpand)]

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)==rownames(env_dist_reexpand)) #all true
table(colnames(dfr)==colnames(env_dist_reexpand)) #all true

#melt back to pairwise comparisons
env_dist<-melt(as.matrix(env_dist_reexpand))
process<-melt(as.matrix(dfr))


table(process$Var1==env_dist$Var1) # all true
table(process$Var2==env_dist$Var2) # all true 
process$env_dist<-env_dist$value
process<-process[complete.cases(process),]


pairwise<-process

names(pairwise)[1]<-"s1_samp_names"
pairwise$s1_samp_names<-as.character(pairwise$s1_samp_names)
names(pairwise)[2]<-"s2_samp_names"
pairwise$s2_samp_names<-as.character(pairwise$s2_samp_names)
names(pairwise)[3]<-"process"

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

pairwise<-merge(pairwise, metadata_s1, by="s1_samp_names")
pairwise<-merge(pairwise, metadata_s2, by="s2_samp_names")

#remove metadata notes
pairwise$s1_notes<-NULL
pairwise$s2_notes<-NULL
pairwise$s1_Notes_sed_water_wt<-NULL
pairwise$s2_Notes_sed_water_wt<-NULL
pairwise$s1_Notes_carbon_nitrogen<-NULL
pairwise$s2_Notes_carbon_nitrogen<-NULL
pairwise$s1_Notes._lake_sed_pH<-NULL
pairwise$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
pairwise$abs_cm<-rep(NA, nrow(pairwise))
i=1
for(i in 1:nrow(pairwise)){
  ifelse(pairwise$s1_lake_drive[i]==pairwise$s2_lake_drive[i],pairwise$abs_cm[i]<-abs(pairwise$s2_depth[i]-pairwise$s1_depth[i]),NA)
}

# calculate geographic distance

require(geosphere)
for(i in 1:nrow(pairwise)){
        pairwise$geo_dist[i]<-as.numeric(distm(data.frame(X = pairwise$s1_longitude[i], Y = pairwise$s1_latitude[i]),data.frame(X = pairwise$s2_longitude[i], Y = pairwise$s2_latitude[i])))
}

pairwise$geo_dist_km<-pairwise$geo_dist/1000

write.csv(pairwise, "qpen_10plusESVs_sediment_characteristics_10July2023.csv")

```

plot all zones together

```{r}

qpn<-read.csv("qpen_10plusESVs_sediment_characteristics_10July2023.csv", header=T, row.names=1)
#subset by samples within the same core
downcore<-qpn[is.na(qpn$abs_cm)==F & qpn$abs_cm<27 ,]
# we don't want to subset only samples within the same core, but really just want samples that are comparable ANYWHERE
# downcore<-qpn

downcore$d_val<-downcore$env_dist
downcore$d_val_group_breaks<-cut2(downcore$d_val, g=10)
downcore$d_val_group<-as.numeric(cut2(downcore$d_val, g=10))
levels(downcore$d_val_group_breaks)
break_labels<- c("0 to <0.03" ,"0.03 to <0.05" ,"0.05 to <0.06", "0.06 to <0.08" ,"0.08 to <0.10" ,"0.10 to <0.13"
,"0.13 to <0.15" ,"0.15 to <0.20" ,"0.20 to <0.28", "0.28 to 1")
# [ includes ( up to 

tmp<-downcore
tally<-data.frame(process=NULL,percent=NULL, d_val_group=NULL,n=NULL)
groups<-sort(unique(downcore$d_val_group))
i=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  processes<-as.data.frame(table(tmp2$process)/nrow(tmp2))
  colnames(processes)[1]<-"process"
  colnames(processes)[2]<-"percent"
  processes$process<-as.character(processes$process)
  processes$d_val_group<-rep(groups[i],nrow(processes))
  processes$n<-rep(nrow(tmp2),nrow(processes))
  tally<-rbind(tally,processes)
}
  

tally[tally$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
tally[tally$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
tally[tally$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
tally[tally$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
tally[tally$process=="Undominated",]$process<-"C_Drift"

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

        ggplt <- ggplot(tally,            
                        aes(x = d_val_group,
                            y = percent,
                            color= process)) +  geom_line(linewidth=2) +geom_point(size=3) + theme_bw() + scale_x_continuous(breaks=seq(1,length(groups),1), 
                                                                                                                             labels=break_labels) + xlab(label = "Sediment characteristic\ndissimilarity")+ ylab(label = "Proportion") + geom_line(linewidth=2) +   labs(color="Assembly process")    +theme(axis.ticks.x = element_blank()) + scale_color_manual(values=new_colors, labels=c("Variable selection",  "Homogeneous selection",    "Drift",  "Homogenizing dispersal" , "Dispersal limitation" )) + theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,.75) + theme(axis.text.x = element_text(angle = 45,hjust=1))+ guides(color = guide_legend(override.aes = list(linewidth = 6))) +
                theme(axis.text=element_text(color="black"))+
                theme(axis.text.x = element_text(angle = 60,hjust=1))+
                theme(text=element_text(size=14), #change font size of all text
                      axis.text=element_text(size=14), #change font size of axis text
                      axis.title=element_text(size=15), #change font size of axis titles
                      plot.title=element_text(size=14), #change font size of plot title
                      legend.text=element_text(size=14), #change font size of legend text
                      legend.title=element_text(size=15),
                      panel.grid.minor = element_blank(), 
                      panel.grid.major.x = element_blank()) #change font size of legend title 

#pdf("Figures/SupplementaryFigures/CAP_sediment_characteristics_intracore_10July2023.pdf", height=3.5, width=6)
pdf("Figures/SupplementaryFigures/CAP_sediment_characteristics_intercore_10July2023.pdf", height=3.5, width=6)
ggplt
dev.off()

unique(tally$n)
# 4277 4276






```

GAMS
```{r}
model_results<-data.frame(process=NULL, devex=NULL, p=NULL)

#Plot the sediment depth GAM for each process
jpeg("Figures/sedchar_GAM_11Jan2023.jpg", height=3.5, width=12, unit="in",res = 400)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="black", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels)),1), las=2, labels = break_labels)
title(xlab=c("","","Sediment dissimilarity","","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)

Data<-data.frame(x=sub$d_val_group, y=sub$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=new_colors[i], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(new_colors[i], alpha.f = 0.40), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(process=sort(unique(tally$process))[i], devex=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
}
dev.off()

round(mean(model_results$devex),digits=4)
#[1] 0.54 11 Jan 2024
```




## II. individual coniss

```{r}
require(rioja)
require(vegan)
# use transformed data
OTU<-as.data.frame(ps_tr@otu_table)
OTU<-t(OTU)

lake_drives<-unique(metadata$lake_drive)
rn<-rownames(OTU)
meta_sed<-metadata
meta_sed<-meta_sed[order(match(rownames(meta_sed),rownames(OTU))),]
table(meta_sed$samp_names==rownames(OTU)) #all true
which(table(metadata$lake_drive)<2)

#remove lakes with one sample
lake_drives<-lake_drives[lake_drives!="BN_1"]
lake_drives<-lake_drives[lake_drives!="ML_1"]

#lakes with two samples, can't be used
lake_drives<-lake_drives[lake_drives!="LB_1"]
lake_drives<-lake_drives[lake_drives!="NB_1"]
lake_drives<-lake_drives[lake_drives!="SG_1"]


#individual lake CONISS clustering
pdf("Figures/ForRevision_CONISS_individ_4Jan2024.pdf",height=12,width=17)
i=1
par(mfrow=c(5,9),mar=c(2,4,2,0))
for(i in 1:length(lake_drives)){
  subset<-meta_sed[meta_sed$lake_drive==lake_drives[i],]
  subset<-subset[order(subset$depth),]
  names<-subset$samp_names
  rows<-which(rn%in%names)
  sub_otu<-as.data.frame(OTU[rows,])
  sub_otu$rownames<-rownames(sub_otu)
  new_dataset <- sub_otu[match(names, sub_otu$rownames), ]       
  rownames(new_dataset)==new_dataset$rownames
  rownames(new_dataset)==rownames(subset)
  new_dataset$rownames<-NULL
  if(length(unique(subset$depth)) < length(subset$depth)){
      dup<-subset$depth[which(duplicated(subset$depth))]
      pos<-which(subset$depth==dup)
        subset$depth[pos[2]]<-subset$depth[pos[2]]+0.5
  }
  rownames(new_dataset)<-subset$depth
  new_dataset<-as.matrix(new_dataset)
  dist<-vegdist(new_dataset)
  clust<-chclust(dist)
  plot(clust, xvar=as.numeric(clust[["labels"]]), main=paste(subset$lake_name[1],subset$drive[1], sep=" "), ylim= c(0,5), hang=-1, horiz=TRUE, x.rev=TRUE)
}
dev.off()

```

## Crenarchaeota
```{r}
sub<-subset_taxa(ps_tr, Phylum=="Crenarchaeota")
sums<-as.data.frame(rowSums(as.data.frame(otu_table(sub))))
sums$otu<-row.names(sums)

centroid=otu14
2.184803731
centroid=otu14

centroid=otu8
2.167314419
centroid=otu8

centroid=otu41
1.277302759
centroid=otu41

centroid=otu67
0.862125923
centroid=otu67

centroid=otu94
0.777594248
centroid=otu94

seqs<-Biostrings::readDNAStringSet("OriginalFiles/zotus_nonchimeric.fa") 
seqs@ranges@NAMES<-stringr::str_split(seqs@ranges@NAMES,pattern = ";", 3, simplify = T)[,1]
seqs_sub<-seqs[c("centroid=otu94","centroid=otu67","centroid=otu41","centroid=otu8","centroid=otu14")]
Biostrings::writeXStringSet(seqs_sub,filepath = "TopCren_9Jan2024.fasta", format = "fasta")

taxa<-as.data.frame(tax_table(sub))
taxa$otu<-as.numeric(stringr::str_split_fixed(row.names(taxa),2, pattern="otu")[,2])

sub<-subset_taxa(ps_tr, Family=="Nitrosotaleaceae")
sub<-tax_glom(sub, taxrank = "Family", NArm = FALSE)
sub<-psmelt(sub)
plot(sub$bin_depth, sub$Abundance, xlim=c(0,26))
summary(lm(sub$Abundance~sub$bin_depth))

sub<-subset_taxa(ps_tr, Phylum=="Euryarchaeota")
sub<-tax_glom(sub, taxrank = "Phylum", NArm = FALSE)
sub<-psmelt(sub)
plot(sub$bin_depth, sub$Abundance, xlim=c(0,26))
summary(lm(sub$Abundance~sub$bin_depth))

sub<-subset_taxa(ps_tr, Phylum=="Planctomycetota")
taxa<-as.data.frame(tax_table(sub))

sub<-tax_glom(sub, taxrank = "Genus", NArm = FALSE)
sub<-psmelt(sub)
plot(sub$bin_depth, sub$Abundance, xlim=c(0,26))
summary(lm(sub$Abundance~sub$bin_depth))


```


```{r}
require(mgcv)
#determine top 3 ESVs
means <- as.data.frame(rowMeans(ps_tr@otu_table))
names(means)<-"val"
means$otu<-rownames(means)
avgabundtax<-means[order(means$val,decreasing=T),][1:10,]
top10esvs<-merge(avgabundtax,tax_tab,by="row.names")
top10esvs<-top10esvs[order(top10esvs$val,decreasing=T),]
Eury_esvs<-top10esvs$Row.names[1:3]

# subset ps_tr by top 3 esvs
ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
tax_tmp<-as.data.frame(ps_tr_26@tax_table@.Data)
row_names<-rownames(tax_tmp)

#make a string with all of the assignments up to Family
tax_tmp$centroid <-rownames(tax_tmp)
ps_tr_26@tax_table@.Data<-as.matrix(tax_tmp)

sub<-subset_taxa(ps_tr_26, centroid%in%Eury_esvs)
melt<-psmelt(sub)

pdf("Figures/SFig2_top3_ESVs_9Jan2024.pdf", width=10, height =4)
par(mfrow=c(1,3))
titles<-c("Methanoregula","Methanosaeta","MBG-D")
i=1
gam_res<-list()
for(i in 1:3){
        tmp<-melt[melt$centroid==Eury_esvs[i],]
        Data<-data.frame(x=tmp$bin_depth,y=tmp$Abundance)
        Data<-Data[order(Data$x),]
        dat_gam=gam(y~s(x, k=5), data=Data)
        pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
        plot(Data$x,Data$y, pch=16, col="#00000050", ylab = "Relative abundance", xlab="Sediment depth (cm)", main=titles[i])
        lines(Data$x,pred$fit, col="#225ea8", lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor("#41b6c4", alpha.f = 0.40), border = NA)
        gam_res[[i]]<-summary(dat_gam)
        text(x=23, y=max(Data$y)*0.9, paste("R-sq: ",round(gam_res[[i]]$r.sq, digits=3), sep=""))
        text(x=22, y=max(Data$y)*0.8, paste("P-val: ",signif(gam_res[[i]]$s.pv, digits=3), sep=""))
         text(x=1, y=max(Data$y)*0.95, c("a", "b", "c")[i], cex=2)
        
}
dev.off()
```


## 4. new NMDS

```{r}
ps_table <- data.frame(otu_table(ps_tr))
ps_table <-t(ps_table)
sd_sed <- data.frame(sample_data(ps_tr))

ord_baseR<-metaMDS(ps_table, distance = "bray")
# Ran 29May2023
# Run 0 stress 0.1707505 
# Run 1 stress 0.1923034 
# Run 2 stress 0.1930776 
# Run 3 stress 0.1974319 
# Run 4 stress 0.2061988 
# Run 5 stress 0.1986631 
# Run 6 stress 0.4193641 
# Run 7 stress 0.1965793 
# Run 8 stress 0.198454 
# Run 9 stress 0.4193671 
# Run 10 stress 0.1963773 
# Run 11 stress 0.1957859 
# Run 12 stress 0.1903609 
# Run 13 stress 0.1973567 
# Run 14 stress 0.192619 
# Run 15 stress 0.1990084 
# Run 16 stress 0.1933836 
# Run 17 stress 0.2008754 
# Run 18 stress 0.2063872 
# Run 19 stress 0.1992947 
# Run 20 stress 0.1928635 
# *** Best solution was not repeated -- monoMDS stopping criteria:
#      3: no. of iterations >= maxit
#     12: stress ratio > sratmax
#      5: scale factor of the gradient < sfgrmin

fig<-ordiplot(ord_baseR, type="points")

NMDS1<-fig$sites[,1]
NMDS2<-fig$sites[,2]

fig_sites<-as.data.frame(fig[["sites"]])
table(fig_sites$NMDS2==NMDS2) #same for both NMDS1 and NMDS2


fig_sites$samp_names<-rownames(fig_sites)
fig_sites$samp_names<-gsub("X","",as.character(fig_sites$samp_names))
table(names(as.data.frame(ps_tr@otu_table))==fig_sites$samp_names) # all true 

#add in metadata to the dataframe with the NMDS
ord_df<-merge(fig_sites,sd_sed, by="samp_names")

#8c510a darker brown
#a6611a # dark brown
#dfc27d
#80cdc1
#018571 # dark teal

darkertan<-darken("#dfc27d", 0.1)
#C4AD79

ord_df$zone_col<-rep('#01857180',nrow(ord_df))
ord_df[ord_df$bin_depth%in%c(6,8,10,12),]$zone_col<-"#C4AD7980"
ord_df[ord_df$bin_depth%in%c(14,16,18,20,22,24,26),]$zone_col<-'#a6611a80'
ord_df[ord_df$depth>26,]$zone_col<-'#00000080' #black

zone_colors<- c('#018571','#dfc27d','#a6611a','#000000')

sd_sed$bottom_water_temp<-sd_sed$water_sample_t_bot
sd_sed$lake_depth<-sd_sed$max_lake_depth
sd_sed$sediment_depth<-sd_sed$depth

#if you want first axis reversed!
ord_df$NMDS1<-(ord_df$NMDS1*(-1))

ord.fit <- envfit(ord_baseR ~  sediment_depth + lake_depth + bottom_water_temp ,  data = sd_sed,  perm = 1000, na.rm = TRUE)
ord.fit[["vectors"]][["arrows"]][1,1]<-(ord.fit[["vectors"]][["arrows"]][1,1]*(-1))

#save.image("NMDS_29May2023.Rdata")
```

#Add more variables in with vectors
```{r}
load("NMDS_29May2023.Rdata")


ord.fit <- envfit(ord_baseR ~ depth + max_lake_depth + water_sample_t_bot +   water_sample_ph_bot + water_sample_do_bot + water_sample_t_surf + water_sample_ph_surf + water_sample_do_surf + c_perc  + n_perc  + d_13_c,  data = sd_sed,  perm = 1000, na.rm = TRUE)
ord.fit[["vectors"]][["arrows"]][1,1]<-(ord.fit[["vectors"]][["arrows"]][1,1]*(-1))

ord_df$shape<-rep(16,nrow(ord_df))
ord_df[ord_df$depth>26,]$shape<-8
ord_df[ord_df$depth>26,]$zone_col<-'#a6611a' #black

ord_df$size<-rep(1.5,nrow(ord_df))
ord_df[ord_df$depth>26,]$size<-1
```
more variables 
```{r}
pdf("Figures/NMDS_11Jan2025_moreVars.pdf", width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,pch=ord_df$shape,cex=ord_df$size, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col=ord_df$zone_col,xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
plot(ord.fit, labels=c("sediment \n depth","lake depth","bottom water temperature","bottom water pH", "bottom water DO" ,"surface water temperature" ,"surface water pH" ,"surface water DO"),p.max=0.05, col="black",lwd=6, cex=1.2)
dev.off()
```

more variables with sed
```{r}
pdf("Figures/NMDS_11Jan2025_moreVars_sedtoo.pdf", width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,pch=ord_df$shape,cex=ord_df$size, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col=ord_df$zone_col,xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
plot(ord.fit, labels=c("sediment \n depth","lake depth","bottom water temperature\n","bottom water pH", "bottom water DO\n\n\n\n" ,"surface water temperature" ,"surface water pH" ,"surface water DO", "% carbon", "% nitrogen", "d13C"),p.max=0.05, col="black",lwd=6, cex=1.2)
dev.off()
```


### a. adonis testing

redo permanova
```{r}
load("WyLakeMicrobes_Phyloseq_11May2023.RData")

require(parallelDist)
require(vegan)
require(tidyverse)

ps_table <- data.frame(otu_table(ps_tr)) 
names(ps_table)<-colnames(ps_tr@otu_table)
ps_table<-as.data.frame(t(ps_table))

sd <- as.matrix(sample_data(ps_tr))
sd<-as.data.frame(sd)
sd[sd$lake_id=="40",]$water_sample_t_bot<-20.1#JVE - first adding surface water temperature for round lake bottom water temperature since the lake it 1.5 m deep
sd<-sd %>% filter(lake_id != "45")

vars<-c("water_sample_t_bot",
"max_lake_depth",
"depth",
"water_sample_ph_bot",
"water_sample_do_bot",
"water_sample_t_surf",
"water_sample_ph_surf",
"water_sample_do_surf")
sd <- sd[names(sd)%in%vars]
table(is.na(sd)) #make sure there are no NAs

ps_table <- ps_table %>%
  filter(row.names(.) %in% row.names(sd))
table(rownames(ps_table)%in%rownames(sd))


adonis_table<-data.matrix(ps_table) 
adonis_dist<-parallelDist::parDist(adonis_table, method = "bray") 
adonis2(adonis_dist ~water_sample_t_bot +
max_lake_depth + 
depth+ 
water_sample_ph_bot+
water_sample_do_bot+
water_sample_t_surf+
water_sample_ph_surf+
water_sample_do_surf, data = sd) 
```

adonis2(adonis_dist ~water_sample_t_bot +
+ max_lake_depth + 
+ depth+ 
+ water_sample_ph_bot+
+ water_sample_do_bot+
+ water_sample_t_surf+
+ water_sample_ph_surf+
+ water_sample_do_surf, data = sd) 
Permutation test for adonis under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 999

adonis2(formula = adonis_dist ~ water_sample_t_bot + max_lake_depth + depth + water_sample_ph_bot + water_sample_do_bot + water_sample_t_surf + water_sample_ph_surf + water_sample_do_surf, data = sd)
                    Df SumOfSqs      R2      F Pr(>F)    
water_sample_t_bot  33   64.822 0.36336 8.2004  0.001 ***
max_lake_depth       1    1.066 0.00598 4.4503  0.001 ***
depth               40   20.286 0.11371 2.1172  0.001 ***
Residual           385   92.222 0.51695                  
Total              459  178.397 1.00000                  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1



```{r}
# install development version from Github
# install devtools if not found - install.packages("devtools")
devtools::install_github("cont-limno/LAGOSUS", dependencies = TRUE)
```

```{r}
library(LAGOSUS)

# only the locus module is currently public
lagosus_get(dest_folder = lagosus_path())


# an example for members of the dev team to specify local data folder paths
lagosus_compile(
  locus_version = "1.0",
  locus_folder = "~/Downloads/LAGOSUS_LOCUS/LOCUS_v1.0",
  limno_version = "2.1",
  limno_folder = "~/Downloads/LAGOSUS_LIMNO/US/LIMNO_v2.1/Final exports",
  depth_version = "0.1",
  depth_folder = "~/Downloads/LAGOSUS_DEPTH/DEPTH_v0.1",
  geo_version = "1.0",
  geo_folder = "~/Downloads/LAGOSUS_GEO/GEO_EXPORT_BETA_v1",
  dest_folder = lagosus_path())
```


# alphaproteobacteria and desulfobacterota

```{r}
sub<-subset_samples(ps_tr, bin_depth<27)
sub<-subset_taxa(sub, Phylum=="Desulfobacterota")
sub<-tax_glom(sub, taxrank = "Family")
plot_bar(sub, x="bin_depth", fill="Family") + geom_bar(aes(color=Family, fill=Family), stat="identity", position="stack")+
        scale_fill_manual(values = c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861")) + scale_color_manual(values=c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861"))




sub<-subset_samples(ps_tr, bin_depth<27)
sub<-subset_taxa(sub, Phylum=="Desulfobacterota")
sub<-tax_glom(sub, taxrank = "Genus")
plot_bar(sub, x="bin_depth", fill="Genus") + geom_bar(aes(color=Genus, fill=Genus), stat="identity", position="stack")+ xlab("Sediment depth (cm)") + 
        scale_fill_manual(values = c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861","#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E")) + scale_color_manual(values=c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861", "#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E"))

```

Looking at denitirification
```{r}

sub<-subset_samples(ps_tr, bin_depth<27)
sub<-subset_taxa(sub, Genus%in%c("Rubrivivax","Pseudomonas"))
sub<-tax_glom(sub, taxrank = "Genus")

plot_bar(sub, x="bin_depth", fill="Genus") + geom_bar(aes(color=Genus, fill=Genus), stat="identity", position="stack")+ xlab("Sediment depth (cm)") + 
        scale_fill_manual(values = c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861","#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E")) + scale_color_manual(values=c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861", "#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E"))

tax_table(sub)


```



