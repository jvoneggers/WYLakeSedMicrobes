---
title: "WY Lake Sediment Prokaryotic Community Analyses"
author: "Jordan Von Eggers"
date: "2024-01-19"
output: html_document
editor_options: 
  chunk_output_type: inline
---

# load packages
```{r}
require(tidyverse)
require(vegan)
require(phyloseq)
require(beepr)
require(parallelDist)
require(colorspace)
require(pivottabler)
require(reshape2)
require(rioja)
require(Biostrings)
require(ape)
require(caret)
require(picante)
require(cluster)
require(geosphere)
require(Hmisc)
require(patchwork)
require(mgcv)
require(Matrix)
require(metagMisc)
sessionInfo()
```
R version 4.2.1 (2022-06-23)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Monterey 12.6.7

Matrix products: default
LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] metagMisc_0.0.4     Matrix_1.5-4        mgcv_1.9-1          patchwork_1.2.0    
 [5] Hmisc_5.1-1         geosphere_1.5-18    cluster_2.1.6       picante_1.8.2      
 [9] nlme_3.1-164        caret_6.0-94        ape_5.7-1           Biostrings_2.66.0  
[13] GenomeInfoDb_1.34.9 XVector_0.38.0      IRanges_2.32.0      S4Vectors_0.36.1   
[17] BiocGenerics_0.44.0 rioja_1.0-6         reshape2_1.4.4      pivottabler_1.5.5  
[21] colorspace_2.1-0    parallelDist_0.2.6  beepr_1.3           phyloseq_1.42.0    
[25] vegan_2.6-4         lattice_0.22-5      permute_0.9-7       lubridate_1.9.3    
[29] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        
[33] readr_2.1.5         tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.4      
[37] tidyverse_2.0.0 

other attached packages:
[1] iCAMP_1.5.12

# Part III: Data Analysis

## 0. Load data

For all numbered analyses, begin by loading the phyloseq object:
```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")
```


## 1. Community assembly processes

### a. Phylogenetic tree 

#### i. Subset ESVS with 10+ reads
```{r}
ESV<-as.data.frame(otu_table(ps))
ESV<-t(ESV)
ESV<-ESV[order(rownames(ESV)),]

table(colSums(ESV)<10)
Sys.Date()
# FALSE  TRUE 
# 28488 64357 
# [1] "2024-01-19"

mean(colSums(ESV)) #53 reads on average - "2024-01-19"

lessthan10<-which(colSums(ESV)<10)
ESV_10plusreads<-ESV[,-lessthan10]
dim(ESV_10plusreads)
# 478 28488 - "2024-01-19"
table(colSums(ESV_10plusreads)<10)# all FALSE
```

#### ii. Subset fasta file with sequences

In local R, subset fasta file by the ESVs with 10+ reads (normalized reads)
```{r}
seqs<-Biostrings::readDNAStringSet("OriginalFiles/zotus_nonchimeric.fa") 
seqs@ranges@NAMES<-stringr::str_split(seqs@ranges@NAMES,pattern = ";", 3, simplify = T)[,1]

seqs_sub<-seqs[colnames(ESV_10plusreads)]
table(seqs_sub@ranges@NAMES %in% colnames(ESV_10plusreads)) # all TRUE
table(colnames(ESV_10plusreads)%in%seqs_sub@ranges@NAMES) # all TRUE
rm(list=ls()[! ls() %in% c("ESV_10plusreads", "seqs_sub" )])
#save.image(paste0(Sys.Date(),"_WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads.RData"))
#writeXStringSet(seqs_sub,filepath = paste0(Sys.Date(),"_ESVs_with10ormorereads_forBeartooth.fasta"), format = "fasta")
```

copy the fasta file over to the supercomputer

```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/2024-01-19_ESVs_with10ormorereads_forBeartooth.fasta jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylogenetic_tree
```

#### iii. Make phylogenetic tree

Using clustalo to align and then fasttree to make the tree

align_maketree.sh
```{bash}
#!/bin/bash
#SBATCH --job-name phylotree
#SBATCH --mem=120GB
#SBATCH --time=1-00:00:00
#SBATCH --cpus-per-task=6
#SBATCH --account=microbiome
#SBATCH --output=phylotree_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load arcc/1.0 miniconda3/4.12.0
conda activate shotgun_env
cd /project/seddna/jvonegge/WY_lake_microbes/16S/phylogenetic_tree

clustalo -i 2024-01-19_ESVs_with10ormorereads_forBeartooth.fasta -o 2024-01-19_tempfile_muscled.fa -v --threads=6

FastTree -nt 2024-01-19_tempfile_muscled.fa > 2024-01-19_ESVs_with10ormorereads_PhylogeneticTree.nwk
```

Copy back to local computer
```{bash}
rsync jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylogenetic_tree/2024-01-19_ESVs_with10ormorereads_PhylogeneticTree.nwk /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes
```

### b. Test for phylogenetic signal 

Code for testing for phylgenetic signals provided by Dr. John Pearman at Cawthorn Institute in Nelson, NZ

For computational tractability, we subset the phylogenetic tree (made with ESVs with 10 or more reads) by selecting the most abundant 3,500 ESVs in each depth bin (0-26 by 2)

```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")
all_depths<-NULL
i=1
cm<-unique(ps_tr@sam_data$bin_depth)
for(i in 1:length(cm)){
  ps_tmp <- subset_samples(ps_tr, bin_depth==cm[i]) 
  ps_tmp <- filter_taxa(ps_tmp, function(x) sum(x) > 0, TRUE)
  means <- as.data.frame(rowMeans(ps_tmp@otu_table))
  names(means)<-"val"
  means$otu<-rownames(means)
  avgabundtax<-means[order(means$val,decreasing=T),]$otu[1:3500]
  all_depths<-c(all_depths,avgabundtax)
}

unique_alldepths<-unique(all_depths)
length(unique_alldepths)

my_subset <- subset(otu_table(ps), rownames(otu_table(ps)) %in% unique_alldepths)
table(sort(rownames(otu_table(my_subset)))==sort(unique_alldepths)) #make sure this is all TRUE
#  TRUE 
# 10954
```


```{r}
#Load phylogenetic tree
phylo <- read.tree("2024-01-19_ESVs_with10ormorereads_PhylogeneticTree.nwk")
#subset by the abundant 10948 ESVs
physeq <- merge_phyloseq(my_subset, tax_table(ps), sample_data(ps), phylo)
tree <- physeq@phy_tree
# make sure only the 10948 ESVs are in the tree
table(tree$tip.label%in%unique_alldepths) # all TRUE
table(unique_alldepths%in%tree$tip.label) # six false here
rm(physeq)

#using just the 10948 most abundant ESVs
#match up with metadata
OTU<-as.data.frame(otu_table(my_subset))
OTU<-t(OTU)
OTU<-OTU[order(rownames(OTU)),] #site by species

#order metadata
metadata<-metadata[order(rownames(metadata)),] 
#subset metadata
metadata.a <- metadata %>% select(depth, elevation_meters,max_lake_depth, water_sample_ph_bot, water_sample_do_bot, water_sample_t_bot,pH,n_perc, c_perc)

#make OTU and metadata match
table(rownames(OTU)==rownames(metadata)) #all true


#Predict the missing metadata
set.seed(496)

metadata.1 <-
  preProcess(metadata.a,
             method = c("bagImpute"))

metadata.2  <- 
  predict(metadata.1 , metadata.a)


OTU_log <- log(OTU + 1) 

OTU_log.p <- match.phylo.comm(tree, OTU_log)$comm
tree_log.p <- match.phylo.comm(tree, OTU_log)$phy

phydist <- cophenetic(tree_log.p)

#phylogenetic distance
phydist_hel <- decostand(phydist, method="hellinger")

#from site x species to species x site
table <- t(OTU_log)

env.var.names<-colnames(metadata.2)

#loop through each environmental variable and create a list of each "final table"
all_env.vars_tab<-list()
q=1
for(q in 1:length(env.var.names)){

table_env<-rbind(metadata.2[,q],table)
rownames(table_env)[1]<-"env.var"

table_w <- t(table_env) #first column environmental variable 

headTable <- colnames(table_w) 
x <- headTable[1] # The first column is a constant env.var and is being compared to OTU


# Create the final_table empty

m <- matrix(0, nrow = 0, ncol = 3) 
final_table <- data.frame(m)
colnames(final_table)  <- c('ymax','d50', 'xmax') 

# the for loop, to get all otus 1 by 1 compared to env.var

for(i in seq(2,length(headTable),1)) #start at 2 because the 1 is the Eh_mv
{
  y <- headTable[i] # get otu name
  tablei <-  table_w[,c(x,y)] # extract 2 columns to create a new table
  
  head  <- colnames(tablei)
  
  ymax = which.max(tablei[,2]) # get the max relative abundance of the OTU
  
  MaxRow <- tablei[ymax,] # create a table with the line of the max OTU value
 
  tableiInf <- subset(tablei,tablei[,1]<= MaxRow[1]) #create two tables greater and lower than the x coord
  tableiSup <- subset(tablei,tablei[,1]>= MaxRow[1]) #of the max
  
  tableiInfno0 <- subset(tableiInf,tableiInf[,2]>(MaxRow[2]/20)) #remove the observations where the relative OTU abundance is 0
  tableiSupno0 <- subset(tableiSup,tableiSup[,2]>(MaxRow[2]/20)) #remove the observations where the relative OTU abundance is 0
  
  
  #Determine the lowest and highest Eh value where you find the OTU
  
  xInf <- min(tableiInfno0[,1])
  xSup <- max(tableiSupno0[,1])
  
  # calculate the d50
  
  d50  <- 0.68*abs(xSup-xInf)/2
  
  # create the final table for the otu in the loop
  
  tablei_fin  <- matrix(c(MaxRow[2],d50,MaxRow[1]),ncol=3)
  rownames(tablei_fin)  <- c(head[2])
  colnames(tablei_fin)  <- c('ymax','d50', 'xmax')
  
  # add to the final_table the values for each otu 
  final_table <- rbind(final_table,tablei_fin)
  
  
}
#write the table and put into a list
write.table(final_table, paste0(Sys.Date(),"_niche_", env.var.names[q], ".txt"), sep="\t")
all_env.vars_tab[[q]]<-final_table
}

#remove all but the two objects needed for the mantel correlogs
rm(list=ls()[! ls() %in% c("all_env.vars_tab","phydist_hel")])
save.image(paste0(Sys.Date(),"_WyLakeSedMicrobes_PhylogeneticSignal_ForBeartooth.RData"))

```
All taxa but six taxa match, so going ahead with using this since these are not highly abundant ESVs (otuXXXX is in 42K-55K range instead of an abundant ESV that would have a smaller otu number)
OTU_log.p <- match.phylo.comm(tree, OTU_log)$comm
[1] "Dropping taxa from the community because they are not present in the phylogeny:"
[1] "centroid=otu42626" "centroid=otu44283" "centroid=otu47415" "centroid=otu48003" "centroid=otu51396"
[6] "centroid=otu55721"
tree_log.p <- match.phylo.comm(tree, OTU_log)$phy
[1] "Dropping taxa from the community because they are not present in the phylogeny:"
[1] "centroid=otu42626" "centroid=otu44283" "centroid=otu47415" "centroid=otu48003" "centroid=otu51396"
[6] "centroid=otu55721"

```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/2024-01-22_WyLakeSedMicrobes_PhylogeneticSignal_ForBeartooth.RData jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylo_signal
```

#### i) run on Beartooth

make_scripts.sh
```{bash}
#!/bin/bash
#SBATCH --job-name make_scripts
#SBATCH --mem=20GB
#SBATCH --time=10:00:00
#SBATCH --cpus-per-task=1
#SBATCH --account=microbiome
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

for i in {1..9}
do
    # Create a new script file for each iteration
    script_file="phylo_signal_${i}.R"

    # Write the content to the script file
    echo "require(vegan)" > "$script_file"
    echo "load(\"2024-01-22_WyLakeSedMicrobes_PhylogeneticSignal_ForBeartooth.RData\")" >> "$script_file"
    echo "sub1<-all_env.vars_tab[[${i}]]" >> "$script_file"
    echo "sub2<-sub1[match(rownames(phydist_hel), rownames(sub1)), ]" >> "$script_file"
    echo "env_dist<-vegdist(sub2\$xmax, method=\"euclidean\")" >> "$script_file"
    echo "mc_result_${i}<-mantel.correlog(env_dist, D.geo = phydist_hel, nperm=999)" >> "$script_file"
    echo "save.image(paste0(Sys.Date(),\"_WyLakeSedMicrobes_PhylogeneticSignal_MantelCorrResult_${i}.RData\"))" >> "$script_file"

done

```


make_jobs.sh
```{bash}
#!/bin/bash
#SBATCH --job-name make_jobs
#SBATCH --mem=20GB
#SBATCH --time=1:00:00
#SBATCH --cpus-per-task=1
#SBATCH --account=microbiome
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

for i in {1..9}
do
    # Make a new bash job file 
    script_file="run_phylo_signal_${i}.sh"

    # write commands for bach job file using echo
    echo "#!/bin/bash" > "$script_file"
    echo "#SBATCH --job-name phylo_signal" >> "$script_file"
    echo "#SBATCH --mem=20GB" >> "$script_file"
    echo "#SBATCH --time=6-00:00:00" >> "$script_file"
    echo "#SBATCH --cpus-per-task=1" >> "$script_file"
    echo "#SBATCH --account=microbiome" >> "$script_file"
    echo "#SBATCH --output=phylo_signal_%A.out" >> "$script_file"
    echo "#SBATCH --mail-type=ALL" >> "$script_file"
    echo "#SBATCH --mail-user=jvonegge@uwyo.edu" >> "$script_file"
    echo "" >> "$script_file"
    echo "module load gcc/12.2.0 r/4.2.2" >> "$script_file"
    echo "cd /project/seddna/jvonegge/WY_lake_microbes/16S/phylo_signal" >> "$script_file"
    echo "date" >> "$script_file"
    echo "" >> "$script_file"
    echo "srun Rscript phylo_signal_${i}.R" >> "$script_file"
    echo "echo \"srun Rscript phylo_signal_${i}.R\"" >> "$script_file"
    echo "" >> "$script_file"
    echo "echo \"JV finished correlog\"" >> "$script_file"
    echo "date" >> "$script_file"

    # Make the script executable
    chmod +x "$script_file"
done

```

run_phylo_signal_jobs.sh
```{bash}
#!/bin/bash
#SBATCH --job-name phylo_signal
#SBATCH --mem=20GB
#SBATCH --time=2-00:00:00
#SBATCH --cpus-per-task=1
#SBATCH --account=microbiome
#SBATCH --output=phylo_signal_%A.out
#SBATCH --mail-type=ALL

# Run bash jobs for running rscripts for phylogenetic signal
for i in {1..9}
do
    sbatch run_phylo_signal_${i}.sh
done

```


Copy folder back to computer

```{bash}
rsync -r jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/phylo_signal /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/PhylogeneticSignal
```

#### ii) Plot mantel correlograms

```{r}
env.var.names<-c("Sediment depth (cm)",               "Elevation (m)"   , "Max lake depth (m)" ,    
"Bottom water pH", "Bottom water dissolved oxygen", "Bottom water temperature" ,
"Sediment pH"                ,  "Sediment percent nitrogen"            ,  "Sediment percent carbon"    )  

i=1
for(i in 1:9){
load(paste0("PhylogeneticSignal/phylo_signal/",list.files("PhylogeneticSignal/phylo_signal")[i]))}


figs<-list()
figs[[1]]<-mc_result_1
figs[[2]]<-mc_result_2
figs[[3]]<-mc_result_3
figs[[4]]<-mc_result_4
figs[[5]]<-mc_result_5
figs[[6]]<-mc_result_6
figs[[7]]<-mc_result_7
figs[[8]]<-mc_result_8
figs[[9]]<-mc_result_9

i=1
pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_Phylogenetic_signal_mantel_corr.pdf"), height = 8, width=10)
par(mfrow=c(3,3), mar=c(4,4,4,2))
for(i in 1:9){
plot(figs[[i]])
title(main=env.var.names[i])
}
dev.off()


```


### c. iCAMP on the supercomputer

Using the qpen function with ESVs with 10+ reads (the ESV abundance table and the phylogenetic tree)

Copy R environment over to supercomputer
```{bash}
rsync /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes/2024-01-19_WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads.RData jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/iCAMP
```

Move the phylogenetic tree file over into the iCAMP folder on the supercomputer
```{bash}
cp 2024-01-19_ESVs_with10ormorereads_PhylogeneticTree.nwk ../iCAMP
```

qpen_function.R
```{r}
require(phyloseq)
require(iCAMP)
require(ape)
load("../2024-01-19_WyLakeMicrobes_PhyloseqEnv_forPhylogeneticTree_ESVs10PlusReads.RData")
comm<-ESV_10plusreads
tree<-read.tree("../2024-01-19_ESVs_with10ormorereads_PhylogeneticTree.nwk")
table(colnames(ESV_10plusreads)%in%tree[["tip.label"]]) #all TRUE
table(tree[["tip.label"]]%in%colnames(ESV_10plusreads)) #all TRUE


wd0="/project/seddna/jvonegge/WY_lake_microbes/16S/iCAMP/qpen"
nworker=6 # parallel computing thread number
rand.time=1000 # usually use 1000 for real data.
  

  # for a big dataset, pdist.big may be used
  save.wd="/project/seddna/jvonegge/WY_lake_microbes/16S/iCAMP/qpen/pdbig.qpen"
  print(save.wd)
  # please change to the folder you want to save the pd.big output.
  
  pd.big=pdist.big(tree = tree, wd=save.wd, nworker = nworker)
  qp2=qpen(comm=comm, pd=pd.big$pd.file, pd.big.wd=pd.big$pd.wd,
           pd.big.spname=pd.big$tip.label, tree=tree,
           rand.time=rand.time, nworker=nworker)
  setwd(wd0)
save.image("2024-01-19_WyLakeMicrobes_PhyloseqEnv_iCAMP_qpen_output.RData")
```

run_qpen_function.sh
```{bash}
#!/bin/bash
#SBATCH --job-name qpen_10plus
#SBATCH --mem=70GB
#SBATCH --time=3-00:00:00
#SBATCH --cpus-per-task=6
#SBATCH --account=microbiome
#SBATCH --output=qpen_10plus_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=jvonegge@uwyo.edu

module load gcc/12.2.0 r/4.2.2
cd /project/seddna/jvonegge/WY_lake_microbes/16S/iCAMP/qpen

srun Rscript qpen_function.R
echo "srun Rscript qpen_function.R"

echo "finished qpen iCAMP - JVE"
date
```


Copy back to desktop
```{bash}
rsync jvonegge@beartooth.arcc.uwyo.edu:/project/seddna/jvonegge/WY_lake_microbes/16S/iCAMP/qpen/2024-01-19_WyLakeMicrobes_PhyloseqEnv_iCAMP_qpen_output.RData /Users/jordanscheibe/Library/CloudStorage/OneDrive-UniversityofWyoming/LakeSedDNA/Data/WYLakeSedMicrobes/WYLakeSedMicrobes
```


### d. Analyze community assembly output

Here we are used ESVs with 10plus reads

#### i) Merge with metadata
```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")
load("2024-01-19_WyLakeMicrobes_PhyloseqEnv_iCAMP_qpen_output.RData")

#pull out results from iCAMP
qpn<-qp2$result[,c("sample1","sample2","process")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"process[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)%in%metadata$samp_names) #all true
table(colnames(dfr)%in%metadata$samp_names) # all true

#now add in environmental distances (lake bottom water and lake depth)
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

table(colnames(dfr)==metadata$samp_names) # all true
table(colnames(dfr)==rownames(metadata_sub)) # all true 

daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))
table(colnames(daisy.mat)==colnames(dfr)) # all true
table(rownames(daisy.mat)==rownames(dfr)) # all true

daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
env_dist<-melt(daisy.mat, na.rm=TRUE)

process<-melt(as.matrix(dfr), na.rm=T)

table(process$Var1==env_dist$Var1) # all true
table(process$Var2==env_dist$Var2) # all true 
process$env_dist<-env_dist$value

pairwise<-process #overwrite original file

names(pairwise)[1]<-"s1_samp_names"
pairwise$s1_samp_names<-as.character(pairwise$s1_samp_names)
names(pairwise)[2]<-"s2_samp_names"
pairwise$s2_samp_names<-as.character(pairwise$s2_samp_names)
names(pairwise)[3]<-"process"

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

pairwise<-merge(pairwise, metadata_s1, by="s1_samp_names")
pairwise<-merge(pairwise, metadata_s2, by="s2_samp_names")

#remove metadata notes
pairwise$s1_notes<-NULL
pairwise$s2_notes<-NULL
pairwise$s1_Notes_sed_water_wt<-NULL
pairwise$s2_Notes_sed_water_wt<-NULL
pairwise$s1_Notes_carbon_nitrogen<-NULL
pairwise$s2_Notes_carbon_nitrogen<-NULL
pairwise$s1_Notes._lake_sed_pH<-NULL
pairwise$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
pairwise$abs_cm<-rep(NA, nrow(pairwise))
i=1
for(i in 1:nrow(pairwise)){
  ifelse(pairwise$s1_lake_drive[i]==pairwise$s2_lake_drive[i],pairwise$abs_cm[i]<-abs(pairwise$s2_depth[i]-pairwise$s1_depth[i]),NA)
}

# calculate geographic distance
for(i in 1:nrow(pairwise)){
        pairwise$geo_dist[i]<-as.numeric(distm(data.frame(X = pairwise$s1_longitude[i], Y = pairwise$s1_latitude[i]),data.frame(X = pairwise$s2_longitude[i], Y = pairwise$s2_latitude[i])))
}

pairwise$geo_dist_km<-pairwise$geo_dist/1000

#write.csv(pairwise, paste0(Sys.Date(),"_iCAMP_qpen_10plusESVs_allcomparisons.csv"))
```

#### ii) Environmental distance

Looking at this within each respective zone

```{r}
comps_backup<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_allcomparisons.csv", header=T, row.names=1)

comps<-comps_backup

comps$d_val<-comps$env_dist

# make breaks for zone A
comps_tmp<-comps[comps$s1_zone=="A" & comps$s2_zone=="A",]

comps_tmp<-comps_tmp[comps_tmp$d_val!=0,]
comps_tmp$d_val_group_breaks<-cut2(comps_tmp$d_val, g=10)
levels(comps_tmp$d_val_group_breaks)
# [1] "[0.0162,0.117)" "[0.1167,0.163)" "[0.1632,0.210)" "[0.2097,0.240)" "[0.2399,0.276)"
#  [6] "[0.2759,0.323)" "[0.3234,0.384)" "[0.3835,0.454)" "[0.4543,0.540)" "[0.5399,0.722]"
breaks<-c(as.numeric(gsub("\\]","" ,gsub("\\[","",unlist(str_split(as.character(levels(comps_tmp$d_val_group_breaks)), pattern=",")))[c(seq(1, 20, 2),20)])))

# make sure first value is below the minimum env_distance measure that isn't 0
min(comps_backup[comps_backup$env_dist!=0,]$env_dist)
#[1] 0.01621537

# make a bottom break (0.016 - just below the lowest env_dist) that is above zero but below the first break
breaks<-c(0.016,breaks[2:11]) 

full_output<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)

zone<-c("A","B","C")
j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]

sub<-comps_sub[comps_sub$d_val==0,]
sub$d_val_group<-rep(0, nrow(sub))

comps_sub<-comps_sub[comps_sub$d_val!=0,]
comps_sub$d_val_group<-as.numeric(cut(comps_sub$d_val, breaks=breaks))
comps_sub<-rbind(sub, comps_sub)

#breaks_labels<- levels(comps$d_val_group_breaks)
breaks_labels<-c("[0, 0]", "[0.016, 0.12)", "[0.12, 0.16)", "[0.16, 0.21)", "[0.21, 0.24)",
 "[0.24, 0.28)", "[0.28, 0.32)", "[0.32, 0.38)", "[0.38, 0.45)",
"[0.45, 0.54)" ,"[0.54, 0.72]")

tmp<-comps_sub
tally<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)
proc<-unique(comps_backup$process)
groups<-sort(unique(tmp$d_val_group))
i=1
p=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  for(p in 1:length(proc)){
    tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2),d_val_group=groups[i], d_val_inclthisnumandbelow=breaks[i],zone=zone[j], dist="env"))
  }
  }

full_output<-rbind(full_output,tally)
}

Sys.Date()
range(full_output$n)
mean(full_output$n)
# "2024-01-22"
#[1]  171 2020
#[1] 947.6364


#write.csv(full_output, paste0(Sys.Date(),"_iCAMP_qpen_10plusESVs_envdist.csv"))

```

#### iii) Geographic distance

```{r}
comps_backup<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_allcomparisons.csv", header=T, row.names=1)

comps<-comps_backup


comps[comps$s1_lake_id==comps$s2_lake_id & comps$s1_lake_drive!=comps$s2_lake_drive,]$geo_dist_km<-0.001 #add one meter for cores in the same lake
comps$d_val<-comps$geo_dist_km
breaks<-c(seq(0,15,5), seq(100, 300, 200), seq(400,500,100))  ##nothing from  43.30254  174.6661
breaks<-c(0,0.1, breaks[2:8])
full_output<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)


zone<-c("A","B","C")
j=1
for( j in 1:3) {
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]

sub<-comps_sub[comps_sub$d_val==0,]
sub$d_val_group<-rep(0, nrow(sub))

comps_sub<-comps_sub[comps_sub$d_val!=0,]
comps_sub$d_val_group<-as.numeric(cut(comps_sub$d_val, breaks=breaks))
comps_sub<-rbind(sub, comps_sub)

breaks_labels<- c("[0,0]",levels(cut(comps$d_val, breaks=breaks)))

tmp<-comps_sub
tally<-data.frame(n=NULL,process=NULL,percent=NULL,d_val_group=NULL, d_val_inclthisnumandbelow=NULL, zone=NULL,dist=NULL)
proc<-unique(comps_backup$process)
groups<-sort(unique(tmp$d_val_group))
i=1
p=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  for(p in 1:length(proc)){
    tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2),d_val_group=groups[i], d_val_inclthisnumandbelow=breaks[i],zone=zone[j], dist="geo"))
  }
  }
full_output<-rbind(full_output,tally)
#count the number of comparisons in each zone
}

Sys.Date()
range(full_output$n)
mean(full_output$n)
# [1] "2024-01-22"
# [1]   75 2604
# [1] 1158.222

print(breaks_labels)
# [1] "[0,0]"     "(0,0.1]"   "(0.1,5]"   "(5,10]"    "(10,15]"   "(15,100]"  "(100,300]"
# [8] "(300,400]" "(400,500]"

#write.csv(full_output, paste0(Sys.Date(),"_iCAMP_qpen_10plusESVs_geodist.csv"))
```

#### iv) Combine the two dataframes

```{r}
geo_dist_tally<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_geodist.csv", header=T, row.names=1)
env_dist_tally<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_envdist.csv", header=T, row.names=1)
full_output<-rbind(geo_dist_tally,env_dist_tally)

full_output[full_output$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
full_output[full_output$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
full_output[full_output$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
full_output[full_output$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
full_output[full_output$process=="Undominated",]$process<-"C_Drift"


#add in color
full_output$zone_col<-rep('#018571',nrow(full_output))
full_output[full_output$zone=="B",]$zone_col<-"#C4AD79"
full_output[full_output$zone=="C",]$zone_col<-'#a6611a'


#add in xlab as dist column
full_output[full_output$dist=="env",]$dist<-'Environmental dissimilarity'
full_output[full_output$dist=="geo",]$dist<-'Distance (km)'

#write.csv(full_output,paste0(Sys.Date(),"_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv"))

#if count needed
count<-unique(full_output[,c("d_val_group","zone","n","dist")])
#write.csv(count, paste0(Sys.Date(),"_qpen_10plusESVs_count_summary.csv"))
```

#### v) Fig. 6: Environmental and geographic dissimilairty

```{r}
full_output<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)
full_output$proportion<-full_output$percent
full_output$percent<-full_output$percent*100

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

break_labels<-list()
break_labels[[1]]<-c( "0",">0 to 0.1" ,  ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0", "0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")


ggplt<-list()
i=1
j=1
for(j in 1:3){
        sub<-full_output[full_output$zone==sort(unique(full_output$zone))[j],]
for(i in 1:2){
        sub2<-sub[sub$dist==unique(sub$dist)[i],]       
ifelse(j==3, 
       
       
       ggplt[[length(ggplt)+1]] <- ggplot(sub2,            
               aes(x = d_val_group,
                   y = percent,
                   color= process)) +  geom_point(size=3)+ theme_bw()   + xlab(label = sub2$dist[1])+ scale_x_continuous(breaks = sort(unique(sub2$d_val_group)), labels=break_labels[[i]])+ ylab(label = "") + geom_line(linewidth=2) +   labs(color="Assembly process")  + scale_color_manual(values=new_colors)+ theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) +theme(axis.text.x = element_text(angle = 60,hjust=1))+      
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
        axis.text=element_text(size=13), #change font size of axis text
        axis.title=element_text(size=15), #change font size of axis titles
        plot.title=element_text(size=14), #change font size of plot title
        legend.text=element_text(size=14), #change font size of legend text
        legend.title=element_text(size=15)) +
                theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())#change font size of legend title
       
       , 
       
       
              ggplt[[length(ggplt)+1]] <- ggplot(sub2,            
               aes(x = d_val_group,
                   y = percent,
                   color= process)) + geom_point(size=3)+ theme_bw()   + xlab(label = sub2$dist[1])+ scale_x_continuous(breaks = sort(unique(sub2$d_val_group)), labels=break_labels[[i]])+ ylab(label = "") + geom_line(linewidth=2) +   labs(color="Assembly process")   + scale_color_manual(values=new_colors)+ theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) +theme(axis.text.x = element_text(angle = 60,hjust=1))+      
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
        axis.text=element_text(size=13), #change font size of axis text
        axis.title=element_text(size=15), #change font size of axis titles
        plot.title=element_text(size=14), #change font size of plot title
        legend.text=element_text(size=14), #change font size of legend text
        legend.title=element_text(size=15))+ #change font size of legend title
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank()) +
        theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())#change font size of legend title
       )
        }}

pdf(paste0("Figures/",Sys.Date(),"_Fig6_CommAssemProc_EnvDist_GeoDist.pdf"),height=7,width=7)
ggplt[[1]]+ggplt[[2]]+ ggplt[[3]]+ggplt[[4]]+ggplt[[5]]+ggplt[[6]]+ 
  plot_layout(ncol = 2)
dev.off()


```



##### - GAMs: Environmental dissimilarity and geographic distance

These generalized additive models look at the proportion of community assembly processes from within and among comparisons (including cores from the same lake or a different lake)
```{r}
full_output<-read.csv("CommunityAssembly/2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)


break_labels<-list()
break_labels[[1]]<-c( "0",">0 to 0.1" ,  ">0.1 to 5"  , ">5 to 10" , ">10 to 15"  ,">15 to 100" , ">100 to 300", ">300 to 400" ,">400 to 500")
break_labels[[2]]<-c("0", "0.01 to <0.12", "0.12 to <0.16", "0.16 to <0.21", "0.21 to <0.24",
 "0.24 to <0.28", "0.28 to <0.32", "0.32 to <0.38", "0.38 to <0.45",
"0.45 to <0.54" ,"0.54 to 0.72")


model_results<-data.frame(dist=NULL, process=NULL, zone=NULL, dev.exp=NULL, p=NULL)

d=1
for (d in 1:2){
pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_CommAssemProc_",unique(full_output$dist)[d],"_GAM.pdf",sep=""), height=3.5, width=12)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
tally<-full_output[full_output$dist==unique(full_output$dist)[d],]
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="white", xaxt="n")
axis(side=1,cex=0.8, at=seq(0,(length(break_labels[[d]])-1),1), las=2, labels = break_labels[[d]])
title(xlab=c("","",unique(full_output$dist)[d],"","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)
x=1
for(x in 1:3){
sub2<-sub[sub$zone==unique(sub$zone)[x],]
points(sub2$d_val_group,sub2$percent, pch=16, col=sub2$zone_col[x])

#GAM
Data<-data.frame(x=sub2$d_val_group, y=sub2$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=sub2$zone_col[x], lwd=3)
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit),
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(sub2$zone_col[x], alpha.f = 0.20), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(dist=unique(full_output$dist)[d], process=sort(unique(tally$process))[i], zone=unique(sub$zone)[x], dev.exp=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))

}}
dev.off()
}

write.csv(model_results, paste0(Sys.Date(),"_iCAMP_qpen_envdist_geodist_GAMs.csv"))

mean(model_results[model_results$dist=="Environmental dissimilarity",]$dev.exp)
#[1] 0.5626
mean(model_results[model_results$dist=="Distance (km)",]$dev.exp)
#[1] 0.5393333

```




#### vi) Fig. 6: Sediment distance

```{r}
qpn<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_allcomparisons.csv", header=T, row.names=1)

#subset by samples within the same core
downcore<-qpn[is.na(qpn$abs_cm)==F & qpn$abs_cm<27 ,]


downcore$d_val<-abs(downcore$abs_cm)
downcore$d_val_group_breaks<-cut2(downcore$d_val, g=10)
downcore$d_val_group<-as.numeric(cut2(downcore$d_val, g=10))
levels(downcore$d_val_group_breaks)
break_labels<- c("0 to <2.5" ,"2.5 to <5" ,"5 to <7", "7 to <9" ,"9 to <11" ,"11 to <15"
,"15 to <18" ,"18 to <22" ,"22 to <26")
#these are put into 9 groups here instead of the requested 10, must be to make it even.

tmp<-downcore
tally<-data.frame(process=NULL,percent=NULL, d_val_group=NULL,n=NULL)
groups<-sort(unique(downcore$d_val_group))
i=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  processes<-as.data.frame(table(tmp2$process)/nrow(tmp2))
  colnames(processes)[1]<-"process"
  colnames(processes)[2]<-"percent"
  processes$process<-as.character(processes$process)
  processes$d_val_group<-rep(groups[i],nrow(processes))
  processes$n<-rep(nrow(tmp2),nrow(processes))
  tally<-rbind(tally,processes)
}
  


tally$proportion<-tally$percent
tally$percent<-tally$percent*100

tally[tally$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
tally[tally$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
tally[tally$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
tally[tally$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
tally[tally$process=="Undominated",]$process<-"C_Drift"

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

        ggplt <- ggplot(tally,            
                        aes(x = d_val_group,
                            y = percent,
                            color= process)) +  geom_line(linewidth=2) +geom_point(size=3) + theme_bw() + scale_x_continuous(breaks=seq(1,length(groups),1), 
                                                                                                                             labels=break_labels) + xlab(label = "Vertical sediment\ndistance (cm)")+ ylab(label = "Proportion (%)") + geom_line(linewidth=2) +   labs(color="Assembly process")    + scale_color_manual(values=new_colors, labels=c("Variable selection",  "Homogeneous selection",    "Drift",  "Homogenizing dispersal" , "Dispersal limitation" )) + theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,75) + theme(axis.text.x = element_text(angle = 45,hjust=1))+ guides(color = guide_legend(override.aes = list(linewidth = 6))) + theme(legend.position="none")+
                theme(axis.text=element_text(color="black"))+
                theme(axis.text.x = element_text(angle = 60,hjust=1))+
                theme(text=element_text(size=14), #change font size of all text
                      axis.text=element_text(size=14), #change font size of axis text
                      axis.title=element_text(size=15), #change font size of axis titles
                      plot.title=element_text(size=14), #change font size of plot title
                      legend.text=element_text(size=14), #change font size of legend text
                      legend.title=element_text(size=15),
                      panel.grid.minor = element_blank(), 
                      panel.grid.major.x = element_blank()) #change font size of legend title 

pdf(paste0("Figures/",Sys.Date(),"_Fig6_CommAssemProc_SedDist.pdf"), height=3.05, width=3.3)
ggplt
dev.off()

unique(tally$n)
#[1] 372 352 302 283 239 403 163 236 190

#write.csv(tally,paste0(Sys.Date(),"_qpen_10plusESVs_seddist_summary.csv"))

```

##### - GAMs: Sediment distance

Sediment distance (with samples from the same zone)
```{r}
tally<-read.csv("CommunityAssembly/2024-01-22_qpen_10plusESVs_seddist_summary.csv", header=T, row.names=1)
model_results<-data.frame(process=NULL, devex=NULL, p=NULL)

tally$percent<-tally$percent/100
break_labels<- c("0 to <2.5" ,"2.5 to <5" ,"5 to <7", "7 to <9" ,"9 to <11" ,"11 to <15"
,"15 to <18" ,"18 to <22" ,"22 to <26")
new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

#Plot the sediment depth GAM for each process
pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_CommAssemProc_SedDist_GAM.pdf"), height=3.5, width=12)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="black", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels)),1), las=2, labels = break_labels)
title(xlab=c("","","Sediment distance (cm)","","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)

Data<-data.frame(x=sub$d_val_group, y=sub$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=new_colors[i], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(new_colors[i], alpha.f = 0.40), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(process=sort(unique(tally$process))[i], devex=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
}
dev.off()

Sys.Date()
round(mean(model_results$devex),digits=3)
# [1] "2024-01-22"
# [1] 0.891

#write.csv(model_results, paste0(Sys.Date(),"_iCAMP_qpen_seddist_GAMs.csv"))

```

#### viii) Results for manuscript
```{r}
qpn<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_allcomparisons.csv", header=T, row.names=1)
Sys.Date()
(table(qpn$process))/nrow(qpn)

# [1] "2024-01-22"
#    Dispersal.Limitation Heterogeneous.Selection   Homogeneous.Selection 
#              0.34891187              0.23619554              0.38010403 
#  Homogenizing.Dispersal             Undominated 
#              0.01316632              0.02162224 


#selection
round(0.38010403 + 0.23619554, digits=3)*100
# [1] 61.6


#stochastic
round(0.01316632 + 0.02162224 + 0.34891187 , digits=3)*100
# [1] 38.4
```

Fig. 6, A: Sediment distance 

```{r}
full_output<-read.csv("CommunityAssembly/2024-01-22_qpen_10plusESVs_seddist_summary.csv", header=T,row.names=1)
i=1
for( i in 1:5){
sub<-full_output[full_output$d_val_group==1 & full_output$process==sort(unique(full_output$process))[i],]
print(sub$process[1])
print(signif(sub$proportion, digits=3)*100)
}
# [1] "2024-01-30"
# [1] "A_Variable selection"
# [1] 5.38
# [1] "B_Homogeneous selection"
# [1] 71
# [1] "C_Drift"
# [1] 1.61
# [1] "D_Homogenizing dispersal"
# [1] 14.2
# [1] "E_Dispersal limitation"
# [1] 7.8

i=1
for( i in 1:5){
sub<-full_output[full_output$d_val_group%in%c(8,9) & full_output$process==sort(unique(full_output$process))[i],]
print(sub$process[1])
print(signif(sub$proportion, digits=3)*100)
}
# [1] "2024-01-22"
# [1] "A_Variable selection"
# [1] 33.1 41.1
# [1] "B_Homogeneous selection"
# [1] 25.8 20.0
# [1] "C_Drift"
# [1] 6.36 6.32
# [1] "D_Homogenizing dispersal"
# [1] 8.47 5.79
# [1] "E_Dispersal limitation"
# [1] 26.3 26.8
```


Fig. 6, B and C: Environmental dissimilarity and geographic distance

```{r}
full_output<-read.csv("CommunityAssembly/2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)

#1) same lake (environment)

print("Homogenous selection")
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="B_Homogeneous selection", ]$percent), digits=3)*100


print("Variable selection")
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="A_Variable selection", ]$percent), digits=2)*100


print("Dispersal limitation")
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="E_Dispersal limitation", ]$percent), digits=2)*100

print("Homogenizing dispersal")
signif(mean(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%in%c(0) & full_output$process=="D_Homogenizing dispersal", ]$percent), digits=2)*100



# [1] "2024-01-22"
# [1] 60.6
# [1] 6.36
# [1] 9.49
# [1] 21.1
```

Note - extremely close but not the exactly the same as if you looked at distance (km) and d_val_groups 0 and 1 (could be rounding)



Inter-lake comparisons (averaged across environmental distance and geographic distance)
```{r}
full_output<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))

for( i in 1:5){

sub<-rbind(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%!in%c(0) & full_output$process==sort(unique(full_output$process))[i],]
      , 
      full_output[full_output$dist=="Distance (km)" & full_output$d_val_group%!in%c(0,1) & full_output$process==sort(unique(full_output$process))[i],])

print(sub$process[1])
print(signif(mean(sub$percent),digits=3)*100)
print(signif(range(sub$percent),digits=3)*100)
}

# [1] "2024-01-22"
# [1] "A_Variable selection"
# [1] 14.3
# [1]  2.31 28.10
# [1] "B_Homogeneous selection"
# [1] 46.7
# [1] 25.8 68.5
# [1] "C_Drift"
# [1] 2.87
# [1] 0.00 8.31
# [1] "D_Homogenizing dispersal"
# [1] 1.29
# [1] 0.00 6.52
# [1] "E_Dispersal limitation"
# [1] 34.8
# [1] 20.4 46.8
```



```{r}
full_output<-read.csv("CommunityAssembly/2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
z=1
for(z in 1:3){
    sub<-full_output[full_output$zone==c("A","B","C")[z],]  

sub2<-rbind(sub[sub$dist=="Environmental dissimilarity" & sub$d_val_group%!in%c(0) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],]
      , 
      sub[sub$dist=="Distance (km)" & sub$d_val_group%!in%c(0,1) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],])

 
print(sub2$zone[1])
print(signif(range(sub2$percent),digits=3)*100)
}

# [1] "2024-01-22"
# [1] "A"
# [1] 12.3 47.9
# [1] "B"
# [1]  8.69 54.30
# [1] "C"
# [1]  2.31 68.50
```



```{r}
full_output<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
z=1
i=1
for( i in 1:5){
sub<-rbind(full_output[full_output$dist=="Environmental dissimilarity" & full_output$d_val_group%!in%c(0) & full_output$process==sort(unique(full_output$process))[i],]
      , 
      full_output[full_output$dist=="Distance (km)" & full_output$d_val_group%!in%c(0,1) & full_output$process==sort(unique(full_output$process))[i],])

for(z in 1:3){
    sub2<-sub[sub$zone==c("A","B","C")[z],]    


print(sub2$process[1])
print(sub2$zone[1])
print(signif(mean(sub2$percent),digits=3)*100)
print(signif(range(sub2$percent),digits=3)*100)
}}


```
[1] "2024-01-22"
[1] "B_Homogeneous selection"
[1] "A"
[1] 38.7
[1] 25.8 47.9
[1] "B_Homogeneous selection"
[1] "B"
[1] 44.1
[1] 33.7 54.3
[1] "B_Homogeneous selection"
[1] "C"
[1] 57.2
[1] 48.9 68.5


```{r}
full_output<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_env_geo_dist_summary.csv", header=T, row.names = 1)

'%!in%' <- function(x,y)!('%in%'(x,y))
i=1
    sub<-full_output[full_output$zone=="C",]
sub2<-rbind(sub[sub$dist=="Environmental dissimilarity" & sub$d_val_group%!in%c(0) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],]
      , 
      sub[sub$dist=="Distance (km)" & sub$d_val_group%!in%c(0,1) & sub$process%in%sort(unique(sub$process))[c(1,2,5)],])

hs_de<-NULL
hs_vs<-NULL
for (i in 1:length(unique(sub2$d_val_group))){
 sub3<-sub2[sub2$d_val_group==sort(unique(sub2$d_val_group))[i],]

hs_de<-c(hs_de,sub3[sub3$process=="B_Homogeneous selection",]$percent/ sub3[sub3$process=="E_Dispersal limitation",]$percent)
hs_vs<-c(hs_vs,sub3[sub3$process=="B_Homogeneous selection",]$percent/ sub3[sub3$process=="A_Variable selection",]$percent)
    
}
Sys.Date()
print(sub3$zone[1])
print("hs_de")
print(signif(mean(hs_de),digits=3))   
print(signif(range(hs_de),digits=3)) 
print("hs_vs")
print(signif(mean(hs_vs),digits=3))  
print(signif(range(hs_vs),digits=3)) 

# [1] "2024-01-22"
# [1] "C"
# [1] "hs_de"
# [1] 1.87
# [1] 1.18 3.36
# [1] "hs_vs"
# [1] 7.68
# [1]  3.5 23.0

```






#### ix) Mantel tests of RCBray values


```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")
load("2024-01-19_WyLakeMicrobes_PhyloseqEnv_iCAMP_qpen_output.RData")

#can reaload data from here, or just use the qp2 object
qpn<-qp2$result[,c("sample1","sample2","RC")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"RC[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)%in%metadata$samp_names) #all true
table(colnames(dfr)%in%metadata$samp_names) # all true

RCbray<-as.dist(dfr)

#now add in environmental distances (lake bottom water and lake depth)
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
metadata_sub<-metadata[,names(metadata)%in%variables]


table(colnames(dfr)==metadata$samp_names) # all true
table(colnames(dfr)==rownames(metadata_sub)) # all true 

env_dist <- as.dist(as.matrix(daisy(scale(metadata_sub), metric="gower")))
table(labels(RCbray)==labels(env_dist))


# geographic distance

#Lat&lon to distance in meters
xy <- data.frame(X = metadata$longitude, Y = metadata$latitude)
rownames(xy)<-metadata$samp_names
dist_m_output<-distm(xy)
rownames(dist_m_output)<-rownames(xy)
names(dist_m_output)<-rownames(xy)
geo_dist<-as.dist(dist_m_output)

#check to make sure all labels match!
table(labels(RCbray)==labels(env_dist)) #all true
table(labels(RCbray)==labels(geo_dist)) #all true

mantel(RCbray, env_dist)
mantel(RCbray, geo_dist)

#add partial mantel test, spatially structured environmental variables
mantel.partial(RCbray, env_dist, geo_dist, method = "pearson", permutations = 999)
mantel.partial(RCbray, geo_dist, env_dist, method = "pearson", permutations = 999)
```

[1] "2024-01-22"

Mantel statistic based on Pearson's product-moment correlation 

Call:
mantel(xdis = RCbray, ydis = env_dist) 

Mantel statistic r: 0.2448 
      Significance: 0.001 

Upper quantiles of permutations (null model):
    90%     95%   97.5%     99% 
0.00976 0.01279 0.01581 0.01967 
Permutation: free
Number of permutations: 999



Mantel statistic based on Pearson's product-moment correlation 

Call:
mantel(xdis = RCbray, ydis = geo_dist) 

Mantel statistic r: 0.2046 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0118 0.0158 0.0196 0.0237 
Permutation: free
Number of permutations: 999



Partial Mantel statistic based on Pearson's product-moment correlation 

Call:
mantel.partial(xdis = RCbray, ydis = env_dist, zdis = geo_dist,      method = "pearson", permutations = 999) 

Mantel statistic r: 0.2421 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0101 0.0128 0.0147 0.0176 
Permutation: free
Number of permutations: 999


Partial Mantel statistic based on Pearson's product-moment correlation 

Call:
mantel.partial(xdis = RCbray, ydis = geo_dist, zdis = env_dist,      method = "pearson", permutations = 999) 

Mantel statistic r: 0.2012 
      Significance: 0.001 

Upper quantiles of permutations (null model):
   90%    95%  97.5%    99% 
0.0112 0.0148 0.0184 0.0236 
Permutation: free
Number of permutations: 999



#### x) Deeper comparisons

```{r}
new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")
comps_backup<-read.csv("2024-01-22_iCAMP_qpen_10plusESVs_allcomparisons.csv", header=T, row.names=1)
comps<-comps_backup
comps$d_val<-comps$abs_cm
comps<-comps[is.na(comps$d_val)==F,]
comps<-comps[comps$d_val>26,] # 119 comparisons, so no many compared to the other ones

tmp2<-comps
tally<-data.frame(n=NULL,process=NULL,percent=NULL)
proc<-unique(comps_backup$process)
for(p in 1:5){
        tally<-rbind(tally,data.frame(n=nrow(tmp2),process=proc[p],percent=nrow(tmp2[tmp2$process==proc[p],])/nrow(tmp2)))
}
tally$group<-rep("Deep comparisons", nrow(tally))

EAP_plot<-ggplot(tally, aes(x = group, y = percent , fill = process)) +
        geom_bar(stat="identity") + scale_fill_manual(values=new_colors,labels= c("Variable selection", "Homogeneous selection", "Drift", "Homogenizing dispersal", "Dispersal limitation" )) + guides(fill=guide_legend(title="Assembly process")) +  xlab(" ") +
  ylab("Proportion (%)") +
pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_CompWithDeepDepauperate_CommAssemProc.pdf"), height=4, width=4)
EAP_plot
dev.off()

```



#### xi) Sediment characteristics

```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")
load("2024-01-19_WyLakeMicrobes_PhyloseqEnv_iCAMP_qpen_output.RData")

qpn<-qp2$result[,c("sample1","sample2","process")]
names(qpn)[1]<-"s1_samp_names"
names(qpn)[2]<-"s2_samp_names"


dfr <- reshape(qpn, direction="wide", idvar="s1_samp_names", timevar="s2_samp_names")
rownames(dfr)<-dfr$s1_samp_names
dfr$s1_samp_names<-NULL
colnames(dfr)<-str_split_fixed(colnames(dfr),"process[.]",n=2)[,2]
dfr$SV0426L<-rep(NA,nrow(dfr))
dfr[nrow(dfr)+1,] <- NA
rownames(dfr)[478]<-"33_1_10_DNA"

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
metadata<-metadata[order(match(rownames(metadata),colnames(dfr))),]
table(colnames(dfr)==metadata$samp_names) # all true


#now select the sediment characteristics to examine
#using objects from above
variables<-c("pH"
, "d_13_c"  
, "cn"
, "sulfur_perc"     
, "water_perc"     
, "protein_per") 

#pull out metadata

metadata_sub<-metadata[,names(metadata)%in%variables]

table(colnames(dfr)==rownames(metadata_sub)) # all true 


daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))
table(colnames(daisy.mat)==colnames(dfr)) # all true
table(rownames(daisy.mat)==rownames(dfr)) # all true


daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
#there are a number of samples that don't have the data specified in the variables, therefore they are listed as NA and removed here.
env_dist<-melt(daisy.mat, na.rm=TRUE)

env_dist_reexpand <- reshape(env_dist, direction="wide", idvar="Var1", timevar="Var2")
rownames(env_dist_reexpand)<-env_dist_reexpand$Var1
env_dist_reexpand$Var1<-NULL
colnames(env_dist_reexpand)<-str_split_fixed(colnames(env_dist_reexpand),"value[.]",n=2)[,2]

#figure out which ones were different
setdiff(rownames(env_dist_reexpand),colnames(env_dist_reexpand))
setdiff(colnames(env_dist_reexpand),rownames(env_dist_reexpand))
env_dist_reexpand$SV0226L<-rep(NA,nrow(env_dist_reexpand))
env_dist_reexpand[nrow(env_dist_reexpand)+1,] <- NA
rownames(env_dist_reexpand)[nrow(env_dist_reexpand)]<-"33_1_10_DNA"

env_dist_reexpand<-env_dist_reexpand[order(row.names(env_dist_reexpand)), ]
table(rownames(env_dist_reexpand)==colnames(env_dist_reexpand)) #all true

#how many NAs in each and overlap for metadata
#metadata_sub[,metadatacolnames(env_dist_reexpand)]
met<-metadata_sub[rownames(metadata_sub)%in% colnames(env_dist_reexpand),]
#pH, cn and percent water are present in most samples, but then half have d13c and half the sulfur and protein percent

#subset the process/dfr data frame by the comparisons in metadata
dfr<-dfr[colnames(env_dist_reexpand),colnames(env_dist_reexpand)]

dfr<-dfr[order(row.names(dfr)), ]
table(rownames(dfr)==colnames(dfr)) #all true
table(rownames(dfr)==rownames(env_dist_reexpand)) #all true
table(colnames(dfr)==colnames(env_dist_reexpand)) #all true

#melt back to pairwise comparisons
env_dist<-melt(as.matrix(env_dist_reexpand))
process<-melt(as.matrix(dfr))


table(process$Var1==env_dist$Var1) # all true
table(process$Var2==env_dist$Var2) # all true 
process$env_dist<-env_dist$value
process<-process[complete.cases(process),]


pairwise<-process

names(pairwise)[1]<-"s1_samp_names"
pairwise$s1_samp_names<-as.character(pairwise$s1_samp_names)
names(pairwise)[2]<-"s2_samp_names"
pairwise$s2_samp_names<-as.character(pairwise$s2_samp_names)
names(pairwise)[3]<-"process"

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

pairwise<-merge(pairwise, metadata_s1, by="s1_samp_names")
pairwise<-merge(pairwise, metadata_s2, by="s2_samp_names")

#remove metadata notes
pairwise$s1_notes<-NULL
pairwise$s2_notes<-NULL
pairwise$s1_Notes_sed_water_wt<-NULL
pairwise$s2_Notes_sed_water_wt<-NULL
pairwise$s1_Notes_carbon_nitrogen<-NULL
pairwise$s2_Notes_carbon_nitrogen<-NULL
pairwise$s1_Notes._lake_sed_pH<-NULL
pairwise$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
pairwise$abs_cm<-rep(NA, nrow(pairwise))
i=1
for(i in 1:nrow(pairwise)){
  ifelse(pairwise$s1_lake_drive[i]==pairwise$s2_lake_drive[i],pairwise$abs_cm[i]<-abs(pairwise$s2_depth[i]-pairwise$s1_depth[i]),NA)
}

# calculate geographic distance

require(geosphere)
for(i in 1:nrow(pairwise)){
        pairwise$geo_dist[i]<-as.numeric(distm(data.frame(X = pairwise$s1_longitude[i], Y = pairwise$s1_latitude[i]),data.frame(X = pairwise$s2_longitude[i], Y = pairwise$s2_latitude[i])))
}

pairwise$geo_dist_km<-pairwise$geo_dist/1000

write.csv(pairwise, paste0(Sys.Date(),"_iCAMP_qpen_10plusESVs_sediment_characteristics.csv"))

```

plot all zones together

```{r}
qpn<-read.csv("CommunityAssembly/2024-01-22_iCAMP_qpen_10plusESVs_sediment_characteristics.csv", header=T, row.names=1)

# three toggle on/off with hash tags total in this chunk:

downcore<-qpn[is.na(qpn$abs_cm)==F & qpn$abs_cm<27 ,] # subset by samples within the same core (intra-core)

#downcore<-qpn # samples that are comparable anywhere (from other lakes, inter-core)

downcore$d_val<-downcore$env_dist
downcore$d_val_group_breaks<-cut2(downcore$d_val, g=10)
downcore$d_val_group<-as.numeric(cut2(downcore$d_val, g=10))
levels(downcore$d_val_group_breaks)
break_labels<- c("0 to <0.03" ,"0.03 to <0.05" ,"0.05 to <0.06", "0.06 to <0.08" ,"0.08 to <0.10" ,"0.10 to <0.13"
,"0.13 to <0.15" ,"0.15 to <0.20" ,"0.20 to <0.28", "0.28 to 1")
# [ includes ( up to 

tmp<-downcore
tally<-data.frame(process=NULL,percent=NULL, d_val_group=NULL,n=NULL)
groups<-sort(unique(downcore$d_val_group))
i=1
for(i in 1:length(groups)){
  tmp2<-tmp[tmp$d_val_group==groups[i],]
  processes<-as.data.frame(table(tmp2$process)/nrow(tmp2))
  colnames(processes)[1]<-"process"
  colnames(processes)[2]<-"percent"
  processes$process<-as.character(processes$process)
  processes$d_val_group<-rep(groups[i],nrow(processes))
  processes$n<-rep(nrow(tmp2),nrow(processes))
  tally<-rbind(tally,processes)
}
  

tally[tally$process=="Homogeneous.Selection",]$process<-"B_Homogeneous selection"
tally[tally$process=="Heterogeneous.Selection",]$process<-"A_Variable selection"
tally[tally$process=="Dispersal.Limitation",]$process<-"E_Dispersal limitation"
tally[tally$process=="Homogenizing.Dispersal",]$process<-"D_Homogenizing dispersal"
tally[tally$process=="Undominated",]$process<-"C_Drift"

new_colors<-c("#556B2F", "#A2CD5A","#CCCCCC","#B0E2FF", "#36648B")

        ggplt <- ggplot(tally,            
                        aes(x = d_val_group,
                            y = percent,
                            color= process)) +  geom_line(linewidth=2) +geom_point(size=3) + theme_bw() + scale_x_continuous(breaks=seq(1,length(groups),1), 
                                                                                                                             labels=break_labels) + xlab(label = "Sediment characteristic\ndissimilarity")+ ylab(label = "Proportion") + geom_line(linewidth=2) +   labs(color="Assembly process")    +theme(axis.ticks.x = element_blank()) + scale_color_manual(values=new_colors, labels=c("Variable selection",  "Homogeneous selection",    "Drift",  "Homogenizing dispersal" , "Dispersal limitation" )) + theme(axis.title.x = element_text(vjust=-0.5)) + theme(panel.grid.minor.x = element_blank()) + ylim(0,.75) + theme(axis.text.x = element_text(angle = 45,hjust=1))+ guides(color = guide_legend(override.aes = list(linewidth = 6))) +
                theme(axis.text=element_text(color="black"))+
                theme(axis.text.x = element_text(angle = 60,hjust=1))+
                theme(text=element_text(size=14), #change font size of all text
                      axis.text=element_text(size=14), #change font size of axis text
                      axis.title=element_text(size=15), #change font size of axis titles
                      plot.title=element_text(size=14), #change font size of plot title
                      legend.text=element_text(size=14), #change font size of legend text
                      legend.title=element_text(size=15),
                      panel.grid.minor = element_blank(), 
                      panel.grid.major.x = element_blank()) #change font size of legend title 

        
# toggle on/off with hash tags
pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_iCAMP_qpen_sediment_characteristics_intracore.pdf"), height=3.5, width=6)
#pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_iCAMP_qpen_sediment_characteristics_intercore.pdf"), height=3.5, width=6)
ggplt
dev.off()


print("intra-core") # toggle on/off with hash tags
#print("inter-core") # toggle on/off with hash tags
unique(tally$n)

# [1] "intra-core"
# [1] 151 150

# [1] "inter-core"
# [1] 4277 4276
```

GAMs
Toggle on "intra-core" in previous chunk
```{r}
model_results<-data.frame(process=NULL, devex=NULL, p=NULL)

#Plot the sediment depth GAM for each process
png(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_iCAMP_qpen_SedCharacteristics_GAMs.png"), height=3.5, width=12, unit="in", res=600)
par(mfrow=c(1,5),mar=c(9,4.5,2,0))
i=1
for(i in 1:5){
sub<-tally[tally$process==sort(unique(tally$process))[i],]
plot(sub$d_val_group,sub$percent, main=stringr::str_split(sort(unique(tally$process))[i],pattern="_")[[1]][2],ylab="", xlab="", pch=16, ylim=c(min(sub$percent),max(sub$percent)),col="black", xaxt="n")
axis(side=1,cex=0.8, at=seq(1,(length(break_labels)),1), las=2, labels = break_labels)
title(xlab=c("","","Sediment dissimilarity","","")[i], cex.lab=1.4, line=7)
title(ylab=c("Proportion","","","","")[i], cex.lab=1.4, line =3)

Data<-data.frame(x=sub$d_val_group, y=sub$percent)
Data<-Data[order(Data$x),]
 Gam=gam(y~s(x, k=3), data=Data)
        pred = predict.gam(Gam, newdata = Data[1], se.fit=T)
        lines(Data$x,pred$fit, col=new_colors[i], lwd=3) 
        polygon(x = c(Data$x, rev(Data$x)),
        y = c( pred$fit + (2 * pred$se.fit), 
              rev(pred$fit - (2 * pred$se.fit))),
        col =  adjustcolor(new_colors[i], alpha.f = 0.40), border = NA)
        gam_res<-summary(Gam)
        model_results<-rbind(model_results,data.frame(process=sort(unique(tally$process))[i], devex=round(gam_res$dev.expl,digits=3), p=gam_res$s.pv))
}
dev.off()

Sys.Date()
round(mean(model_results$devex),digits=4)
# [1] "2024-01-30"
# [1] 0.6888

model_results$p<-round(model_results$p, digits=3)
model_results
```
                   process devex     p
1     A_Variable selection 0.582 0.010
2  B_Homogeneous selection 0.818 0.001
3                  C_Drift 0.488 0.075
4 D_Homogenizing dispersal 0.731 0.011
5   E_Dispersal limitation 0.825 0.000




## 2. Alpha diversity

### a. using estimate_richness in phyloseq instead
```{r}
ps_26<-subset_samples(ps,bin_depth<=26)
rich<-estimate_richness(ps_26)

rownames(rich)<-gsub("X","",as.character(rownames(rich)))
rich<-merge(rich,metadata,by="row.names")

jpeg(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_Richness.jpg"), height=3, width=8, units = "in",res = 600)
par(mfrow=c(1,3))
plot(rich$bin_depth,rich$Observed, pch=16, col="#00000060", xlab="Depth (cm)", ylab="Observed richness")
abline(lm(rich$Observed~rich$bin_depth), lwd=2)
text(y=max(rich$Observed)*0.97, x=20, paste0("p-val: ", signif(summary(lm(rich$Observed~rich$bin_depth))$coefficients[2,4], digits=3)), cex=1)
text(y=max(rich$Observed)*0.91, x=20, paste0("r-sq: ", round(summary(lm(rich$Observed~rich$bin_depth))$r.sq, digits=2)), cex=1)
mtext("A",side=3,line=0.5 ,at=1, cex=2)

plot(rich$bin_depth,rich$Shannon, pch=16, col="#00000060", xlab="Depth (cm)", ylab="Shannon" )
abline(lm(rich$Shannon~rich$bin_depth), lwd=2)
text(y=max(rich$Shannon)*0.45, x=20, paste0("p-val: ", signif(summary(lm(rich$Shannon~rich$bin_depth))$coefficients[2,4], digits=3)), cex=1)
text(y=max(rich$Shannon)*0.4, x=20, paste0("r-sq: ", round(summary(lm(rich$Shannon~rich$bin_depth))$r.sq, digits=2)), cex=1)
mtext("B",side=3,line=0.5 ,at=1, cex=2)


plot(rich$bin_depth,rich$InvSimpson, pch=16, col="#00000060", xlab="Depth (cm)", ylab="Inverse Simpson")
abline(lm(rich$InvSimpson~rich$bin_depth), lwd=2)
text(y=max(rich$InvSimpson)*0.96, x=20, paste0("p-val: ", signif(summary(lm(rich$InvSimpson~rich$bin_depth))$coefficients[2,4], digits=3)), cex=1)
text(y=max(rich$InvSimpson)*0.88, x=20, paste0("r-sq: ", round(summary(lm(rich$InvSimpson~rich$bin_depth))$r.sq, digits=2)), cex=1)
mtext("C",side=3,line=0.5,at=1, cex=2)

dev.off()
```




## 3. NMDS 

### a. run NMDS
```{r}
ps_table <- data.frame(otu_table(ps_tr))
ps_table <-t(ps_table)
sd_sed <- data.frame(sample_data(ps_tr))

Sys.Date()
ord_baseR<-metaMDS(ps_table, distance = "bray")


fig<-ordiplot(ord_baseR, type="points")

NMDS1<-fig$sites[,1]
NMDS2<-fig$sites[,2]

fig_sites<-as.data.frame(fig[["sites"]])
table(fig_sites$NMDS2==NMDS2) #same for both NMDS1 and NMDS2


fig_sites$samp_names<-rownames(fig_sites)
fig_sites$samp_names<-gsub("X","",as.character(fig_sites$samp_names))
table(names(as.data.frame(ps_tr@otu_table))==fig_sites$samp_names) # all true 

#add in metadata to the dataframe with the NMDS
ord_df<-merge(fig_sites,sd_sed, by="samp_names")

#8c510a darker brown
#a6611a # dark brown
#dfc27d
#80cdc1
#018571 # dark teal

darkertan<-darken("#dfc27d", 0.1)
#C4AD79

ord_df$zone_col<-rep('#01857180',nrow(ord_df))
ord_df[ord_df$bin_depth%in%c(6,8,10,12),]$zone_col<-"#C4AD7980"
ord_df[ord_df$bin_depth%in%c(14,16,18,20,22,24,26),]$zone_col<-'#a6611a80'
ord_df[ord_df$depth>26,]$zone_col<-'#00000080' #black

zone_colors<- c('#018571','#dfc27d','#a6611a','#000000')

sd_sed$bottom_water_temp<-sd_sed$water_sample_t_bot
sd_sed$lake_depth<-sd_sed$max_lake_depth
sd_sed$sediment_depth<-sd_sed$depth

#if you want first axis reversed!
ord_df$NMDS1<-(ord_df$NMDS1*(-1))

ord.fit <- envfit(ord_baseR ~  sediment_depth + lake_depth + bottom_water_temp,  data = sd_sed,  perm = 1000, na.rm = TRUE)
ord.fit[["vectors"]][["arrows"]][1,1]<-(ord.fit[["vectors"]][["arrows"]][1,1]*(-1))

#save.image(paste0(Sys.Date(),"_NMDS.Rdata"))
beep()
```


### b. Add variables in with vectors
```{r}
load("IntermediateAnalysisFiles/2024-01-23_NMDS.Rdata")

ord.fit <- envfit(ord_baseR ~ depth + max_lake_depth + water_sample_t_bot +   water_sample_ph_bot + water_sample_do_bot + water_sample_t_surf + water_sample_ph_surf + water_sample_do_surf + c_perc  + n_perc  + d_13_c,  data = sd_sed,  perm = 1000, na.rm = TRUE)
ord.fit[["vectors"]][["arrows"]][1,1]<-(ord.fit[["vectors"]][["arrows"]][1,1]*(-1))

ord_df$shape<-rep(16,nrow(ord_df))
ord_df[ord_df$depth>26,]$shape<-8
ord_df[ord_df$depth>26,]$zone_col<-'#a6611a' 

ord_df$size<-rep(1.5,nrow(ord_df))
ord_df[ord_df$depth>26,]$size<-1
```

### c. plot NMDS
```{r}
pdf(paste0("Figures/",Sys.Date(),"_Fig4_NMDS.pdf"), width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,pch=ord_df$shape,cex=ord_df$size, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col=ord_df$zone_col,xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
plot(ord.fit, labels=c("sediment \n depth","lake depth","bottom water temperature\n","bottom water pH", "bottom water DO\n\n\n\n" ,"surface water temperature" ,"surface water pH" ,"surface water DO", "% carbon", "% nitrogen", "d13C"),p.max=0.05, col="black",lwd=6, cex=1.2)
dev.off()
```

### d. plot graphical summary
```{r}
ord_df$shape<-rep(16,nrow(ord_df))
ord_df[ord_df$depth>26,]$zone_col<-'#a6611a80'


pdf(paste0("Figures/",Sys.Date(),"_NMDS_graphicalsummary.pdf"), width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,pch=ord_df$shape,cex=1.2, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col=ord_df$zone_col,xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
dev.off()
```

### e. points by mountain range

```{r}
ord_df$mtn_pch<-rep(NA,nrow(ord_df))
ord_df[ord_df$mountain_range=="Snowy",]$mtn_pch<-21 #circle
ord_df[ord_df$mountain_range=="Beartooth",]$mtn_pch<-22 #square
ord_df[ord_df$mountain_range=="Wind River",]$mtn_pch<-23 #diamond
ord_df[ord_df$mountain_range=="Bighorn",]$mtn_pch<-24 #triangle
ord_df$mtn_pch<-as.numeric(ord_df$mtn_pch)
ord_df[ord_df$depth>26,]$zone_col<-'#00000099' 


pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_NMDS_mtnshapes.pdf"), width=5, height=4.5)
par(mar=c(4, 4, 2, 1), xpd=TRUE)
plot(ord_df$NMDS1, ord_df$NMDS2,cex=1.5, ylim=c(-1.5,2.3), yaxt="n", xlim=c(-3,2.3),col="black",bg=ord_df$zone_col, pch=ord_df$mtn_pch, xlab='', cex.axis=1.2,ylab='')
axis(2,at=c(-1,0,1,2),labels =c(-1,0,1,2), cex.axis=1.2, las=2, col = NA, col.ticks = 1)
title(xlab="NMDS1", line = 2.5, cex.lab=1.2)
title(ylab="NMDS2", line = 2, cex.lab=1.2)
dev.off()

```



### f. PERMANOVA

```{r}
ps_table <- data.frame(otu_table(ps_tr)) 
names(ps_table)<-colnames(ps_tr@otu_table)
ps_table<-as.data.frame(t(ps_table))

sd <- as.matrix(sample_data(ps_tr))
sd<-as.data.frame(sd)
sd[sd$lake_id=="40",]$water_sample_t_bot<-20.1 #JVE - first adding surface water temperature for round lake bottom water temperature since the lake it 1.5 m deep
sd<-sd %>% filter(lake_id != "45") 

vars<-c("water_sample_t_bot",
"max_lake_depth",
"depth",
"water_sample_ph_bot",
"water_sample_do_bot",
"water_sample_t_surf",
"water_sample_ph_surf",
"water_sample_do_surf")
sd <- sd[names(sd)%in%vars]
table(is.na(sd)) #make sure there are no NAs

ps_table <- ps_table %>%
  filter(row.names(.) %in% row.names(sd))
table(rownames(ps_table)%in%rownames(sd))

#convert sample data from character to numeric
sd[] <- lapply(sd, as.numeric)
glimpse(sd)

#create distance matrix with 
adonis_table<-data.matrix(ps_table) 
adonis_dist<-parallelDist::parDist(adonis_table, method = "bray")
 
adonis2(adonis_dist ~ depth + water_sample_t_bot +
max_lake_depth +water_sample_t_surf+ water_sample_ph_surf + water_sample_do_bot + water_sample_do_surf + water_sample_ph_bot, data = sd) 

beep()
```

Permutation test for adonis under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 999

adonis2(formula = adonis_dist ~ depth + water_sample_t_bot + max_lake_depth + water_sample_ph_bot + water_sample_do_bot + water_sample_t_surf + water_sample_ph_surf + water_sample_do_surf, data = sd)
                      Df SumOfSqs      R2       F Pr(>F)    
depth                  1    9.364 0.05251 29.0915  0.001 ***
water_sample_t_bot     1    7.441 0.04173 23.1152  0.001 ***
max_lake_depth         1    3.566 0.02000 11.0772  0.001 ***
water_sample_ph_bot    1    2.013 0.01129  6.2536  0.001 ***
water_sample_do_bot    1    2.531 0.01419  7.8626  0.001 ***
water_sample_t_surf    1    3.179 0.01783  9.8774  0.001 ***
water_sample_ph_surf   1    2.651 0.01487  8.2363  0.001 ***
water_sample_do_surf   1    2.399 0.01345  7.4528  0.001 ***
Residual             451  145.175 0.81413                   
Total                459  178.320 1.00000                   



This has numeric and I added sediment depth first theb bottom water temperature first

Permutation test for adonis under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 999

adonis2(formula = adonis_dist ~ depth + water_sample_t_bot + max_lake_depth, data = sd)
                    Df SumOfSqs      R2      F Pr(>F)    
depth                1    9.364 0.05251 27.035  0.001 ***
water_sample_t_bot   1    7.441 0.04173 21.481  0.001 ***
max_lake_depth       1    3.566 0.02000 10.294  0.001 ***
Residual           456  157.949 0.88576                  
Total              459  178.320 1.00000                  



Permutation test for adonis under reduced model
Terms added sequentially (first to last)
Permutation: free
Number of permutations: 999

adonis2(formula = adonis_dist ~ depth + water_sample_t_bot + max_lake_depth + water_sample_t_surf + water_sample_ph_surf + water_sample_do_bot + water_sample_do_surf + water_sample_ph_bot, data = sd)
                      Df SumOfSqs      R2       F Pr(>F)    
depth                  1    9.364 0.05251 29.0915  0.001 ***
water_sample_t_bot     1    7.441 0.04173 23.1152  0.001 ***
max_lake_depth         1    3.566 0.02000 11.0772  0.001 ***
water_sample_t_surf    1    3.442 0.01930 10.6921  0.001 ***
water_sample_ph_surf   1    2.904 0.01629  9.0220  0.001 ***
water_sample_do_bot    1    1.570 0.00880  4.8774  0.001 ***
water_sample_do_surf   1    2.488 0.01395  7.7297  0.001 ***
water_sample_ph_bot    1    2.370 0.01329  7.3615  0.001 ***
Residual             451  145.175 0.81413                   
Total                459  178.320 1.00000                   






## 4. Rel abund of dominant taxa

### a. Caluclate top phyla

#### ii. Subset phyloseq by 26 cm and then glom by Phylum
```{r}
#subset samples less than or equal to 26
ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
ps_tr_26_phy<-tax_glom(ps_tr_26, taxrank = "Phylum",NArm = FALSE)
ps_melt<-psmelt(ps_tr_26_phy)
write.csv(ps_melt, paste0(Sys.Date(),"_RelativeAbundance_AllPhyla.csv"))
beep()
```

#### ii. calculate top phyla
```{r}
ps_melt<-read.csv("2024-01-26_RelativeAbundance_AllPhyla.csv", header=T, row.names=1)

#which phyla go over a threshold on AVERAGE for each bin depth
    pt <- PivotTable$new()
    pt$addData(ps_melt)
    pt$addRowDataGroups("bin_depth") 
    pt$addColumnDataGroups("Phylum") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    
    
    phy_avg_abund <- pt$asDataFrame()
    phy_avg_abund$bin_depth<-rownames(phy_avg_abund)
    phy_avg_abund<-phy_avg_abund[-which(phy_avg_abund$bin_depth=="Total"),]
    phy_avg_abund$Total<-NULL
    phy_avg_abund$bin_depth <- as.numeric(phy_avg_abund$bin_depth)
    phy_avg_abund <- melt(phy_avg_abund, id.vars = "bin_depth")
    
    rm(pt)
    
length(unique(as.character(phy_avg_abund[which(phy_avg_abund$value>0.04),]$variable)))
#10 - 2024-01-26

subphy<-unique(as.character(phy_avg_abund[which(phy_avg_abund$value>0.04),]$variable))
subphy
 # [1] "Acidobacteriota"   "Bacteroidota"      "Chloroflexi"       "Crenarchaeota"    
 # [5] "Cyanobacteria"     "Desulfobacterota"  "Halobacterota"     "Planctomycetota"  
 # [9] "Proteobacteria"    "Verrucomicrobiota"

# number of samples included
length(unique(ps_melt$samp_names))
#429 samples - 2024-01-26

# what percent are these 10 phyla in the entire dataset?
sum(ps_melt[ps_melt$Phylum%in%subphy,]$Abundance)/length(unique(ps_melt$samp_names))
#[1] 0.7065141 - 2024-01-26 total reads

```

#### iii. Proportion of reads 

Proportion of reads 0f the dominant phyla in each zone
```{r}
#proportion of the dominant phyla in the redox zone
zone<-subset_samples(ps_tr, bin_depth%in%c(0,2,4))
round(sum(colSums(otu_table(subset_taxa(zone, Phylum%in%c("Bacteroidota" ,"Cyanobacteria"  ,  "Proteobacteria","Verrucomicrobiota")))))/sum(colSums(otu_table(zone)))*100, digits=1)
#[1] 33.5 - 2024-01-26

#transition zone
zone<-subset_samples(ps_tr, bin_depth%in%c(6,8,10,12))
round(sum(colSums(otu_table(subset_taxa(zone, Phylum%in%c("Acidobacteriota" ,"Chloroflexi",  "Desulfobacterota" ,"Halobacterota")))))/sum(colSums(otu_table(zone)))*100, digits=1)
#[1] 38.8 -  2024-01-26

#depauperate zone 
zone<-subset_samples(ps_tr, bin_depth%in%c(14,16,18,20,22,24,26))
round(sum(colSums(otu_table(subset_taxa(zone, Phylum%in%c("Crenarchaeota"   ,"Planctomycetota")))))/sum(colSums(otu_table(zone)))*100, digits=1)
#[1] 20.1 - 2024-01-26
```

#### iv. Plot Fig 3. A
```{r}
topphy<-read.csv("2024-01-26_RelativeAbundance_AllPhyla.csv", header=T, row.names=1)
topphy<-topphy[topphy$Phylum%in%c("Acidobacteriota" ,  "Bacteroidota" ,    
"Chloroflexi"    ,   "Crenarchaeota"    ,"Halobacterota",
"Cyanobacteria"  ,   "Desulfobacterota" ,
"Planctomycetota" , "Proteobacteria"   ,
"Verrucomicrobiota"),]

ordphy<-c(  "Bacteroidota" ,    
"Cyanobacteria"  ,  "Proteobacteria"   ,
"Verrucomicrobiota",
"Acidobacteriota" ,"Chloroflexi",  "Desulfobacterota" ,"Halobacterota"
 ,"Crenarchaeota"   ,"Planctomycetota")

lake_drives<-unique(topphy$lake_drive)
zone_colors<- c(rep('#018571',4), rep('#C4AD79', 4), rep('#a6611a',3))

vals<-list()
labs<-list()

pdf(paste0("Figures/", Sys.Date(),"_RelAbun_TopPhyla.pdf"), width=13, height=4)
par(mfrow=c(1,13), mar=c(6,6,1,0))
plot(0:26,0:26, bty="n", frame.plot = FALSE, xaxt="n", yaxt="n",ylab = "Depth (cm)", xlab="",ylim=c(26,0), las=1, cex.lab=1.6, pch=19, col="white")
axis(side=2, at= seq(0, 26, by=2), cex.axis=1.6,labels= seq(0, 26, by=2), las=1)
par(mar=c(6,0.5,1,1), xpd=TRUE)
for(i in 1:length(unique(topphy$Phylum))){
  temp<-topphy[topphy$Phylum==ordphy[i],]
  temp<-temp[order(temp$bin_depth,decreasing=T),]
  pt <- PivotTable$new()
    pt$addData(temp)
    pt$addRowDataGroups("bin_depth") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    meanabund <- pt$asDataFrame()
    meanabund$bin_depth<-rownames(meanabund)
    meanabund<-meanabund[-which(meanabund$bin_depth=="Total"),]
    meanabund$bin_depth<-as.numeric(meanabund$bin_depth)
    meanabund<-meanabund[order(meanabund$bin_depth,decreasing = T),]
    plot(temp$Abundance,temp$bin_depth,col="white",ylim=c(26,0),bty="n",xlim=c(0,max(meanabund$Abundance)*1.8),ylab="",xlab="",yaxt="n",xaxt="n",cex.axis=1.6)
    vals[[i]]<-seq(0,(max(meanabund$Abundance)*1.8), length.out=5)
    labs[[i]]<- c("0", as.character(round(vals[[i]][2:5], digits=2)))
    axis(side = 1, at = vals[[i]], labels =labs[[i]], cex.axis=1.6)

    for(l in 1:length(lake_drives)){
  temp2<-temp[temp$lake_drive==lake_drives[l],]  
  temp2<-temp2[order(temp2$bin_depth,decreasing = F),]
  lines(temp2$Abundance,temp2$bin_depth, col="gray")}
    lines(meanabund$Abundance,meanabund$bin_depth, col=zone_colors[i],lwd=4)
}
dev.off()


```



### b. Top families

```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")
#subset samples less than or equal to 26
ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
ps_tr_26_fam<-tax_glom(ps_tr_26, taxrank = "Family",NArm = FALSE)
ps_melt<-psmelt(ps_tr_26_fam)
write.csv(ps_melt, paste0(Sys.Date(),"_RelativeAbundance_AllFamilies.csv"))
```

```{r}
ps_melt<-read.csv("2024-01-29_RelativeAbundance_AllFamilies.csv", header=T, row.names=1)
ps_melt$taxtofam<-paste(ps_melt$Phylum, ps_melt$Class, ps_melt$Order, ps_melt$Family, sep = "@")

#which phyla go over a threshold on AVERAGE for each bin depth
    pt <- PivotTable$new()
    pt$addData(ps_melt)
    pt$addRowDataGroups("bin_depth") 
    pt$addColumnDataGroups("taxtofam") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    
    
    fam_avg_abund <- pt$asDataFrame()
    fam_avg_abund$bin_depth<-rownames(fam_avg_abund)
    fam_avg_abund<-fam_avg_abund[-which(fam_avg_abund$bin_depth=="Total"),]
    fam_avg_abund$Total<-NULL
    fam_avg_abund$bin_depth <- as.numeric(fam_avg_abund$bin_depth)
    fam_avg_abund <- melt(fam_avg_abund, id.vars = "bin_depth")
    
    rm(pt)
    

# remove NA@NA
fam_avg_abund<-fam_avg_abund[fam_avg_abund$variable!="NA@NA@NA@NA",]
    

# Only include those that are actually assigned to a family, otherwise you are looking really at unassigned families in specific orders or classes

subfam<-unique(as.character(fam_avg_abund[which(fam_avg_abund$value>0.0138),]$variable))
table((str_split(subfam,pattern = "@", 4, simplify = T)[,4])!="NA")
subfam
#  [1] "Acidobacteriota@Aminicenantia@Aminicenantales@NA"                     
#  [2] "Acidobacteriota@Vicinamibacteria@Vicinamibacterales@NA"               
#  [3] "Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"       
#  [4] "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"              
#  [5] "Chloroflexi@Anaerolineae@RBG-13-54-9@NA"                              
#  [6] "Chloroflexi@Dehalococcoidia@MSBL5@NA"                                 
#  [7] "Chloroflexi@KD4-96@NA@NA"                                             
#  [8] "Crenarchaeota@Bathyarchaeia@NA@NA"                                    
#  [9] "Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
# [10] "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae"            
# [11] "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
# [12] "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae"    
# [13] "Latescibacterota@NA@NA@NA"                                            
# [14] "Nanoarchaeota@Nanoarchaeia@Woesearchaeales@NA"                        
# [15] "Planctomycetota@Phycisphaerae@DG-20@NA"                               
# [16] "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
# [17] "Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group"
# [18] "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
# [19] "Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae"    
# [20] "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
# [21] "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"           
# [22] "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
# [23] "Sva0485@NA@NA@NA"                                                     
# [24] "Thermoplasmatota@Thermoplasmata@Marine Benthic Group D and DHVEG-1@NA"
# [25] "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"           
# [26] "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae"    



subfam<-c("Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"    
, "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"              
, "Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
, "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae"            
, "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
, "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae"    
, "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
,"Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group"
, "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"           
, "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
, "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"           
, "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae"  )

sum(ps_melt[ps_melt$taxtofam%in%subfam,]$Abundance)/length(unique(ps_melt$samp_names))

#[1] 0.2705308 - 2024-01-29
```

#### i. Plot Fig. 3 B
```{r}
topfam<-read.csv("2024-01-29_RelativeAbundance_AllFamilies.csv", header=T, row.names=1)
topfam$taxtofam<-paste(topfam$Phylum, topfam$Class,topfam$Order, topfam$Family, sep = "@")
topfam<-topfam[topfam$taxtofam%in%c("Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"   
, "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"              
, "Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
, "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae"            
, "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
, "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae"    
, "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
,"Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group"
, "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"           
, "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
, "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"           
, "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae"  ),]

#Look at which ones are archaea
topfam %>% select(Kingdom, taxtofam) %>% unique()

#alphabetically ordered by family name
ordered<-c("Proteobacteria@Gammaproteobacteria@Burkholderiales@Comamonadaceae" 
, "Cyanobacteria@Cyanobacteriia@Synechococcales@Cyanobiaceae" 
, "Proteobacteria@Gammaproteobacteria@Methylococcales@Methylomonadaceae" 
, "Verrucomicrobiota@Verrucomicrobiae@Pedosphaerales@Pedosphaeraceae" 
,"Cyanobacteria@Cyanobacteriia@Cyanobacteriales@Phormidiaceae"          
, "Planctomycetota@Planctomycetes@Pirellulales@Pirellulaceae"            
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@Rhodocyclaceae"    
, "Proteobacteria@Gammaproteobacteria@Burkholderiales@SC-I-84"      

, "Chloroflexi@Anaerolineae@Anaerolineales@Anaerolineaceae"
,"Bacteroidota@Bacteroidia@Bacteroidales@Bacteroidetes vadinHA17"   
, "Halobacterota@Methanomicrobia@Methanomicrobiales@Methanoregulaceae"   
, "Halobacterota@Methanosarcinia@Methanosarciniales@Methanosaetaceae" 
, "Verrucomicrobiota@Omnitrophia@Omnitrophales@Omnitrophaceae"      

, "Planctomycetota@Phycisphaerae@MSBL9@SG8-4"                            
,"Planctomycetota@Phycisphaerae@Phycisphaerales@AKAU3564 sediment group")

lake_drives<-unique(topfam$lake_drive)

zone_colors<- c(rep('#018571',8), rep('#C4AD79', 5), rep('#a6611a',2))

vals<-list()
labs<-list()

pdf(paste0("Figures/", Sys.Date(),"_RelAbun_TopFam.pdf"), width=14, height=4)
par(mfrow=c(1,16), mar=c(6,6,1,0))
plot(0:26,0:26, bty="n", frame.plot = FALSE, xaxt="n", yaxt="n",ylab = "Depth (cm)", xlab="",ylim=c(26,0), las=1, cex.lab=1.6, pch=19, col="white")
axis(side=2, at= seq(0, 26, by=2), cex.axis=1.6,labels= seq(0, 26, by=2), las=1)
par(mar=c(6,0.5,1,1), xpd=TRUE)
for(i in 1:length(unique(topfam$taxtofam))){
  temp<-topfam[topfam$taxtofam==ordered[i],]
  temp<-temp[order(temp$bin_depth,decreasing=T),]
  pt <- PivotTable$new()
    pt$addData(temp)
    pt$addRowDataGroups("bin_depth") 
    pt$defineCalculation(calculationName="Abundance", summariseExpression="mean(Abundance,na.rm=T)")
    pt$renderPivot()
    meanabund <- pt$asDataFrame()
    meanabund$bin_depth<-rownames(meanabund)
    meanabund<-meanabund[-which(meanabund$bin_depth=="Total"),]
    meanabund$bin_depth<-as.numeric(meanabund$bin_depth)
    meanabund<-meanabund[order(meanabund$bin_depth,decreasing = T),]
    plot(temp$Abundance,temp$bin_depth,col="white",ylim=c(26,0),bty="n",xlim=c(0,max(meanabund$Abundance)*1.8),ylab="",xlab="",yaxt="n",xaxt="n", cex.axis=1.6)
        vals[[i]]<-seq(0,(max(meanabund$Abundance)*1.8), length.out=5)
    labs[[i]]<- c("0", as.character(round(vals[[i]][2:5], digits=2)))
    axis(side = 1, at = vals[[i]], labels =labs[[i]], cex.axis=1.6)

    for(l in 1:length(lake_drives)){
  temp2<-temp[temp$lake_drive==lake_drives[l],]  
  temp2<-temp2[order(temp2$bin_depth,decreasing = F),]
  lines(temp2$Abundance,temp2$bin_depth, col="gray")}
    lines(meanabund$Abundance,meanabund$bin_depth, col=zone_colors[i],lwd=4)
}
dev.off()


```




### c. Elemental analyses
```{r}
load("2024-01-19_VonEggers_WyLakeSedMicrobes_Phyloseq.RData")

ps_tr_26<-subset_samples(ps_tr, bin_depth<=26)
ESV<-as.data.frame(ps_tr_26@otu_table@.Data)
meta_sed_26<-metadata[metadata$samp_names%in%names(ESV),]

depthbins<-sort(unique(meta_sed_26$bin_depth),decreasing=F)

summary<-data.frame(bin_depth=NULL,
                    c13_mean=NULL,c13_sd=NULL,
                    c_perc_mean=NULL,c_perc_sd=NULL,
                    cn_mean=NULL,cn_sd=NULL)
i=1
for(i in 1:length(depthbins)){
  tmp<-meta_sed_26[meta_sed_26$bin_depth==depthbins[i],]
  tmp2<-data.frame(bin_depth=depthbins[i],
                    c13_mean=mean(tmp$d_13_c,na.rm=T),c13_sd=sd(tmp$d_13_c,na.rm=T),
                    c_perc_mean=mean(tmp$c_perc,na.rm=T),c_perc_sd=sd(tmp$c_perc,na.rm=T),
                   cn_mean=mean(tmp$cn,na.rm=T),cn_sd=sd(tmp$cn,na.rm=T))
  summary<-rbind(summary,tmp2)
}


# create a mean relative abundance of each ESV for each depth
ESV<-as.data.frame(ps_tr@otu_table@.Data)
ESV<-t(ESV)

ESV_meta<-as.matrix(ps_tr@sam_data)
ESV_meta<-as.data.frame(ESV_meta)
ESV_meta$bin_depth<-as.numeric(ESV_meta$bin_depth)


mean_abundances<-data.frame()
i=1
centimeters<-c(0,2,4,6,8,10,12,14,16,18,20,22,24,26)
  sub<-ESV[rownames(ESV)%in%(ESV_meta[ESV_meta$bin_depth==centimeters[1] & is.na(ESV_meta$bin_depth)==FALSE,]$samp_names),]
  mean_abundances<-as.data.frame(colMeans(sub))
  colnames( mean_abundances)[1]<-centimeters[i]
for(i in 2:length(centimeters)){
  sub<-ESV[rownames(ESV)%in%(ESV_meta[ESV_meta$bin_depth==centimeters[i] & is.na(ESV_meta$bin_depth)==FALSE,]$samp_names),]
  means<-as.data.frame(colMeans(sub))
  colnames(means)[1]<-centimeters[i]
  mean_abundances<-cbind(mean_abundances,means)
}

# Average CONISS across all samples
tma<-as.matrix(t(mean_abundances))
dist<-vegdist(tma)
clust<-chclust(dist)
```


#### ii. Plot elemental measurements for Fig. 3 A
```{r}
pdf(paste0("Figures/", Sys.Date(),"_RelAbun_Elemental.pdf"), width=13, height=4)  
seq<-seq(2,6,2)
lab<-c("d13C", "%C","C:N")
lines<-3.5
sed_col<-"#616161"



par(mfrow=c(1,13), mar=c(6,6,1,0))
plot(0:26,0:26, bty="n", frame.plot = FALSE, xaxt="n", yaxt="n",ylab = "Depth (cm)", xlab="",ylim=c(26,0), las=1, cex.lab=1.6, pch=19, col="white")
axis(side=2, at= seq(0, 26, by=2), cex.axis=1.6,labels= seq(0, 26, by=2), las=1)
par(mar=c(6,0.5,1,1), xpd=TRUE)

i=1
for(i in 1:length(lab)){
  sum_temp<-summary[,c(1,seq[i],seq[i]+1)]
  sum_temp$sdp<-sum_temp[,2]+sum_temp[,3]
  sum_temp$sdm<-sum_temp[,2]-sum_temp[,3]
  plot(sum_temp[,2],sum_temp$bin_depth,ylim=c(26,0),xlim=c(min(sum_temp$sdm),max(sum_temp$sdp)),type="l",bty="n", yaxt="n", ylab="",col="white",lwd=2, xlab="", cex.axis=1.6)
    mtext(lab[i],side=1,line=3.5, cex=1.1)
polygon(x = c(sum_temp$sdp,rev(sum_temp$sdm)),  # X-Coordinates of polygon 
        y = c(sum_temp$bin_depth, rev(sum_temp$bin_depth)),    # Y-Coordinates of polygon
        col = paste("#616161","50",sep=""), 
        border=paste("#616161","50",sep="")) 
lines(sum_temp[,2],sum_temp$bin_depth, col="#616161",lwd=3)
}
 dev.off()
   
```

#### ii. Plot CONISS for Fig 3. A
```{r}
pdf(paste0("Figures/", Sys.Date(),"_RelAbun_CONISS.pdf"), width=13, height=4)
par(mfrow=c(1,13), mar=c(5.5,6,1.5,0))

par(mar=c(5.5,2,1.5,1))
 plot(clust, xvar=as.numeric(clust[["labels"]]),ylim=c(0,3.2), xaxt="n",hang=-1, cex=1.6, cex.lab=1.6, cex.main=1.8, horiz=TRUE, x.rev=TRUE) 
  mtext("Distance",side=1,line=3, cex=1.1)
  mtext("CONISS", side=3, line=0, cex=1.1)
  axis(side=1,at=c(0,1,2,3),labels=c(0,1,2,3), cex.axis=1.6)
dev.off()
```


## 5. Stats for manuscript
```{r}
# date chunk was ran
Sys.Date()
#[1] "2024-01-29"

# what is the total number of cores and lakes?
length(unique(metadata$lake_id)) # 36 lakes
length(unique(metadata$lake_drive)) # 48 cores 

#average and range of sediment depth for cores? 
lake_drives<-unique(metadata$lake_drive)
maxd<-NULL
for(i in 1:length(lake_drives)){
        tmp<-metadata[metadata$lake_drive==lake_drives[i],]
       maxd <-c(maxd,max(tmp$depth))
}
mean(maxd)
#21.83333
max(maxd)
#88
min(maxd)   
#2

min(metadata$max_lake_depth)
max(metadata$max_lake_depth)
#0.5-19m

#how many lakes greater than or equal to 26 cm deep? 
table(maxd>=26)
22/(26+22)
#0.4583333 of the lakes were at or greater than 26 cm 

# how many samples are less than or equal to 26 cm
nrow(metadata[metadata$depth<=26,])
# 429 samples

# how many samples greater than 26 cm
478-429
#49 

meta_sed_26<-metadata[metadata$depth<=26,]


# all the true
table(is.na(metadata$pH)==F)
#278

table(is.na(metadata$cn)==F)
#282

table(is.na(metadata$d_13_c)==F)
#130



#where are those from?
unique(ps@sam_data[is.na(ps@sam_data$d_13_c)==FALSE,]$mountain_range)
#just the Snowies

#Values for elemental measurements for results section

print("surface")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(0,2,4),]$c_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(0,2,4),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(0,2,4),]$cn, na.rm=T),digits=1)

print("replacement")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12),]$c_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12),]$cn, na.rm=T),digits=2)

print("depauperate")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(14,16,18,20,22,24,26),]$c_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(14,16,18,20,22,24,26),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(14,16,18,20,22,24,26),]$cn, na.rm=T),digits=1)

print("replacement and depauperate")
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22,24,26),]$c_perc, na.rm=T),digits=1)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22,24,26),]$n_perc, na.rm=T),digits=2)
round(mean(meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22,24,26),]$cn, na.rm=T),digits=2)


# [1] "surface"
# [1] 13.09
# [1] 1.34
# [1] 10
# [1] "replacement"
# [1] 11.46
# [1] 1.02
# [1] 11.33
# [1] "depauperate"
# [1] 11.34
# [1] 0.95
# [1] 12.4
# [1] "replacement and depauperate"
# [1] 11.4
# [1] 0.98
# [1] 11.88



# a positive shift in carbon isotopic composition (13C) of occurred from depths 0-4 cm
sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(0),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
#[1] -30.0454 
sd(sub$d_13_c)
#[1] 2.124595 


sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(4),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
#[1] -25.2764
sd(sub$d_13_c)
#[1] 4.420052
(-30.0454) - (-25.2764)
#-4.769 (round to 4.77%) 

sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(6,8,10,12,14,16,18,20,22),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
mean(sub$d_13_c)
#[1] -24.65961 
sd(sub$d_13_c)
#[1] 4.301652  

sub<-meta_sed_26[meta_sed_26$bin_depth%in%c(24,26),]
sub<-sub[is.na(sub$d_13_c)==FALSE,]
nrow(sub)
#10 samples at depths 24 and 26 with isotopic data
mean(sub$d_13_c)
#[1] -26.081  
sd(sub$d_13_c)
#[1] 2.139629  


# range of elevations
range(metadata$elevation_meters,na.rm=T) #NAs are the blanks that don't have elevations
#2032 3350
#subset for 26 cm cutoff elevation
range(meta_sed_26$elevation_meters,na.rm=T) 
#2032 3350 (same)

#range of temperatures

#these are the same for the 26 cm and less samples and the entire dataset
range(metadata$water_sample_t_bot, na.rm=T)
#3.8 20.1
#these are the same for the 26 cm and less samples and the entire dataset
range(metadata$water_sample_t_surf, na.rm=T)
#11.3 20.7
range(metadata$water_sample_ph_bot, na.rm=T)
#5.39 9.68
range(metadata$water_sample_ph_surf, na.rm=T)
#6.83 9.63
range(metadata$water_sample_do_bot, na.rm=T)
#-0.06 12.14
range(metadata$water_sample_do_surf, na.rm=T)
#3.14 8.23

# Started with 555 samples
# ended with 478 samples

# How many lakes cored in 2018 and 2017
sub2017<-metadata[metadata$year_sample=="2017",]
length(unique(sub2017$lake_name)) # 17 lakes
sub2018<-metadata[metadata$year_sample=="2018",]
length(unique(sub2018$lake_name)) # 19 lakes

#how many cores from the Snowies
sub<-metadata[metadata$mountain_range=="Snowy",]
length(unique(sub$lake_name)) #20

#looking for how many lakes were cored more than once (eight)
sort(unique(sub$lake_drive))

#bighorn
sub<-metadata[metadata$mountain_range=="Bighorn",]
length(unique(sub$lake_name)) #6 lakes
sub<-metadata[metadata$mountain_range=="Beartooth",]
length(unique(sub$lake_name)) #5 lakes
sub<-metadata[metadata$mountain_range=="Wind River",]
length(unique(sub$lake_name)) #5 lakes


#create supplementary table 1

ST1<-metadata[,names(metadata)%in%c("lake_id"                
, "drive"                  
,"lake_name"              
,"lake_number"            
, "year_sample"            
, "mountain_range"         
, "latitude"               
, "longitude"              
, "elevation_meters"       
, "max_lake_depth"
,"water_sample_depth_surf"
, "water_sample_ph_surf"   
,"water_sample_do_surf"   
, "water_sample_t_surf"    
, "water_sample_depth_bot" 
,"water_sample_ph_bot"    
, "water_sample_do_bot"    
,"water_sample_t_bot")]

ST1<-unique(ST1)

write.csv(ST1, paste0(Sys.Date(),"_SupplementaryTable1.csv"))


#what percent of reads are archaea?
arch<-subset_taxa(ps, Kingdom=="Archaea")
sum(rowSums(arch@otu_table))/sum(rowSums(ps@otu_table))
#[1] 0.1774655 

```

## 6. Community similarity
### i. Create pairwise comparisons

Community similarity distance decay across sediment distance, geographic distance, and enviromental dissimilarity
```{r}
#used transformed data
OTU<-t(as.data.frame(ps_tr@otu_table@.Data))
#calculate Bray-Curtis similarity between all samples
comm.dist <- 1 - vegdist(OTU)

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),rownames(OTU))),]
table(rownames(OTU)==rownames(metadata)) #all true

#Lat&lon to distance in meters
xy <- data.frame(X = metadata$longitude, Y = metadata$latitude)
rownames(xy)<-metadata$samp_names
dist_m_output<-distm(xy)
rownames(dist_m_output)<-rownames(xy)
names(dist_m_output)<-rownames(xy)
dist_m_output<-as.dist(dist_m_output)


#transform all distance matrices into dataframes with pairwise comparisons
coord.dist.ls<-as.matrix(dist_m_output)
coord.dist.ls[upper.tri(coord.dist.ls, diag = T)] <- NA
coord.dist.ls<-reshape2::melt(coord.dist.ls, na.rm=T)
names(coord.dist.ls)<-c("s1_samp_names","s2_samp_names","geo_dist")


comm.dist.ls<-as.matrix(comm.dist)
comm.dist.ls[upper.tri(comm.dist.ls, diag = T)] <- NA
comm.dist.ls<-reshape2::melt(comm.dist.ls, na.rm=T)
names(comm.dist.ls)<-c("s1_samp_names","s2_samp_names","comm")


#check the names of these match
table(coord.dist.ls[,1]==comm.dist.ls[,1]) #all true
table(coord.dist.ls[,2]==comm.dist.ls[,2]) #all true

#create df with similarity of community and distance
comps<-data.frame(comm.dist.ls)
comps$geo_dist<-coord.dist.ls$geo_dist
comps$s1_samp_names<-as.character(comps$s1_samp_names)
comps$s2_samp_names<-as.character(comps$s2_samp_names)

#add zone into metadata
metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

#merge in metadata to table
metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

comps<-merge(comps, metadata_s1, by="s1_samp_names")
comps<-merge(comps, metadata_s2, by="s2_samp_names")

#remove metadata notes
comps$s1_notes<-NULL
comps$s2_notes<-NULL
comps$s1_Notes_sed_water_wt<-NULL
comps$s2_Notes_sed_water_wt<-NULL
comps$s1_Notes_carbon_nitrogen<-NULL
comps$s2_Notes_carbon_nitrogen<-NULL
comps$s1_Notes._lake_sed_pH<-NULL
comps$s2_Notes._lake_sed_pH<-NULL

# add in centimeters into the distance
comps$abs_cm<-rep(NA, nrow(comps))
comps$s1_depth<-as.numeric(comps$s1_depth)
comps$s2_depth<-as.numeric(comps$s2_depth)
i=1
for(i in 1:nrow(comps)){
  ifelse(comps$s1_lake_drive[i]==comps$s2_lake_drive[i],comps$abs_cm[i]<-abs(comps$s2_depth[i]-comps$s1_depth[i]),NA)
}

#this one takes forever and adds 1 meter to cores within the same lake
comps$dist_1m_forsamelake<-rep(NA,nrow(comps))
i=1
for(i in 1:nrow(comps)){
 if(comps$s1_lake_name[i]==comps$s2_lake_name[i] & comps$s1_lake_drive[i] != comps$s2_lake_drive[i]){comps$dist_1m_forsamelake[i]<-comps$geo_dist[i]+1}else{comps$dist_1m_forsamelake[i]<-comps$geo_dist[i]}
}


#one sample with 2 replicates, so put in 0.001 for the dist_cm_core column
comps<-comps[order(comps$abs_cm,decreasing=F),]
which(names(comps)=="abs_cm")
comps[1,which(names(comps)=="abs_cm")]<-0.001
#check
comps[1,]

rm(comm.dist.ls)
rm(coord.dist.ls)
rm(metadata_s1)
rm(metadata_s2)
rm(OTU)
rm(xy)
rm(comm.dist)
rm(dist_m_output)
rm(i)

#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(ps_tr@otu_table@.Data))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

daisy.mat <- as.dist(as.matrix(daisy(scale(metadata_sub), metric="gower")))

env_distance<-as.matrix(daisy.mat)
env_distance[upper.tri(env_distance, diag = T)] <- NA
env_distance<-reshape2::melt(env_distance, na.rm=T)
names(env_distance)<-c("s1_samp_names","s2_samp_names","env_dist")

env_distance$s1_samp_names<-as.character(env_distance$s1_samp_names)
env_distance$s2_samp_names<-as.character(env_distance$s2_samp_names)

comps<-comps[order(comps$s1_samp_names,comps$s2_samp_names),]
env_distance<-env_distance[order(env_distance$s1_samp_names,env_distance$s2_samp_names),]

table(comps$s1_samp_names==env_distance$s1_samp_names) #all TRUE
table(comps$s2_samp_names==env_distance$s2_samp_names) #all TRUE

comps$env_dist<-env_distance$env_dist
rm(env_distance)

comps$geo_dist_km<-comps$geo_dist/1000

write.csv(comps,paste0(Sys.Date(),"_community_similarity_distance_decay.csv"))

```


### ii. Fig. 5 Community similarity decay

```{r}
comps<-read.csv("IntermediateAnalysisFiles/2024-01-29_community_similarity_distance_decay.csv", header=T, row.names=1)

model_result<-list()
theme_comm<-theme_classic()+
        theme(legend.position="none", axis.text=element_text(color="black"))+
        theme(text=element_text(size=14), #change font size of all text
              axis.text=element_text(size=13), #change font size of axis text
              axis.title=element_text(size=15), #change font size of axis titles  
              axis.title.x = element_text(vjust=-0.3),
              axis.title.y = element_text(margin = margin(r = 10)))
ggplt<-list()
#sediment distance from an individual core
sub<-comps[is.na(comps$abs_cm)==FALSE,]
sub<-sub[sub$s1_zone%in%c("A","B","C") & sub$s2_zone%in%c("A","B","C"),]
table(sub$s1_lake_drive==sub$s2_lake_drive)
#2081 comparisons


Data<-data.frame(x=sub$abs_cm,y=sub$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data) 
model_result[[1]]<-summary(dat_gam)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit

gam.check(dat_gam)

## plot
ggplt[[1]]<-ggplot(data =Data , aes(x = x, y = fit)) +
                geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
                geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                           col="black", alpha = 0.7) +
        geom_line(linewidth=1.5) + labs(x = "Sediment distance (cm)", y = "Community similarity (1-Bray)")+
        scale_x_continuous(breaks=seq(0,26,4))+
        ylim(0,0.8)+
        theme_comm



sub_bind<-NULL
#Geographic distance#
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        sub_bind<-rbind(sub_bind,sub)
}
        Data<-data.frame(x=sub_bind$geo_dist_km,y=sub_bind$comm)
        Data<-Data[order(Data$x),]
        dat_gam=gam(y~s(x, k=4), data=Data)
        model_result[[2]]<-summary(dat_gam)
        pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
        Data$fit<-pred$fit
        Data$se<-pred$se.fit
         model_result[[2]]
        

ggplt[[2]]<-ggplot(data =Data , aes(x = x, y = fit)) +
        geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
        geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                    col="black", alpha = 0.7) +
        geom_line(linewidth=1.5) + labs(x = "Distance (km)", y = "")+
        scale_x_continuous(breaks=seq(0,500,100)) +
        ylim(0,0.8)+
        theme_comm  


sub_bind<-NULL
#environmental distance distance#
i=1
for(i in 1:3){
        sub<-comps[comps$s1_zone==c("A","B","C")[i] & comps$s2_zone==c("A","B","C")[i],]
        sub_bind<-rbind(sub_bind,sub)
}
Data<-data.frame(x=sub_bind$env_dist,y=sub_bind$comm)
Data<-Data[order(Data$x),]
dat_gam=gam(y~s(x, k=4), data=Data)
model_result[[3]]<-summary(dat_gam)
pred = predict.gam(dat_gam, newdata = Data[1], se.fit=T)
Data$fit<-pred$fit
Data$se<-pred$se.fit
model_result[[3]]

   ggplt[[3]]<-ggplot(data =Data , aes(x = x, y = fit)) +
           geom_point(data =  Data, aes(x = x, y = y), size=1.5, col="darkgray", alpha=0.3) +
           geom_ribbon(aes(ymin = fit - se, ymax = fit + se, y = NULL),
                       col="black", alpha = 0.7) +
   geom_line(linewidth=1.5) + labs(x = "Environmental dissimilarity", y = "")+
   scale_x_continuous(breaks=seq(0,0.73,0.1)) +
           ylim(0,0.8)+
           theme_comm


pdf(paste0("Figures/",Sys.Date(),"_CommSimmDecay.pdf"), height = 3.5, width= 11)
ggplt[[1]]+ ggplt[[2]] + ggplt[[3]] + plot_layout(ncol = 3)
dev.off()

model_result[[1]]
model_result[[2]]
model_result[[3]]
```

### iii. Environmental dissimilarity and geographic distance
```{r}
comps<-read.csv("IntermediateAnalysisFiles/2024-01-29_community_similarity_distance_decay.csv", header=T, row.names=1)


env_geo <- comps %>%
        select(env_dist,geo_dist_km) %>%
        filter(env_dist !=0 , geo_dist_km !=0) %>%
        distinct()

summary(lm(env_geo$env_dist~env_geo$geo_dist_km))

```

Call:
lm(formula = env_geo$env_dist ~ env_geo$geo_dist_km)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29799 -0.11605 -0.01822  0.10958  0.39301 

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)          3.293e-01  9.889e-03  33.301   <2e-16 ***
env_geo$geo_dist_km -6.192e-05  3.531e-05  -1.754   0.0799 .  

Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 0.1544 on 639 degrees of freedom
Multiple R-squared:  0.004791,	Adjusted R-squared:  0.003233 
F-statistic: 3.076 on 1 and 639 DF,  p-value: 0.07994



## 7. Shared ESVs 
### i. Calculate shared ESVs
```{r}
#calculate
shared_esvs <- phyloseq_num_shared_otus(ps)


#shared ESVs
shared<-as.matrix(shared_esvs[["shared"]])
shared[upper.tri(shared, diag = T)] <- NA
shared<-melt(shared,na.rm=TRUE)

colnames(shared)[3]<-"shared"

#nonshared ESVs
nonshared<-as.matrix(shared_esvs[["nonshared_total"]])
nonshared[upper.tri(nonshared, diag = T)] <- NA
nonshared<-melt(nonshared,na.rm=TRUE)
colnames(nonshared)[3]<-"nonshared"

table(nonshared$Var1==shared$Var1) #all T
table(nonshared$Var2==shared$Var2) #all T

shared$nonshared<-nonshared$nonshared
rm(nonshared)
shared$percent<-shared$shared/(shared$shared+shared$nonshared)


#now add in environmental distances
#using objects from above
variables<-c("max_lake_depth"         
, "water_sample_ph_bot"     
, "water_sample_do_bot"     
, "water_sample_t_bot") 

#pull out metadata
metadata<-metadata[order(match(rownames(metadata),colnames(as.matrix(shared_esvs[["shared"]])))),]
metadata_sub<-metadata[,names(metadata)%in%variables]

daisy.mat <- as.matrix(daisy(scale(metadata_sub), metric="gower"))

daisy.mat[upper.tri(daisy.mat, diag = T)] <- NA
env_dist<-melt(daisy.mat, na.rm=TRUE)

table(shared$Var1==env_dist$Var1) # all true
table(shared$Var2==env_dist$Var2) # all true 
shared$env_dist<-env_dist$value
 #overwrite original file

names(shared)[1]<-"s1_samp_names"
shared$s1_samp_names<-as.character(shared$s1_samp_names)
names(shared)[2]<-"s2_samp_names"
shared$s2_samp_names<-as.character(shared$s2_samp_names)

metadata$zone<-rep("A",nrow(metadata))
metadata[metadata$bin_depth%in%c(6,8,10,12),]$zone<-"B"
metadata[metadata$bin_depth%in%c(14,16,18,20,22,24,26),]$zone<-"C"
metadata[metadata$depth>26,]$zone<-"D"

metadata_s1<-metadata
colnames(metadata_s1)<-paste("s1",colnames(metadata_s1), sep="_")

metadata_s2<-metadata
colnames(metadata_s2)<-paste("s2",colnames(metadata_s2), sep="_")

shared<-merge(shared, metadata_s1, by="s1_samp_names")
shared<-merge(shared, metadata_s2, by="s2_samp_names")

#remove metadata notes
shared$s1_notes<-NULL
shared$s2_notes<-NULL
shared$s1_Notes_sed_water_wt<-NULL
shared$s2_Notes_sed_water_wt<-NULL
shared$s1_Notes_carbon_nitrogen<-NULL
shared$s2_Notes_carbon_nitrogen<-NULL
shared$s1_Notes._lake_sed_pH<-NULL
shared$s2_Notes._lake_sed_pH<-NULL

#absolute cm for sediment distance

# add in absolute centimeters into the distance
shared$abs_cm<-rep(NA, nrow(shared))
i=1
for(i in 1:nrow(shared)){
  ifelse(shared$s1_lake_drive[i]==shared$s2_lake_drive[i],shared$abs_cm[i]<-abs(shared$s2_depth[i]-shared$s1_depth[i]),NA)
}


# calculate geographic distance


for(i in 1:nrow(shared)){
        shared$geo_dist[i]<-as.numeric(distm(data.frame(X = shared$s1_longitude[i], Y = shared$s1_latitude[i]),data.frame(X = shared$s2_longitude[i], Y = shared$s2_latitude[i])))
}

shared$geo_dist_km<-shared$geo_dist/1000


write.csv(shared, paste0(Sys.Date(), "_sharedESVs.csv"))
```
### ii. Plot SFig. X shared ESVs
```{r}
comps_backup<-read.csv("2024-01-29_sharedESVs.csv",header=T,row.names=1)
comps_backup$percent<-comps_backup$percent*100

zone<-c("A","B","C")
comps<-comps_backup
pdf(paste0("Figures/SupplementaryFigures/",Sys.Date(),"_SFigX_PercentSharedESVs.pdf"), width=7, height=7)
par(mfrow=c(3,3), mar=c(4,4,3,2))

j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]
plot(comps_sub$env_dist, comps_sub$percent, ylab="Shared ESVs (%)", pch=16, col="#00000050",xlab="Environmental dissimilarity", ylim=c(0,40),main=c("Redox", "Transition", "Depauperate")[j])
abline(lm(comps_sub$percent~comps_sub$env_dist), col="lightgreen", lwd=2)
if(summary(lm(comps_sub$percent~comps_sub$env_dist))$coefficients[2,4]<0.05){
        text(x=(max(comps_sub$env_dist)*.95), 40*0.95,"*" ,cex=3)
}}



j=1
for(j in 1:3){
comps_sub<-comps[comps$s1_zone==zone[j] & comps$s2_zone==zone[j],]
plot(comps_sub$geo_dist_km, comps_sub$percent, ylab="Shared ESVs (%)", pch=16, col="#00000050",xlab="Distance (km)",ylim=c(0,40))
abline(lm(comps_sub$percent~comps_sub$geo_dist_km), col="lightgreen", lwd=2)
if(summary(lm(comps_sub$percent~comps_sub$geo_dist_km))$coefficients[2,4]<0.05){
        text(x=(max(comps_sub$geo_dist_km)*.95), 40*0.95,"*" ,cex=3)
}}



#sediment
comps<-comps_backup[is.na(comps_backup$abs_cm)==F & comps_backup$abs_cm<27 ,]
plot(comps$abs_cm, comps$percent, ylab="Shared ESVs (%)", xlab="Sediment distance (cm)", pch=16, col="#00000050",main="All horizons, individual cores")
abline(lm(comps$percent~comps$abs_cm), col="lightgreen", lwd=2)
if(summary(lm(comps$percent~comps$abs_cm))$coefficients[2,4]<0.05){
        text(x=(max(comps$abs_cm)*.95), max(comps$percent)*0.95,"*" ,cex=3)
}

dev.off()
```




## 8. Individual lake CONISS

```{r}
# use transformed data
OTU<-as.data.frame(ps_tr@otu_table)
OTU<-t(OTU)

lake_drives<-unique(metadata$lake_drive)
rn<-rownames(OTU)
meta_sed<-metadata
meta_sed<-meta_sed[order(match(rownames(meta_sed),rownames(OTU))),]
table(meta_sed$samp_names==rownames(OTU)) #all true
which(table(metadata$lake_drive)<2)

#remove lakes with one sample
lake_drives<-lake_drives[lake_drives!="BN_1"]
lake_drives<-lake_drives[lake_drives!="ML_1"]

#lakes with two samples, can't be used
lake_drives<-lake_drives[lake_drives!="LB_1"]
lake_drives<-lake_drives[lake_drives!="NB_1"]
lake_drives<-lake_drives[lake_drives!="SG_1"]


#individual lake CONISS clustering
pdf(paste0("Figures/", Sys.Date(),"_individual_lake_CONISS.pdf"),height=12,width=17)
i=1
par(mfrow=c(5,9),mar=c(2,4,2,0))
for(i in 1:length(lake_drives)){
  subset<-meta_sed[meta_sed$lake_drive==lake_drives[i],]
  subset<-subset[order(subset$depth),]
  names<-subset$samp_names
  rows<-which(rn%in%names)
  sub_otu<-as.data.frame(OTU[rows,])
  sub_otu$rownames<-rownames(sub_otu)
  new_dataset <- sub_otu[match(names, sub_otu$rownames), ]       
  rownames(new_dataset)==new_dataset$rownames
  rownames(new_dataset)==rownames(subset)
  new_dataset$rownames<-NULL
  if(length(unique(subset$depth)) < length(subset$depth)){
      dup<-subset$depth[which(duplicated(subset$depth))]
      pos<-which(subset$depth==dup)
        subset$depth[pos[2]]<-subset$depth[pos[2]]+0.5
  }
  rownames(new_dataset)<-subset$depth
  new_dataset<-as.matrix(new_dataset)
  dist<-vegdist(new_dataset)
  clust<-chclust(dist)
  plot(clust, xvar=as.numeric(clust[["labels"]]), main=paste(subset$lake_name[1],subset$drive[1], sep=" "), ylim= c(0,5), hang=-1, horiz=TRUE, x.rev=TRUE)
}
dev.off()

```






